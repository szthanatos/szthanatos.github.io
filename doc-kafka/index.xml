<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kafka 30 分钟指北 | Kryptonite Lab</title>
    <link>https://szthanatos.github.io/doc-kafka/</link>
      <atom:link href="https://szthanatos.github.io/doc-kafka/index.xml" rel="self" type="application/rss+xml" />
    <description>Kafka 30 分钟指北</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh-Hans</language><lastBuildDate>Tue, 15 Jan 2019 15:40:52 +0800</lastBuildDate>
    <image>
      <url>https://szthanatos.github.io/images/icon_hu38c28d6ecf464f8a293472d2a570e5b8_6181_512x512_fill_lanczos_center_2.png</url>
      <title>Kafka 30 分钟指北</title>
      <link>https://szthanatos.github.io/doc-kafka/</link>
    </image>
    
    <item>
      <title>Kafka -01- 安装配置</title>
      <link>https://szthanatos.github.io/doc-kafka/install/</link>
      <pubDate>Thu, 06 Dec 2018 10:09:46 +0800</pubDate>
      <guid>https://szthanatos.github.io/doc-kafka/install/</guid>
      <description>&lt;h2 id=&#34;环境说明&#34;&gt;环境说明&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;当前版本&lt;/th&gt;
&lt;th&gt;发布日期&lt;/th&gt;
&lt;th&gt;下载地址&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2.0&lt;/td&gt;
&lt;td&gt;2018-07-30&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.apache.org/dyn/closer.cgi?path=/kafka/2.0.0/kafka_2.11-2.0.0.tgz&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;官方 2.0.0 镜像&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;安装步骤&#34;&gt;安装步骤&lt;/h2&gt;
&lt;p&gt;_** 注意：** 文中以 &lt;code&gt;{}&lt;/code&gt; 包裹起来的内容需要自己替换，并非直接使用_&lt;/p&gt;
&lt;h3 id=&#34;0-环境准备&#34;&gt;0. 环境准备&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;基础环境&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Java&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Java 版本应该在 8(jdk1.8) 或以上，以更好的支持 G1 回收&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;硬件参数&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;CPU: 英特尔至强 E5-2650 v4 &lt;em&gt;2 (共计 24 核) &lt;br&gt;Mem: DDR4 内存 - 32GB&lt;/em&gt; 8 &lt;br&gt;Sto: 2000GB * 8 raid 0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;文件路径&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;/home/tools/kafka_2.11-2.0.0/&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;数据存放位置&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;/home/sdb/kafka-logs,/home/sdc/kafka-logs, &lt;br&gt;/home/sdd/kafka-logs,/home/sde/kafka-logs, &lt;br&gt;/home/sdf/kafka-logs,/home/sdg/kafka-logs, &lt;br&gt;/home/sdh/kafka-logs,/home/sdi/kafka-logs&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;zookeeper 集群位置&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;10.10.20.83:2181,10.10.20.84:2181,10.10.20.85:2181&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;1-下载安装&#34;&gt;1. 下载安装&lt;/h3&gt;
&lt;p&gt;下载最新版本 Kafka，解压到指定目录，无需其他操作即完成安装。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;tar -xzf kafka_2.11-2.0.0.tgz -C /home/tools
cd kafka_2.11-2.0.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;2-配置集群参数&#34;&gt;2. 配置集群参数&lt;/h3&gt;
&lt;p&gt;修改 &lt;code&gt;config/server.properties&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;基本参数如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# broker 唯一 id，值为不重复正整数
broker.id={n: int}

# 服务监听地址
listeners=PLAINTEXT://{your.host}:9092

# 日志存放位置列表，以逗号隔开
log.dirs={data.storage.list}

# zookeeper 地址列表，以逗号隔开
zookeeper.connect={zookeeper.server.list}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;优化参数配置如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 消息处理线程数，建议数量为 cpu 核数加 1
num.network.threads=25

# 磁盘 IO 的线程数, 建议为 cpu 核数 2 倍，最大不超过 3 倍
num.io.threads=48

# 拉取线程数，影响 follower 的 I/O 并发度，单位时间内 leader 持有更多请求，相应负载会增大
num.replica.fetchers=2

# 分区数量配置，根据业务情况修改
num.partitions=16

# 消息日志备份数，默认是 1
default.replication.factor=2

# 刷盘 (写入文件到磁盘) 间隔消息数，建议设为 10000
log.flush.interval.messages=10000

# 刷盘间隔毫秒数，建议 1 秒 (1000)
log.flush.interval.ms=1000

# 日志保留小时数
log.retention.hours=48

# 段文件大小，过小会产生很多小文件降低性能，过大会影响快速回收磁盘空间以及 Kafka 重启后的载入速度
og.segment.bytes=1073741824

# 最大字节数，默认 1M，可以调到 5M 以上
replica.fetch.max.bytes=5242880

# 可接受数据大小，受限于 java int 类型的取值范围, 超出后会报 OOM 异常
socket.request.max.bytes=2147483600

# 日志传输时候的压缩格式，可选择 lz4, snappy, gzip, 不压缩。建议打开压缩，可以提高传输性能
compression.type=snappy

# 是否允许通过管理工具删除 topic，默认是 false
delete.topic.enable=true

# 是否允许程序自动创建 Topic
auto.create.topics.enable=false
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;3-配置日志参数&#34;&gt;3. 配置日志参数&lt;/h3&gt;
&lt;p&gt;修改 &lt;code&gt;config/log4j.properties&lt;/code&gt; 的 jog4j 参数，提高 Kafka 操作日志（和数据日志区分）的日志级别，以降低日志输出相关资源占用。具体可更改配置如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Kafka2.0 默认只有 controller 是 TRACE 级别，可以改为 INFO，其他 INFO 级别可以适当提升为 WARN

# zookeeper 日志级别，
log4j.logger.org.I0Itec.zkclient.ZkClient=INFO
log4j.logger.org.apache.zookeeper=INFO

# 主日志级别
log4j.logger.kafka=INFO
log4j.logger.org.apache.kafka=INFO

# request 日志级别，只有当需要调试时才有必要输出
log4j.logger.kafka.request.logger=WARN, requestAppender
log4j.additivity.kafka.request.logger=false

# 需要调试时解除以下三行注释，并将 RequestChannel$ 设为 TRACE
# log4j.logger.kafka.network.Processor=TRACE, requestAppender
# log4j.logger.kafka.server.KafkaApis=TRACE, requestAppender
# log4j.additivity.kafka.server.KafkaApis=false
log4j.logger.kafka.network.RequestChannel$=WARN, requestAppender
log4j.additivity.kafka.network.RequestChannel$=false

# controller 日志级别，默认为 TRACE
log4j.logger.kafka.controller=INFO, controllerAppender
log4j.additivity.kafka.controller=false

# 日志清理的日志级别
log4j.logger.kafka.log.LogCleaner=INFO, cleanerAppender
log4j.additivity.kafka.log.LogCleaner=false

log4j.logger.state.change.logger=TRACE, stateChangeAppender
log4j.additivity.state.change.logger=false

# 登陆认证的日志级别
log4j.logger.kafka.authorizer.logger=INFO, authorizerAppender
log4j.additivity.kafka.authorizer.logger=false
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;4-配置-jvm-参数&#34;&gt;4. 配置 JVM 参数&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Warning&lt;/strong&gt;：谨慎调试&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;在 &lt;code&gt;bin/kafka-server-start.sh&lt;/code&gt; 文件中调整参数如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 在 base_dir 之后配置参数
base_dir=$(dirname $0)

export KAFKA_HEAP_OPTS=&amp;quot;-Xms6g -Xmx6g -XX:MetaspaceSize=96m -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;ps：&lt;/strong&gt; 虽然看起来很激进，但是以上配置参照的是 LinkIn 高峰时期最繁忙的集群:&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-properties&#34;&gt;60 brokers
50k partitions (replication factor 2)
800k messages/sec in
300 MB/sec inbound, 1 GB/sec+ outbound
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;ps2：&lt;/strong&gt; 这个配置的集群实现了 90% 的 GC 中断时间不超过 21 毫秒，每秒钟新生代 GC 次数不超过一次&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;ps3：&lt;/strong&gt; 上述环境的 Java 版本为 JDK 1.8 u5&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;5-配置-linux-参数&#34;&gt;5. 配置 Linux 参数&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Warning&lt;/strong&gt;：谨慎调试&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 调整系统所有进程一共可以打开的最大文件数：
echo &#39;fs.file-max = 1024000&#39; &amp;gt;&amp;gt; /etc/sysctl.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以及 &lt;code&gt;/etc/security/limits.conf&lt;/code&gt; 末尾增加：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 设置当前 user 以及由它启动的进程的资源限制
{user}      soft    nofile      1024000
{user}      hard    nofile      1024000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;增大 socket buffer size，以提高吞吐性能&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;echo 212992 &amp;gt;&amp;gt; /proc/sys/net/core/wmem_max
echo 212992 &amp;gt;&amp;gt; /proc/sys/net/core/rmem_max
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;kafka20-官方安装指南&#34;&gt;Kafka2.0 官方安装指南&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://kafka.apache.org/documentation/#quickstart&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quick Start&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Kafka -02- 滚动升级</title>
      <link>https://szthanatos.github.io/doc-kafka/update/</link>
      <pubDate>Sun, 09 Dec 2018 15:19:52 +0800</pubDate>
      <guid>https://szthanatos.github.io/doc-kafka/update/</guid>
      <description>&lt;h2 id=&#34;环境说明&#34;&gt;环境说明&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;版本号&lt;/th&gt;
&lt;th&gt;发布日期&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;当前版本&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;0.11.0.1&lt;/td&gt;
&lt;td&gt;2017-09-14&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;最新版本&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;2.0&lt;/td&gt;
&lt;td&gt;2018-07-30&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;配置文件路径：&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;/home/tools/kafka_2.12-0.11.0.1/config/&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;目标需求：&lt;/strong&gt; 在 Kafka 集群不停机不停止服务的情况下进行升级改造。&lt;/p&gt;
&lt;h2 id=&#34;可能存在的风险&#34;&gt;可能存在的风险&lt;/h2&gt;
&lt;h3 id=&#34;轻微警报&#34;&gt;轻微警报&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;consumer 可能出现偏移量提交失败而造成重复消费&lt;/li&gt;
&lt;li&gt;broker 提示&amp;rsquo;NotLeaderForPartitionException&amp;rsquo;异常&lt;/li&gt;
&lt;li&gt;由于节点下线，可能造成临时性能问题&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;严重警报&#34;&gt;严重警报&lt;/h3&gt;
&lt;p&gt;严格按照步骤升级，暂未捕捉到严重问题相关信息&lt;/p&gt;
&lt;h2 id=&#34;升级步骤滚动升级&#34;&gt;升级步骤（滚动升级）&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;限定通讯协议版本：&lt;/p&gt;
&lt;p&gt;配置 broker 上的 server.properties 文件：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;inter.broker.protocol.version = 0.11.0
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;依次更新代码并重启 borker：&lt;/p&gt;
&lt;p&gt;一次关闭一个 broker，更新源码，重启&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;更新通讯协议版本：&lt;/p&gt;
&lt;p&gt;完成所有 broker 节点的源码更新后, 升级协议（方法同上）：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;inter.broker.protocol.version = 2.0
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;再次依次重启 broker：&lt;/p&gt;
&lt;p&gt;同上，一次重启一个&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;ps：&lt;/em&gt;&lt;/strong&gt; 如果修改过消息格式版本 (log.message.format.version)，则需要在上面步骤中，同步配置：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;log.message.format.version = 当前版本 / 要升级的版本
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;替代方案离线升级&#34;&gt;替代方案（离线升级）&lt;/h2&gt;
&lt;p&gt;关闭所有 broker，更新代码并重新启动。默认情况下，自动以新协议开始。&lt;/p&gt;
&lt;h2 id=&#34;kafka20-官方升级指南&#34;&gt;Kafka2.0 官方升级指南&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://kafka.apache.org/documentation/#upgrade&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;upgrade&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
