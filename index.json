[{"authors":null,"categories":null,"content":"I\u0026rsquo;m whatever Gotham needs me to be.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I\u0026rsquo;m whatever Gotham needs me to be.","tags":null,"title":"Lex Wayne","type":"authors"},{"authors":["sz"],"categories":null,"content":"施工ing\u0026hellip;\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"e82475504794dbc9e1d724238b8546f1","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"施工ing\u0026hellip;","tags":null,"title":"苏展","type":"authors"},{"authors":["gpp"],"categories":null,"content":"施工ing\u0026hellip;\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"7f42f91a3638621e5bbdad06e0d16b81","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"施工ing\u0026hellip;","tags":null,"title":"郭柿子小可爱","type":"authors"},{"authors":null,"categories":null,"content":" 2020 年，我使用的 Windows 系统被评为最好的 Linux 发行版 ←_←\n为什么呢？\n各类工具层出不穷\n环境生态市场份额世界第一\n这是事实，无需否认\n所以人们蜂拥而来\n这系统总会给你一丝希望\n谎言也好，幻觉也罢\n但如此近\n仿佛触手可及\n让人奋不顾身\u0026hellip;\n 在这个程序员标配苹果的世界里，对于那些对 MacOS 抱有偏见的人来说（比如我），Wsl2 就是那丝希望。\n不过讲道理，相对于其他平台（主要是 MacOS），想要在 Windows 下获得足够舒适（颜值在线）的开发体验，过程还是繁琐许多，无法开箱即用，可能需要一些技巧才能上手。\n公平的是，配置好之后，得益于 Windows 生态，体验的上限也比其他平台要高（个人意见）。\n我这边主要是后端开发（Python most, Go sometimes）为主，代码也主要运行在 Linux 环境下。\n想要获得完整的开发体验，你需要：\n 配置 WSL 什么是 WSL 适用于 Linux 的 Windows 子系统可让开发人员按原样运行 GNU/Linux 环境 - 包括\n  配置 Terminal 介绍就两个字，颜值。 安装方式同样是 Microsoft Store。 默认可以使用\n  配置 Ubuntu 启用 root 用户 ubuntu 默认没有 root 密码，使用 sudo passwd root 设置 root 密码 配置国内镜像\n  配置 Shell // TODO 吹一下 zsh 安装 zsh # 安装 zsh sudo apt install zsh -y # 修改默认 shell 为 zsh sudo chsh -s /bin/zsh\n  配置 Tmux Tmux 是一个终端复用软件。比如你开一个 terminal 窗口，相当于和本地的或远\n  配置 Python 环境 (选) 在前面的部分已经配置好了 Python 的死蛇源，所以现在已经可以使用 Ubuntu 作\n  配置 Docker 环境 嗯，是的，其实可以直接在 Windows 下运行 Docker 而无需 Wsl。但是 Wsl2 会提供\n  配置 Pycharm 选项 大小写敏感 File -\u0026gt; Settings -\u0026gt; Editor -\u0026gt; General -\u0026gt; Code Completion 取消后全小写也能自动补全，\n  请根据实际需要进行针对性配置。\n比如不整这些花里胡哨的，直接配置 Wsl 和 Docker 就好\u0026hellip;\n又不是不能用\u0026hellip; ┑(￣Д ￣)┍ 异端~ 颜值才是生产力！(╯‵□′)╯︵┻━┻\n ","date":1599609600,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1599609600,"objectID":"d75ec7ea08b23ca18a2d08a85dea11f6","permalink":"https://szthanatos.github.io/topic/wsl2/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/topic/wsl2/","section":"topic","summary":"Wsl2+Ubuntu+Zsh+Tmux+Docker","tags":null,"title":"WSL2 开发环境 30 分钟指北","type":"book"},{"authors":null,"categories":null,"content":"关于 Kafka，看完你就知道他们都在逼逼什么了。\n","date":1547538052,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1547538052,"objectID":"4b903f59e77b20dc804f8bb6d71441b2","permalink":"https://szthanatos.github.io/topic/kafka/","publishdate":"2019-01-15T15:40:52+08:00","relpermalink":"/topic/kafka/","section":"topic","summary":"关于 Kafka，看完你就知道他们都在逼逼什么了。","tags":null,"title":"Kafka 30 分钟指北","type":"book"},{"authors":null,"categories":null,"content":"关于 Docker，看完你就知道他们都在逼逼什么了。\n","date":1544342124,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1536451200,"objectID":"31c005a75ad173ed9241ca0781db762e","permalink":"https://szthanatos.github.io/topic/docker/","publishdate":"2018-12-09T15:55:24+08:00","relpermalink":"/topic/docker/","section":"topic","summary":"关于 Docker，看完你就知道他们都在逼逼什么了。","tags":null,"title":"Docker 30 分钟指北","type":"book"},{"authors":null,"categories":null,"content":" Redis 是一个开源（BSD 许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets） 与范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询。 Redis 内置了 复制（replication），LUA 脚本（Lua scripting）， LRU 驱动事件（LRU eviction），事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过 Redis 哨兵（Sentinel）和自动 分区（Cluster）提供高可用性（high availability）。\n —— Redis 官方介绍\n","date":1526614970,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1560666892,"objectID":"9aac42af5621e08eafcc0c2bfaf288e8","permalink":"https://szthanatos.github.io/topic/redis/","publishdate":"2018-05-18T11:42:50+08:00","relpermalink":"/topic/redis/","section":"topic","summary":"关于 Redis，看完你就知道他们都在逼逼什么了。","tags":null,"title":"Redis 30 分钟指北","type":"book"},{"authors":null,"categories":null,"content":" // TODO\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1536451200,"objectID":"fe594a95087a7443d3eaa02b0afd9efd","permalink":"https://szthanatos.github.io/topic/redis/01-design/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/topic/redis/01-design/","section":"topic","summary":"// TODO","tags":null,"title":"设计","type":"book"},{"authors":null,"categories":null,"content":"  集群相关命令 集群信息 节点信息 集群节点相关信息可以通过 cluster nodes 命令获取： 127.0.0.1:6379\u0026gt; cluster nodes\n  ","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1536451200,"objectID":"e03c3158fe8367e0fa79c77bbd988a33","permalink":"https://szthanatos.github.io/topic/redis/02-usage/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/topic/redis/02-usage/","section":"topic","summary":"集群相关命令 集群信息 节点信息 集群节点相关信息可以通过 cluster nodes 命令","tags":null,"title":"操作","type":"book"},{"authors":null,"categories":null,"content":"  单机 \u0026amp; 集群安装 版本 软件 版本 更新日期 备注 Redis 4.0.11 2018-08-03 必装 Ruby 2.5.1 2018-03-28 可选, 集群执行 rb 脚本\n  ","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1536451200,"objectID":"2c4c248e1ffa3bce5426ec224b6d0a3c","permalink":"https://szthanatos.github.io/topic/redis/03-operation/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/topic/redis/03-operation/","section":"topic","summary":"单机 \u0026amp; 集群安装 版本 软件 版本 更新日期 备注 Redis 4.0.11 2018-08-03 必装 Ruby 2.5.1 2018-03-28 可选,","tags":null,"title":"运维","type":"book"},{"authors":null,"categories":null,"content":"redis性能优化可以从设计，使用，运维三个层面上着手：\n 设计  结构：合理选择数据类型 负载：保证数据在空间上均匀分布   使用，  操作：保证操作在时间上均匀分布 策略：优化资源利用   运维  监控：持续关注执行效率和性能指标 部署：物理层面的调优    下面具体的谈一下几个tips。\n 设计 数据结构 不同数据类型对应的操作的时间复杂度也不一样，选择合适\n  使用 操作 批量操作 传统数据库也存在批量操作效率高于单次操作的情况，\n  运维 监控 为了发现前面所说的问题，需要开发 / 运维人员不断的监控 redis 运\n  ","date":1552892675,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1552892675,"objectID":"d992e798fbc89821cafe6dd32ca0317f","permalink":"https://szthanatos.github.io/topic/redis/04-advanced/","publishdate":"2019-03-18T15:04:35+08:00","relpermalink":"/topic/redis/04-advanced/","section":"topic","summary":"redis性能优化可以从设计，使用，运维三个层面上着手： 设计","tags":null,"title":"优化指南","type":"book"},{"authors":null,"categories":null,"content":"各种情况下的解决办法。\n connection reset by peer 报错信息 Error: Connection reset by peer 原因 读写操作发生在连接断开后。 解决办法 用 info/cluster\n  not able to persist on disk 报错信息 MISCONF Redis is configured to save RDB snapshots, but it is currently not able to persist on disk. 原因 绝大多数情况\n  ","date":1535618448,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1535618448,"objectID":"13dd29f31f520633097b53ee0461a116","permalink":"https://szthanatos.github.io/topic/redis/05-troubleshooting/","publishdate":"2018-08-30T16:40:48+08:00","relpermalink":"/topic/redis/05-troubleshooting/","section":"topic","summary":"各种情况下的解决办法。 connection reset by peer 报错信息 Error: Connection reset by peer 原因 读写操作","tags":null,"title":"问题处理","type":"book"},{"authors":null,"categories":null,"content":"// TODO\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1536451200,"objectID":"11a9f09ae33e5f0aad939598900b2bd6","permalink":"https://szthanatos.github.io/topic/redis/06-reference/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/topic/redis/06-reference/","section":"topic","summary":"// TODO","tags":null,"title":"参考文献","type":"book"},{"authors":null,"categories":null,"content":"Docker 简介 什么是 Docker Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，并于 2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护，后来还加入了 Linux 基金会，并成立推动 开放容器联盟（OCI）。\nDocker 最初是在 Ubuntu 12.04 上以 Go 语言 进行开发实现的, Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持 (换句话说不支持 CentOS6.5 以下)。\nDocker 是一种 容器化技术 ，类似虚拟机的概念，但不同的是传统虚拟机是在虚拟硬件的基础上，完整模拟一整个操作系统，而 Docker 是以单个应用（容器）为单位进行虚拟。\nDocker 特点 Docker 具有以下特点：\n 文件系统隔离 ：每个进程容器运行在完全独立的根文件系统里。 资源隔离 ：可以使用 cgroup 为每个进程容器分配不同的系统资源，例如 CPU 和内存。 网络隔离 ：每个进程容器运行在自己的网络命名空间里，拥有自己的虚拟接口和 IP 地址。 写时复制 ：采用写时复制方式创建根文件系统，这让部署变得极其快捷，并且节省内存和硬盘空间。 日志记录 ：Docker 将会收集和记录每个进程容器的标准流（stdout/stderr/stdin），用于实时检索或批量检索。 变更管理 ：容器文件系统的变更可以提交到新的映像中，并可重复使用以创建更多的容器。无需使用模板或手动配置。 交互式 Shell ：Docker 可以分配一个虚拟终端并关联到任何容器的标准输入上，例如运行一个一次性交互 shell。  为什么要使用 Docker    特性 容器 虚拟机     启动 秒级 分钟级   硬盘使用 一般为 MB 一般为 GB   性能 接近原生 弱于原生   系统支持量 单机支持上千个容器 一般几十个     更高效的利用系统资源 ：由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker 对系统资源的利用率更高。相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。 更快速的启动时间 ：Docker 容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。 一致的运行环境 ： Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 「这段代码在我机器上没问题啊」 这类问题。 持续交付和部署 ：对 DevOps 人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。使用 Docker 可以通过定制应用镜像来实现持续集成、持续交付、部署。开发人员可以通过 Dockerfile 来进行镜像构建，并结合 持续集成 (Continuous Integration) 系统进行集成测试，而运维人员则可以直接在生产环境中快速部署该镜像，甚至结合 持续部署 (Continuous Delivery/Deployment) 系统进行自动部署。 更轻松的迁移 ：由于 Docker 确保了执行环境的一致性，使得应用的迁移更加容易。Docker 可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结果是一致的。因此用户可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。  基本概念 Docker 包括三个基本概念\n 镜像（Image） 容器（Container） 仓库（Repository）  理解了这三个概念，就理解了 Docker 的整个生命周期。\n镜像 操作系统分为内核和用户空间。对于 Linux 而言，内核启动后，会挂载 root 文件系统为其提供用户空间支持。而 Docker 镜像（Image），就相当于是一个 root 文件系统。比如官方镜像 ubuntu:16.04 就包含了完整的一套 Ubuntu 16.04 最小系统的 root 文件系统。\nDocker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。 镜像不包含任何动态数据，其内容在构建之后也不会被改变。\n严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。\n镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。 比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。\n分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。\n容器 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的 类 和 实例 一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。\n容器的实质是进程 ，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。也因为这种隔离的特性，很多人初学 Docker 时常常会混淆容器和虚拟机。\n前面讲过镜像使用的是分层存储，容器也是如此。 每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层， 我们可以称这个为容器运行时读写而准备的存储层为 容器存储层 。\n容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此， 任何保存于容器存储层的信息都会随容器删除而丢失 。\n按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。 所有的文件写入操作，都应该使用 [数据卷（Volume）](#### 方式 1：数据卷（推荐）)、或者 [绑定宿主目录](#### 方式 2：挂载主机目录) ，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。\n数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器删除或者重新运行之后，数据却不会丢失。\n仓库 如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker 提供注册服务器 (Docker Registry) 来实现这样的服务。\n一个 Docker Registry 中可以包含多个 仓库 （Repository）；每个仓库可以包含多个 标签 （Tag）；每个标签对应一个镜像。\n通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 \u0026lt;仓库名\u0026gt;:\u0026lt; 标签 \u0026gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。\n以 Ubuntu 镜像 为例，ubuntu 是仓库的名字，其内包含有不同的版本标签，如，14.04, 16.04。我们可以通过 ubuntu:14.04，或者 ubuntu:16.04 来具体指定所需哪个版本的镜像。如果忽略了标签，比如 ubuntu，那将视为 ubuntu:latest。\n仓库名经常以 两段式路径 形式出现，比如 jwilder/nginx-proxy，前者往往意味着 Docker Registry 多用户环境下的用户名，后者则往往是对应的软件名。但这并非绝对，取决于所使用的具体 Docker Registry 的软件或服务。\n类似 git 和 GitHub，官方提供 Docker Hub，作为默认的 Registry。用户也可以在本地搭建私有 Docker Registry。Docker 官方提供了 Docker Registry 镜像，可以直接使用做为私有 Registry 服务。\n生命周期 结合上面的概念，这里有一张图比较好的概括了整个 Docker 工作的生命周期（以及主要命令）。 安装配置 这里仅以 CentOS 安装 Docker CE 举例说明。详见 Docker 官方 CentOS 安装文档\n准备工作 系统要求 Docker CE 支持 64 位版本 CentOS 7，并且要求内核版本不低于 3.10。 CentOS 7 满足最低内核的要求，但由于内核版本比较低，部分功能（如 overlay2 存储层驱动）无法使用，并且部分功能可能不太稳定。\n 警告：切勿在没有配置 Docker YUM 源的情况下直接使用 yum 命令安装 Docker.\n 卸载旧版本 旧版本的 Docker 称为 docker 或者 docker-engine，使用以下命令卸载旧版本：\nsudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine  使用脚本安装（非生产环境） 对于个人测试，可以使用这个脚本自动化安装 Docker：\ncurl -fsSL get.docker.com -o get-docker.sh sh get-docker.sh  但是，需要注意， 这个脚本可能扰乱你的系统配置、安装及大量的（你可能用不到的）依赖，并且只能安装最新（可能未经充分测试的）版本的 Docker ， 所以不推荐在生产环境中使用。\n使用 yum 安装 安装依赖包：\nsudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2  添加 yum 软件源：\n# 中国科学技术大学开源软件镜像源 sudo yum-config-manager \\ --add-repo \\ https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo # 官方源 # sudo yum-config-manager \\ # --add-repo \\ # https://download.docker.com/linux/centos/docker-ce.repo  更新 yum 软件源缓存，并安装 docker-ce。\nsudo yum makecache fast sudo yum install docker-ce  离线安装 以 docker-ce-18.03.1 为例：\n 在 https://download.docker.com/linux/centos/7/x86_64/stable/Packages/ 这里找到对应 rpm 包 执行安装命令：rpm -ivh docker-ce-18.03.1.ce-1.el7.centos.x86_64.rpm 由于安装环境不同，可能会发现缺少一些相关依赖包（eg: libcgroup、libtool-ltdl、container-selinux）前往 https://pkgs.org/ 或 https://buildlogs.centos.org/ 下载对应依赖包，依次安装即可  启动 Docker CE sudo systemctl enable docker sudo systemctl start docker  建立 Docker 用户组 默认情况下，docker 命令需要 root 权限，为了避免每次输入命令都要加 sudo，可以将用户加入 docker 用户组：\nsudo groupadd docker sudo usermod -aG docker $USER  退出当前终端并重新登录，进行如下测试。\n测试 Docker 是否安装正确 执行\ndocker run hello-world  Docker 会从官方仓库下载 hello-world 镜像并启动，如果一切正常的话会看到类似如下提示：\nUnable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world ca4f61b1923c: Pull complete Digest: sha256:be0cd392e45be79ffeffa6b05338b98ebb16c87b255f48e297ec7f98e123905c Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026quot;hello-world\u0026quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://cloud.docker.com/ For more examples and ideas, visit: https://docs.docker.com/engine/userguide/  镜像加速 鉴于国内网络问题，建议使用 Docker 中国或者其他国内镜像源。\n修改（或新增）/etc/docker/daemon.json 文件，添加:\n{ \u0026quot;registry-mirrors\u0026quot;: [\u0026quot;https://registry.docker-cn.com\u0026quot;] }  之后重启 Docker 使配置生效。\n常用 Docker 操作 # 查看 docker 版本 docker version # 显示 docker 系统的信息 docker info # 日志信息 docker logs # 故障检查 service docker status # 启动关闭 docker sudo service docker start|stop  使用镜像 基本操作 以 redis 为例，我们从 Docker Hub 上获取官方镜像到本地：\ndocker pull redis  ps1： 由于 redis 是官方源（Official），否则应该写完整的两段式仓库名 \u0026lt;用户名\u0026gt;/\u0026lt; 软件名 \u0026gt;，例如 bitnami/redis。\nps2： 此处没有指定镜像版本，默认会拉取 redis:lastest 镜像，指定版本应该写成例如：redis:5.0-rc5\n查看已经下载的镜像：\ndocker image ls # 会有类似如下显示 REPOSITORY TAG IMAGE ID CREATED SIZE redis latest 5f515359c7f8 5 days ago 183 MB ......  更细节的显示可以使用 docker image ls --format \u0026quot;{{.ID}}: {{.Repository}}\u0026quot; 直接列出镜像 ID 和仓库名,\n或者使用 docker image ls --format \u0026quot;table {{.ID}}\\t{{.Repository}}\\t{{.Tag}}\u0026quot; 以表格等距显示.\n如果要删除某个镜像的话，可以使用 docker image rm {IMAGE ID}|{REPOSITORY} 命令，不要过先确保没有容器在使用这个镜像。\nDockerfile 除了引用制作好的镜像，我们也可以基于现有镜像定制新的镜像。定制所用的脚本文件就是 Dockerfile。\nDockerfile 是一个文本文件，其内包含了一条条的 指令 (Instruction) ，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。\n我们新建一个空白文件，命名为 dockerfile，再文件中写入如下内容：\nFROM redis RUN mkdir redis WORKDIR redis COPY ./redis.conf /etc/ CMD [\u0026quot;redis-server\u0026quot;, \u0026quot;/etc/redis.conf\u0026quot;]  我们依次解释上面每一行：\n FROM 就是指定 基础镜像 , 一个 Dockerfile 中 FROM 是必备的指令，并且必须是第一条指令。如果不以任何镜像为基础，那应该用 FROM scratch 作为起始指令。 RUN 是 Dockerfile 的核心指令，用于执行一条命令，由于 Dockerfile 每一条指令都会新建一层，所以应该尽量将执行的内容写在一行（多行内容可以通过在末尾加 \\ 以表示未结束），它有两种写法：  shell 格式：RUN \u0026lt;命令\u0026gt;，就像直接在命令行中输入的命令一样。 exec 格式：RUN [\u0026quot;可执行文件\u0026quot;, \u0026quot;参数 1\u0026quot;, \u0026quot;参数 2\u0026quot;]，这更像是函数调用中的格式。   WORKDIR 表示指定当前工作目录，相当于 cd 命令。 COPY 即复制文件到容器中，在这里是把 redis.conf 文件复制到容器的 /etc 目录下。 CMD 是启动程序的命令，写法和 RUN 相同，一般推荐使用 exec 格式。  常用 Docker 指令列表如下：\n   指令 含义 用法     FROM 指定基础镜像 FROM \u0026lt;基础镜像\u0026gt;   RUN 执行指令 RUN [\u0026quot;可执行文件\u0026quot;, \u0026quot;参数 1\u0026quot;, \u0026quot;参数 2\u0026quot;]   COPY 复制文件 COPY [\u0026quot;\u0026lt; 源路径 1\u0026gt;\u0026quot;,... \u0026quot;\u0026lt; 目标路径 \u0026gt;\u0026quot;]   ADD 更高级的复制文件 ADD \u0026quot;\u0026lt;压缩文件\u0026gt;\u0026quot;   CMD 容器启动命令 CMD [\u0026quot;可执行文件\u0026quot;, \u0026quot;参数 1\u0026quot;, \u0026quot;参数 2\u0026quot;...]   ENTRYPOINT 入口点 ENTRYPOINT [\u0026quot;可执行文件\u0026quot;, \u0026quot;参数 1\u0026quot;, \u0026quot;参数 2\u0026quot;]   ENV 设置环境变量 ENV \u0026lt;key1\u0026gt;=\u0026lt;value1\u0026gt; \u0026lt;key2\u0026gt;=\u0026lt;value2\u0026gt;...   ARG 构建参数 ARG \u0026lt;参数名\u0026gt;[=\u0026lt; 默认值 \u0026gt;]   VOLUME 定义匿名卷 VOLUME [\u0026quot;\u0026lt; 路径 1\u0026gt;\u0026quot;, \u0026quot;\u0026lt; 路径 2\u0026gt;\u0026quot;...]   EXPOSE 暴露端口 EXPOSE \u0026lt;端口 1\u0026gt; [\u0026lt; 端口 2\u0026gt;...]   WORKDIR 指定工作目录 WORKDIR \u0026lt;工作目录路径\u0026gt;   USER 指定当前用户 USER \u0026lt;用户名\u0026gt;   HEALTHCHECK 健康检查 `HEALTHCHECK NONE   ONBUILD 构建下级镜像 ONBUILD \u0026lt;其它指令\u0026gt;   MAINTAINER 指定作者 ONBUILD \u0026lt;作者\u0026gt;    更多指令及用法请参照 官方文档\n如上，我们完成了一个使用自己配置文件的 redis 镜像的准备工作，之后依据这个 Dockerfile 进行构建：\ndocker build -t redis_test:v0.1 . # 会有类似如下输出： Sending build context to Docker daemon 2.048 kB Step 1 : FROM redis ... ... Removing intermediate container 9cdc27646c7b Successfully built 44aa4490ce2c  docker build 的用法为：\ndocker build [选项] \u0026lt; 上下文路径 / URL/-\u0026gt;  最后，可以使用 docker push 将你自己构建的镜像上传到仓库中，详细用法见 官方文档 push\n容器操作 容器启停 我们可以用这样的方式从之前的镜像启动一个容器：\ndocker run -d --name some-redis redis  docker run 的用法为 docker run [选项] 镜像 [命令] [参数...]，其中：\n--name 指定容器的名称， -d 指定后台运行，其他常用参数包括 -i 交互式操作，-t 使用终端（it 一般同时使用），--rm 容器退出后随之将其删除，完整参数列表可以通过 --help 或者 在线文档 docker run 查看\n由于我们是在后台运行，使用 docker container ls 来查看容器相关情况，如果要查看停止的进程，后面需要增加参数 -a：\ndocker container ls # 会看到类似如下内容 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 77b2dc01fe0f redis:v2 redis-server redis.conf 'while tr 2 minutes ago Up 1 minute agitated_wright  使用 docker container stop 来结束容器的运行：\ndocker container stop 77b2dc01fe0f  类似的，使用 docker container start | restart | stop 可以控制容器的启停， 使用 docker container rm 来删除指定容器。\n数据管理 之前提到过，随着容器的销毁，容器内的数据也会一同丢失。为了保存数据，Docker 提供了两种方式（还有一种 tmpfs mountsb 不常用到）：\n方式 1：数据卷（推荐） 数据卷 volume 是一个可供一个或多个容器使用的特殊目录，它不依赖于 Unix 文件系统，也拥有独立于容器的生命周期。\n创建一个数据卷:\ndocker volume create my-vol  查看数据卷及具体信息：\n# 查看所有的数据卷 docker volume ls # 会看到类似如下内容 local my-vol # ----------------------------------- # 查看具体卷的信息 docker volume inspect my-vol # 会看到类似如下内容 [ { \u0026quot;Driver\u0026quot;: \u0026quot;local\u0026quot;, \u0026quot;Labels\u0026quot;: {}, \u0026quot;Mountpoint\u0026quot;: \u0026quot;/var/lib/docker/volumes/my-vol/_data\u0026quot;, \u0026quot;Name\u0026quot;: \u0026quot;my-vol\u0026quot;, \u0026quot;Options\u0026quot;: {}, \u0026quot;Scope\u0026quot;: \u0026quot;local\u0026quot; } ]  在用 docker run 的时候，增加 --mount 参数来使用数据卷, 还是以启动 redis 为例，这里我们启动 redis 并且开启 aof 持久化：\ndocker run -d \\ --name redis \\ --mount source=my-vol,target=/data \\ # -v my-vol:/data \\ redis \\ redis-server --appendonly yes  在这里 redis 产生的数据（/data 目录下）被挂载到数据卷 my-vol 中。\n我们也可以使用 -v 或者 --volume 语法，但是 官方建议 尽量使用 --mount。\n同样使用 inspect 语法，我们可以查看 redis 容器的信息：\ndocker inspect redis # 会看到类似如下内容 \u0026quot;Mounts\u0026quot;: [ { \u0026quot;Type\u0026quot;: \u0026quot;volume\u0026quot;, \u0026quot;Name\u0026quot;: \u0026quot;my-vol\u0026quot;, \u0026quot;Source\u0026quot;: \u0026quot;/var/lib/docker/volumes/my-vol/_data\u0026quot;, \u0026quot;Destination\u0026quot;: \u0026quot;/data\u0026quot;, \u0026quot;Driver\u0026quot;: \u0026quot;local\u0026quot;, \u0026quot;Mode\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;RW\u0026quot;: true, \u0026quot;Propagation\u0026quot;: \u0026quot;\u0026quot; } ],  方式 2：绑定主机目录 我们也可以直接将容器的数据挂载 bind mount 到宿主机的目录或文件 （而非由 Docker 创建的数据卷）, 以当前目录 $(pwd) 为例：\ndocker run -d \\ --name redis \\ --mount type=bind,source=\u0026quot;$(pwd)\u0026quot;/target,target=/data \\ redis \\ redis-server --appendonly yes  挂载单独文件的方法类似。\n需要注意，本地目录必须存在，否则会报错。\n区别 Volumes 是由 Docker 创建和管理，存储在宿主机固定位置（在 linux 上是 / var/lib/docker/volumes/）。 非 Docker 应用程序不能改动这一位置的数据。 一个数据卷可以同时被挂载到几个容器中。即使没有正在运行的容器使用这个数据卷，它依然不会清除。可以通过 docker volume prune 清除不再使用的数据卷。\nBind mounts 的数据可以存放在宿主机的任何地方。 非 Docker 应用程序可以改变这些数据。\n使用网络 端口映射 docker run 的时候使用 -P(\u0026ndash;publish-all) 参数，随机映射一个 49000~49900 的端口到内部容器开放的网络端口。\n或者使用 -p ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort(\u0026ndash;publish) 来指定具体端口映射：\ndocker run -d \\ --name some-redis \\ -p 6379:6379 \\ -p 127.0.0.1::16379/udp -p 127.0.0.1:80:80 redis  这里我们分别将容器的 6379 端口映射到宿主机 任意 ip 的 6379 端口 ，容器的 16379 udp 端口映射到宿主机的 任意端口 ，容器的 80 端口映射到宿主机 对应的 80 端口 。\n使用 docker port 可以查看对应容器的全部端口映射。\n容器互联 简单的容器互联可以通过 --link 实现，但是 官方未来可能会删除这个参数 ，所以不展开。\n最新的方式是搭建 docker 网络实现容器互联，先创建一个新的 Docker 网络：\ndocker network create -d bridge my-net  这里的 -d 参数指定网络类型，常用的只有 bridge，其他的可能会在 Swarm 用到, 如果不知道 Swarm 是什么就不用在意。\n以 redis 客户端 / 服务端为例，分别在启动的时候将之加入 my-net 网络：\ndocker run -d \\ --name redis-server \\ --network my-net \\ redis docker run -it \\ --rm \\ --name redis-client \\ --network my-net \\ redis redis-cli -h redis-server  可以看到成功进入 redis-cli 客户端，我们可以尝试 info/keys * 或者其他命令查看 redis 服务端运行情况。\n延申 容器编排 面临一组容器配合使用的情况，例如一个包括负载均衡——网站后台——数据库的 Web 系统，我们可以使用 Docker 提供的 Compose 完成统一配置管理。它将提供相同功能的容器定义为服务 service——以方便复用；将完整的容器组合组成项目 project 以方便统一管理。所有的配置通过一个 yml 文件即可实现。\nNvidia Docker 对使用 GPU 的容器，Docker 提供 Nvidia Docker 以发挥 GPU 的运算性能。\n基本要求如下：\n GNU/Linux x86_64 with kernel version \u0026gt; 3.10 Docker \u0026gt;= 1.12 NVIDIA GPU with Architecture \u0026gt; Fermi (2.1) NVIDIA drivers ~= 361.93 (untested on older versions)  详细安装使用见 官方项目 Wiki\n","date":1544019442,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544019442,"objectID":"2a21c6713191c46e684013e469dfa8c0","permalink":"https://szthanatos.github.io/topic/docker/basis/","publishdate":"2018-12-05T22:17:22+08:00","relpermalink":"/topic/docker/basis/","section":"topic","summary":"Docker 简介 什么是 Docker Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公","tags":null,"title":"Docker -01- 基本概念","type":"book"},{"authors":null,"categories":null,"content":"","date":1544061966,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544061966,"objectID":"1f86e46c235768ad9250f893cd0dedeb","permalink":"https://szthanatos.github.io/topic/docker/ecology/","publishdate":"2018-12-06T10:06:06+08:00","relpermalink":"/topic/docker/ecology/","section":"topic","summary":"","tags":null,"title":"Docker -02- 进阶生态","type":"book"},{"authors":null,"categories":null,"content":"什么是 WSL  适用于 Linux 的 Windows 子系统可让开发人员按原样运行 GNU/Linux 环境 - 包括大多数命令行工具、实用工具和应用程序 - 且不会产生传统虚拟机或双启动设置开销。\n 然而现在出的 WSL2 是基于 Hyper-V 虚拟机的\u0026hellip;\n什么是 WSL 2  WSL 2 是适用于 Linux 的 Windows 子系统体系结构的一个新版本，它支持适用于 Linux 的 Windows 子系统在 Windows 上运行 ELF64 Linux 二进制文件。 它的主要目标是提高文件系统性能，以及添加完全的系统调用兼容性。\n wsl1 其实感觉速度更快，和 windows 共享网络，而且没有文件系统的限制。\n然而 wsl1 不是完整 Linux 内核，不支持 Docker。如果你只是要一个 Linux 环境可以考虑使用 wsl1 。\n安装 启用 Windows-Subsystem-Linux 在 控制面板-程序- 启用或关闭 Windows 功能 中勾选 适用于 Linux 的 Windows 子系统 以及 虚拟机平台(wsl2 需要)\n或者通过命令行（管理员身份）执行：\n# 适用于 Linux 的 Windows 子系统 dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart # 虚拟机平台 dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart  完成后需要重启电脑。\n更新内核 目前版本的 Win10 需要手动更新 WSL2 内核，前往 下载适用于 x64 计算机的最新 WSL2 Linux 内核 下载 msi 文件手动更新。\nARM 平台前往 下载适用于 ARM64 计算机的最新 WSL2 Linux 内核\n设置 wsl 默认版本 通过命令行（管理员身份）执行：\nwsl --set-default-version 2  让未来的 Linux 都默认以 WSL2 形式安装。\n现有 WSL 虚拟机也可以通过：\n# 获取现有 wsl 版本信息 wsl --list --verbose # 将现有发行版转化为制定版本 wsl --set-version \u0026lt;distribution name\u0026gt; \u0026lt;versionNumber\u0026gt;  升级到 WSL2 。\n安装 Linux 系统 打开 Microsoft Store，搜索 wsl 即可获取可用 Linux 发行版。\n现在支持的发行版有：\n Ubuntu 16.04 LTS Ubuntu 18.04 LTS Ubuntu 20.04 LTS openSUSE Leap 15.1 SUSE Linux Enterprise Server 12 SP5 SUSE Linux Enterprise Server 15 SP1 Kali Linux Debian GNU/Linux Fedora Remix for WSL Pengwin Pengwin Enterprise Alpine WSL  下载完成后，点击图标进入，首次使用会需要几分钟执行安装。\n完成安装后，设置 Ubuntu 用户名（非 root）及密码，正式开启 Ubuntu 系统。\n移动安装位置（可选） 目前 WSL 不支持设置安装路径，使用一段时间后体积会膨胀到 10G+ ，可以通过开源工具 LxRunOffline 实现将 Linux 安装到任意位置，或者将现有 Linux 子系统移动到任意位置。\n安装 LxRunOffline Scoop 是一个 Window 命令行包管理器，可以提供类似 apt/yum 的体验。\n通过 Scoop 安装 LxRunOffline 方法如下：\n# 在 Powershell 中执行 set-executionpolicy remotesigned -scope currentuser iex (new-object net.webclient).downloadstring('https://get.scoop.sh') scoop bucket add extras scoop install lxrunoffline  或者你可以直接下载安装二进制文件，之后运行 regsvr32 LxRunOfflineShellExt.dll 完成。\n移动 # 在 Powershell 中执行 # 查看所有已安装的发行版 lxrunoffline gd # 移动已存在发行版， 路径格式类似于 D:\\wsl\\Ubuntu-18.04 LxRunOffline m -n \u0026lt;发行版名称\u0026gt; -d \u0026lt; 路径 \u0026gt; # 等待一段时间完成移动，查看发行版当前位置 LxRunOffline di -n \u0026lt;发行版名称\u0026gt;  常用操作 wsl 命令  wsl --shutdown 立即终止所有正在运行的分发和 WSL 2 轻型工具虚拟机 wsl -t \u0026lt;分发版\u0026gt; 终止指定的发行版 wsl -l -v 列出分发版及其版本信息 wsl --export \u0026lt;分发版\u0026gt; \u0026lt; 文件名 \u0026gt; 将分发导出到 tar 文件 wsl --import \u0026lt;分发版\u0026gt; \u0026lt; 安装位置 \u0026gt; \u0026lt; 文件名 \u0026gt; [选项] 将指定的 tar 文件作为新分发进行导入  注意，导入导出发行版会导致无法从 Microsoft 应用管理中管理或更新。\n网络 WSL2 相当于独立虚拟机，而 WSL1 是和 Windows 复用同一个网络的。\n然后和一般宿主机虚拟机略微相反，从 Windows 可以通过 localhost 访问 WSL 上的服务，反之则不行。\n想要访问 Windows 上的服务，可以使用命令\nip route | grep default | awk '{print $3}'  或者查询 /etc/resolv.conf 中的 nameserver 获取到 Windows 宿主机的 ip，\n然后通过 ip 访问。\n文件系统 WSL1 的时候，文件目录位于\n Ubuntu: %localappdata%\\Packages\\CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc\\LocalState\\rootfs Ubuntu18.04: %localappdata%\\Packages\\CanonicalGroupLimited.Ubuntu18.04onWindows_79rhkp1fndgsc\\LocalState\\rootfs  WSL2 可以直接通过 \\\\wsl$ 在文件管理器中查看到网络位置上的 WSL 虚拟机，Ubuntu 就是 \\\\wsl$\\Ubuntu。\n或者你可以从 WSL2 中直接打开当前目录，直接在终端里调用 explorer.exe . 就行了，非常 cool~\nWindows 的磁盘在 WSL 中都表示为 /mnt/c|d|e...，可以看，但是操作还是尽量拷贝到 WSL 目录下，因为性能损失巨大。\nGPU 差不多能用：\n 在 WSL 2 中启用 NVIDIA CUDA CUDA on Windows Subsystem for Linux (WSL) - Public Preview  参考文档  WSL 文档 WSL 2 常见问题解答  ","date":1598067425,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1598067425,"objectID":"10c875a2c6598d312282e385a0b11558","permalink":"https://szthanatos.github.io/topic/wsl2/coding_with_wsl2_01/","publishdate":"2020-08-22T11:37:05+08:00","relpermalink":"/topic/wsl2/coding_with_wsl2_01/","section":"topic","summary":"什么是 WSL 适用于 Linux 的 Windows 子系统可让开发人员按原样运行 GNU/Linux 环境 - 包括","tags":null,"title":"开启 WSL2 安装 Ubuntu","type":"book"},{"authors":null,"categories":null,"content":"环境说明    当前版本 发布日期 下载地址     2.0 2018-07-30 官方 2.0.0 镜像    安装步骤 _** 注意：** 文中以 {} 包裹起来的内容需要自己替换，并非直接使用_\n0. 环境准备    基础环境 说明     Java Java 版本应该在 8(jdk1.8) 或以上，以更好的支持 G1 回收   硬件参数 CPU: 英特尔至强 E5-2650 v4 2 (共计 24 核) Mem: DDR4 内存 - 32GB 8 Sto: 2000GB * 8 raid 0   文件路径 /home/tools/kafka_2.11-2.0.0/   数据存放位置 /home/sdb/kafka-logs,/home/sdc/kafka-logs, /home/sdd/kafka-logs,/home/sde/kafka-logs, /home/sdf/kafka-logs,/home/sdg/kafka-logs, /home/sdh/kafka-logs,/home/sdi/kafka-logs   zookeeper 集群位置 10.10.20.83:2181,10.10.20.84:2181,10.10.20.85:2181    1. 下载安装 下载最新版本 Kafka，解压到指定目录，无需其他操作即完成安装。\ntar -xzf kafka_2.11-2.0.0.tgz -C /home/tools cd kafka_2.11-2.0.0  2. 配置集群参数 修改 config/server.properties\n基本参数如下：\n# broker 唯一 id，值为不重复正整数 broker.id={n: int} # 服务监听地址 listeners=PLAINTEXT://{your.host}:9092 # 日志存放位置列表，以逗号隔开 log.dirs={data.storage.list} # zookeeper 地址列表，以逗号隔开 zookeeper.connect={zookeeper.server.list}  优化参数配置如下：\n# 消息处理线程数，建议数量为 cpu 核数加 1 num.network.threads=25 # 磁盘 IO 的线程数, 建议为 cpu 核数 2 倍，最大不超过 3 倍 num.io.threads=48 # 拉取线程数，影响 follower 的 I/O 并发度，单位时间内 leader 持有更多请求，相应负载会增大 num.replica.fetchers=2 # 分区数量配置，根据业务情况修改 num.partitions=16 # 消息日志备份数，默认是 1 default.replication.factor=2 # 刷盘 (写入文件到磁盘) 间隔消息数，建议设为 10000 log.flush.interval.messages=10000 # 刷盘间隔毫秒数，建议 1 秒 (1000) log.flush.interval.ms=1000 # 日志保留小时数 log.retention.hours=48 # 段文件大小，过小会产生很多小文件降低性能，过大会影响快速回收磁盘空间以及 Kafka 重启后的载入速度 og.segment.bytes=1073741824 # 最大字节数，默认 1M，可以调到 5M 以上 replica.fetch.max.bytes=5242880 # 可接受数据大小，受限于 java int 类型的取值范围, 超出后会报 OOM 异常 socket.request.max.bytes=2147483600 # 日志传输时候的压缩格式，可选择 lz4, snappy, gzip, 不压缩。建议打开压缩，可以提高传输性能 compression.type=snappy # 是否允许通过管理工具删除 topic，默认是 false delete.topic.enable=true # 是否允许程序自动创建 Topic auto.create.topics.enable=false  3. 配置日志参数 修改 config/log4j.properties 的 jog4j 参数，提高 Kafka 操作日志（和数据日志区分）的日志级别，以降低日志输出相关资源占用。具体可更改配置如下：\n# Kafka2.0 默认只有 controller 是 TRACE 级别，可以改为 INFO，其他 INFO 级别可以适当提升为 WARN # zookeeper 日志级别， log4j.logger.org.I0Itec.zkclient.ZkClient=INFO log4j.logger.org.apache.zookeeper=INFO # 主日志级别 log4j.logger.kafka=INFO log4j.logger.org.apache.kafka=INFO # request 日志级别，只有当需要调试时才有必要输出 log4j.logger.kafka.request.logger=WARN, requestAppender log4j.additivity.kafka.request.logger=false # 需要调试时解除以下三行注释，并将 RequestChannel$ 设为 TRACE # log4j.logger.kafka.network.Processor=TRACE, requestAppender # log4j.logger.kafka.server.KafkaApis=TRACE, requestAppender # log4j.additivity.kafka.server.KafkaApis=false log4j.logger.kafka.network.RequestChannel$=WARN, requestAppender log4j.additivity.kafka.network.RequestChannel$=false # controller 日志级别，默认为 TRACE log4j.logger.kafka.controller=INFO, controllerAppender log4j.additivity.kafka.controller=false # 日志清理的日志级别 log4j.logger.kafka.log.LogCleaner=INFO, cleanerAppender log4j.additivity.kafka.log.LogCleaner=false log4j.logger.state.change.logger=TRACE, stateChangeAppender log4j.additivity.state.change.logger=false # 登陆认证的日志级别 log4j.logger.kafka.authorizer.logger=INFO, authorizerAppender log4j.additivity.kafka.authorizer.logger=false  4. 配置 JVM 参数 Warning：谨慎调试\n在 bin/kafka-server-start.sh 文件中调整参数如下：\n# 在 base_dir 之后配置参数 base_dir=$(dirname $0) export KAFKA_HEAP_OPTS=\u0026quot;-Xms6g -Xmx6g -XX:MetaspaceSize=96m -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80\u0026quot;  ps： 虽然看起来很激进，但是以上配置参照的是 LinkIn 高峰时期最繁忙的集群:\n60 brokers 50k partitions (replication factor 2) 800k messages/sec in 300 MB/sec inbound, 1 GB/sec+ outbound  ps2： 这个配置的集群实现了 90% 的 GC 中断时间不超过 21 毫秒，每秒钟新生代 GC 次数不超过一次\nps3： 上述环境的 Java 版本为 JDK 1.8 u5\n5. 配置 Linux 参数 Warning：谨慎调试\n# 调整系统所有进程一共可以打开的最大文件数： echo 'fs.file-max = 1024000' \u0026gt;\u0026gt; /etc/sysctl.conf  以及 /etc/security/limits.conf 末尾增加：\n# 设置当前 user 以及由它启动的进程的资源限制 {user} soft nofile 1024000 {user} hard nofile 1024000  增大 socket buffer size，以提高吞吐性能\necho 212992 \u0026gt;\u0026gt; /proc/sys/net/core/wmem_max echo 212992 \u0026gt;\u0026gt; /proc/sys/net/core/rmem_max  Kafka2.0 官方安装指南 Quick Start\n","date":1544062186,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544062186,"objectID":"8906f5bc4c52e993b12567b4405f72b6","permalink":"https://szthanatos.github.io/topic/kafka/install/","publishdate":"2018-12-06T10:09:46+08:00","relpermalink":"/topic/kafka/install/","section":"topic","summary":"环境说明 当前版本 发布日期 下载地址 2.0 2018-07-30 官方 2.0.0 镜像 安装步骤 _** 注意","tags":null,"title":"Kafka -01- 安装配置","type":"book"},{"authors":null,"categories":null,"content":"介绍就两个字，颜值。\n安装方式同样是 Microsoft Store。\n默认可以使用 win+r 输入 wt 呼出。\n个人使用配置如下，版本号 1.1.2233.0\n{ // 默认打开 Ubuntu \u0026quot;defaultProfile\u0026quot;: \u0026quot;{2c4de342-38b7-51cf-b940-2309a097f518}\u0026quot;, \u0026quot;copyOnSelect\u0026quot;: false, \u0026quot;copyFormatting\u0026quot;: false, \u0026quot;theme\u0026quot;: \u0026quot;dark\u0026quot;, \u0026quot;profiles\u0026quot;: { \u0026quot;defaults\u0026quot;: { // 开启毛玻璃 (模糊) 效果 \u0026quot;useAcrylic\u0026quot;: true, // 模糊系数 0(透明)-\u0026gt;1(不透明) \u0026quot;acrylicOpacity\u0026quot;: 0.75, // zsh Powerlevel10k 所用到的字体，详见 shell 配置章节 \u0026quot;fontFace\u0026quot;: \u0026quot;MesloLGS NF\u0026quot;, // 必须显式设置字体大小，不然初次显示会不正常 \u0026quot;fontSize\u0026quot;: 12, // 光标形状 \u0026quot;cursorShape\u0026quot;:\u0026quot;filledBox\u0026quot; }, \u0026quot;list\u0026quot;: [ // ... { // 自己写的一个配色文件 \u0026quot;colorScheme\u0026quot;: \u0026quot;Sz-dark-material\u0026quot;, \u0026quot;guid\u0026quot;: \u0026quot;{2c4de342-38b7-51cf-b940-2309a097f518}\u0026quot;, \u0026quot;hidden\u0026quot;: false, \u0026quot;name\u0026quot;: \u0026quot;Ubuntu\u0026quot;, \u0026quot;source\u0026quot;: \u0026quot;Windows.Terminal.Wsl\u0026quot;, // 将起始位置改为用户根目录 \u0026quot;startingDirectory\u0026quot;: \u0026quot;//wsl$/Ubuntu/home/sz/\u0026quot; }, // ... ] }, \u0026quot;schemes\u0026quot;: [ { // 仿 Solarized Dark 的一个配色 \u0026quot;background\u0026quot;: \u0026quot;#002B36\u0026quot;, \u0026quot;black\u0026quot;: \u0026quot;#2C3E50\u0026quot;, \u0026quot;blue\u0026quot;: \u0026quot;#396FE2\u0026quot;, \u0026quot;brightBlack\u0026quot;: \u0026quot;#34495E\u0026quot;, \u0026quot;brightBlue\u0026quot;: \u0026quot;#82AAFF\u0026quot;, \u0026quot;brightCyan\u0026quot;: \u0026quot;#89DDFF\u0026quot;, \u0026quot;brightGreen\u0026quot;: \u0026quot;#C3E88D\u0026quot;, \u0026quot;brightPurple\u0026quot;: \u0026quot;#C792EA\u0026quot;, \u0026quot;brightRed\u0026quot;: \u0026quot;#FF5370\u0026quot;, \u0026quot;brightWhite\u0026quot;: \u0026quot;#FFFFFF\u0026quot;, \u0026quot;brightYellow\u0026quot;: \u0026quot;#FFCB6B\u0026quot;, \u0026quot;cyan\u0026quot;: \u0026quot;#2DDAFD\u0026quot;, \u0026quot;foreground\u0026quot;: \u0026quot;#ECEFF1\u0026quot;, \u0026quot;green\u0026quot;: \u0026quot;#9ECE58\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;Sz-material\u0026quot;, \u0026quot;purple\u0026quot;: \u0026quot;#BB80B3\u0026quot;, \u0026quot;red\u0026quot;: \u0026quot;#E54B4B\u0026quot;, \u0026quot;white\u0026quot;: \u0026quot;#D0D0D0\u0026quot;, \u0026quot;yellow\u0026quot;: \u0026quot;#FAED70\u0026quot; }, { // Solarized + Campbell \u0026quot;background\u0026quot;: \u0026quot;#0C0C0C\u0026quot;, \u0026quot;black\u0026quot;: \u0026quot;#2C3E50\u0026quot;, \u0026quot;blue\u0026quot;: \u0026quot;#396FE2\u0026quot;, \u0026quot;brightBlack\u0026quot;: \u0026quot;#767676\u0026quot;, \u0026quot;brightBlue\u0026quot;: \u0026quot;#82AAFF\u0026quot;, \u0026quot;brightCyan\u0026quot;: \u0026quot;#89DDFF\u0026quot;, \u0026quot;brightGreen\u0026quot;: \u0026quot;#C3E88D\u0026quot;, \u0026quot;brightPurple\u0026quot;: \u0026quot;#C792EA\u0026quot;, \u0026quot;brightRed\u0026quot;: \u0026quot;#FF5370\u0026quot;, \u0026quot;brightWhite\u0026quot;: \u0026quot;#FFFFFF\u0026quot;, \u0026quot;brightYellow\u0026quot;: \u0026quot;#FFCB6B\u0026quot;, \u0026quot;cyan\u0026quot;: \u0026quot;#2DDAFD\u0026quot;, \u0026quot;foreground\u0026quot;: \u0026quot;#ECEFF1\u0026quot;, \u0026quot;green\u0026quot;: \u0026quot;#9ECE58\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;Sz-dark-material\u0026quot;, \u0026quot;purple\u0026quot;: \u0026quot;#BB80B3\u0026quot;, \u0026quot;red\u0026quot;: \u0026quot;#E54B4B\u0026quot;, \u0026quot;white\u0026quot;: \u0026quot;#D0D0D0\u0026quot;, \u0026quot;yellow\u0026quot;: \u0026quot;#FAED70\u0026quot; } ], // ... }  其他设置详见 官方文档\n","date":1598085661,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1598085661,"objectID":"af0d171ff53b4c524fed70c10cc59708","permalink":"https://szthanatos.github.io/topic/wsl2/coding_with_wsl2_02/","publishdate":"2020-08-22T16:41:01+08:00","relpermalink":"/topic/wsl2/coding_with_wsl2_02/","section":"topic","summary":"介绍就两个字，颜值。 安装方式同样是 Microsoft Store。 默认可以使用","tags":null,"title":"使用 Windows-Terminal 作为终端","type":"book"},{"authors":null,"categories":null,"content":"环境说明     版本号 发布日期     当前版本 0.11.0.1 2017-09-14   最新版本 2.0 2018-07-30    配置文件路径：\n /home/tools/kafka_2.12-0.11.0.1/config/\n 目标需求： 在 Kafka 集群不停机不停止服务的情况下进行升级改造。\n可能存在的风险 轻微警报  consumer 可能出现偏移量提交失败而造成重复消费 broker 提示\u0026rsquo;NotLeaderForPartitionException\u0026rsquo;异常 由于节点下线，可能造成临时性能问题  严重警报 严格按照步骤升级，暂未捕捉到严重问题相关信息\n升级步骤（滚动升级）   限定通讯协议版本：\n配置 broker 上的 server.properties 文件：\ninter.broker.protocol.version = 0.11.0    依次更新代码并重启 borker：\n一次关闭一个 broker，更新源码，重启\n  更新通讯协议版本：\n完成所有 broker 节点的源码更新后, 升级协议（方法同上）：\ninter.broker.protocol.version = 2.0    再次依次重启 broker：\n同上，一次重启一个\n  ps： 如果修改过消息格式版本 (log.message.format.version)，则需要在上面步骤中，同步配置：\nlog.message.format.version = 当前版本 / 要升级的版本  替代方案（离线升级） 关闭所有 broker，更新代码并重新启动。默认情况下，自动以新协议开始。\nKafka2.0 官方升级指南 upgrade\n","date":1544339992,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544339992,"objectID":"526c33a705e30098d5aac5e54a4db62c","permalink":"https://szthanatos.github.io/topic/kafka/update/","publishdate":"2018-12-09T15:19:52+08:00","relpermalink":"/topic/kafka/update/","section":"topic","summary":"环境说明 版本号 发布日期 当前版本 0.11.0.1 2017-09-14 最新版本 2.0 2018-07-30 配置文件路径：","tags":null,"title":"Kafka -02- 滚动升级","type":"book"},{"authors":null,"categories":null,"content":"集群信息 节点信息 集群节点相关信息可以通过 cluster nodes 命令获取：\n127.0.0.1:6379\u0026gt; cluster nodes 5022fa41642195d74200fd512c08653dc12609e7 172.17.0.2:6380@16380 master - 0 1552814467000 2 connected 5461-10922 730d05ee4da3147d0885c6d47437465c94409f74 172.17.0.2:6383@16383 slave 25a2a1d8c96e9473d4cb3c8b0077d3b7b07dd5c0 0 1552814468555 5 connected 25a2a1d8c96e9473d4cb3c8b0077d3b7b07dd5c0 172.17.0.2:6379@16379 myself,master - 0 1552814468000 1 connected 0-5460 cf0be45c6a05c0d332b7356a7f57de95b32c3a71 172.17.0.2:6384@16384 slave 5022fa41642195d74200fd512c08653dc12609e7 0 1552814468654 6 connected 55d264b148ce35903928964ac017d682fc803eab 172.17.0.2:6381@16381 master - 0 1552814468000 3 connected 10923-16383 1a60baf4c2254b2e3a37cf6215d42b316ffdccc7 172.17.0.2:6382@16382 slave 55d264b148ce35903928964ac017d682fc803eab 0 1552814468000 4 connected 127.0.0.1:6379\u0026gt;  可以看到，每一行即是一个节点的信息，以第一行为例，每个字段的含义分别是：\n   字段 含义     502\u0026hellip;\u0026hellip;9e7 node_id，节点标识   172.17.0.2:6380@16380 IP 端口   master 身份，一般就是 myself/master/slave，其他 fail?/handshake/noaddr/noflags   - 对应主节点的 node_id(如果你是从节点的话，否则就是 -)   0 0 表示没有待发送的 ping，否则是要发送 ping 的时间戳   1552814467000 收到上一个 pong 命令的时间戳   2 权重   connected 状态，connectedordisconnected   5461-10922 哈希槽，连续的哈希槽用 - 连接，离散的用 , 隔开    状态信息 集群信息通过 cluster info 获取：\n127.0.0.1:6379\u0026gt; cluster info # 集群状态 cluster_state:ok # 已分配的哈希槽数量，不是 16384 就有问题了 cluster_slots_assigned:16384 # 正确的哈希槽数量，如果有哈希槽分配到了离线的节点上就不是这个数字了 cluster_slots_ok:16384 # 临时错误哈希槽数，比如网络波动但节点还是正常的，那就是 pfail，节点确认离线了就是 fail cluster_slots_pfail:0 cluster_slots_fail:0 # 集群节点数 cluster_known_nodes:6 # 集群规模 cluster_size:3 # 当前最大权重 cluster_current_epoch:6 # 本节点的权重 cluster_my_epoch:1 # 集群建立至今发送 / 接受的 ping/pong/meet 消息数 cluster_stats_messages_ping_sent:1554 cluster_stats_messages_pong_sent:1558 cluster_stats_messages_sent:3112 cluster_stats_messages_ping_received:1553 cluster_stats_messages_pong_received:1554 cluster_stats_messages_meet_received:5 cluster_stats_messages_received:3112 127.0.0.1:6379\u0026gt;  集群操作 就不挨个详述了，写了个速查表如下，全部命令详见 redis 官方文档。\n   命令 含义     信息    cluster info 返回集群基本信息   cluster nodes 返回全部节点   控制    cluster count-failure-reports \u0026lt;node_id\u0026gt; 返回节点的错误报告数   cluster failover [FORCE/TAKEOVER] 在从节点上执行，测试故障转移   cluster set-config-epoch \u0026lt;config-epoch\u0026gt; 为新节点设置权重   cluster saveconfig 将节点的配置文件保存到硬盘里面   cluster reset [HARD/SOFT] 重置没有 key 的当前节点 (所以应该先 flushall)   cluster readonly 将从节点置为可读 (默认情况下，指向从节点的连接会被转向主节点)   cluster readwrite 将从节点置为读写 (相当于还原为 readonly 之前的状态)   节点    cluster meet \u0026lt;ip\u0026gt; \u0026lt;port\u0026gt; 将节点加入集群作为主节点   cluster replicate \u0026lt;node_id\u0026gt; 将当前节点作为 \u0026lt; node_id \u0026gt; 的从节点加入集群   cluster replicas \u0026lt;node_id\u0026gt; redis5.0 开始支持，列出指定主节点的从节点   cluster slaves \u0026lt;node_id\u0026gt; 不再建议被使用，基本同 replicas   cluster replicaof \u0026lt;ip\u0026gt; \u0026lt;port\u0026gt; redis5.0 开始支持，将当前节点置为指定节点的从节点   cluster slaveof \u0026lt;ip\u0026gt; \u0026lt;port\u0026gt; 不再建议被使用，基本同 replicaof   cluster forget \u0026lt;node_id\u0026gt; 从集群中移除 \u0026lt; node_id \u0026gt; 节点（前提是没给他分配哈希槽 / 内容）   哈希槽    cluster addslots \u0026lt;slot\u0026gt;,... 将一个或多个哈希槽添加到当前节点   cluster delslots \u0026lt;slot\u0026gt;,... 从当前节点移除哈希槽   cluster flushslots 清空当前节点的哈希槽   cluster setslot \u0026lt;slot\u0026gt; node \u0026lt;node_id\u0026gt; 将 未分配的 哈希槽分配给指定节点   cluster setslot \u0026lt;slot\u0026gt; migrating \u0026lt;node_id\u0026gt; 将本节点的哈希槽合并到指定节点   cluster setslot \u0026lt;slot\u0026gt; importing \u0026lt;node_id\u0026gt; 从指定节点引入哈希槽到本节点   cluster setslot \u0026lt;slot\u0026gt; stable 取消哈希槽的移动，主要是修复 redis-trib fix 引发的问题←_←   cluster flushslots 清空当前节点的哈希槽   cluster flushslots 清空当前节点的哈希槽   键    cluster keyslot \u0026lt;key\u0026gt; 计算 key 应该被放在哪个槽   cluster countkeysinslot \u0026lt;slot\u0026gt; 返回哈希槽中 key 的数量   cluster getkeysinslot \u0026lt;slot\u0026gt; \u0026lt;count\u0026gt; 从哈希槽中返回指定数量个 key     ps1：从 redis5.0 起，slave 关键字将被 replicate 取代，相关命令也会逐步被替代    ps2：readonly 这个额外说一下，默认情况下，redis 的从节点不处理客户端请求，只负责同步主节点的数据，设置 readonly 之后，指向从节点的读请求会被执行，这样相当于为主节点分担了读的压力 (也算是 scale 了)，但是还是存在两个限制：\n 写请求还是会转移给主节点； 要读的 key 的哈希槽不属于这个节点，请求一样会被转移；    ","date":1535635578,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1535635578,"objectID":"001d3bc6d74079a5349f806631d49ace","permalink":"https://szthanatos.github.io/topic/redis/02-usage/cluster_command/","publishdate":"2018-08-30T21:26:18+08:00","relpermalink":"/topic/redis/02-usage/cluster_command/","section":"topic","summary":"集群信息 节点信息 集群节点相关信息可以通过 cluster nodes 命令获取： 127.0.0.1:6379\u0026gt; cluster nodes","tags":null,"title":"Redis 集群相关命令","type":"book"},{"authors":null,"categories":null,"content":"启用 root 用户 ubuntu 默认没有 root 密码，使用\nsudo passwd root  设置 root 密码\n配置国内镜像源 更换 /etc/apt/sources.list 为:\n# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # 预发布软件源，不建议启用 # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse  以使用 清华大学镜像源\n注意我这里 Ubuntu 版本是 20.04(focal)。\n关于 Ubuntu 源：\n  按软件自由度区分：\n   源 说明     main 完全的自由软件   restricted 不完全的自由软件   universe ubuntu 官方不提供支持与补丁，全靠社区支持   muitiverse 非自由软件，完全不提供支持和补丁      按使用目的区分：\n   源 说明     security 仅修复漏洞，并且尽可能少的改变软件包的行为，低风险   update 修复严重但不影响系统安全运行的漏洞，低风险   proposed pre-update，仅建议提供测试和反馈的人进行安装   backports 不会由 Ubuntu-security-team 审查和更新 (但是可能对你有用)，存在风险      添加第三方源 (可选) # git sudo add-apt-repository ppa:git-core/ppa # python sudo add-apt-repository ppa:deadsnakes/ppa # 更新 sudo apt update  配置 ssh 修改 /etc/ssh/sshd_config 文件：\n# port 为大于 1024 的任意端口（不能是 22 是因为 WSL 和 win10 共用端口且 win10 的优先级更高，win10 内置 SSH Server For Windows 已经占用 22 端口, 大于 1024 是为了避开其他系统服务） Port 2333 # 允许使用用户名密码方式访问 PasswordAuthentication yes # (可选) 允许 root 访问 (任何认证方式 / 只允许 public key 认证方式 / 不允许任何认证方式) PermitRootLogin yes/without-password/no  保存，执行以下命令：\n# 生成密钥 dpkg-reconfigure openssh-server # 重启 ssh sudo service ssh restart  完成 ssh 配置。\n早期版本需要重装 openssh-server，但是最近直接使用没发现问题。\n开机自启后台服务 (可选) 在 Wsl 早期，想要使用 Wsl 上的 Python 解释器或者别的工具需要通过 ssh 从宿主机连接，而 Wsl 没有 Systemd 也没法开机自启。\n通过计划任务实现开机启动 Wsl 上的 ssh 服务是一种刚需。\n不过现在 Docker 也好，Pycharm 也好，都直接从软件层面支持 Wsl 了，需要 ssh 的场合不多（雾）。\n不过 * 2，网上存在的教程都告诉你要在 Ubuntu 写个 shell 脚本，再在 Windows 下写个 vb 脚本，再去创建一个计划任务\u0026hellip;.\n直接计划任务一句话搞定不香么？黑人问号. jpg\n还是以 ssh 服务为例：\n  root 身份编辑 /etc/sudoers 文件，\n在 %sudo ALL=(ALL:ALL) ALL 下新增一行\n%sudo ALL=(ALL) NOPASSWD: /usr/sbin/service ssh *\n避免 sudo 启动 ssh 需要密码的问题。\n  在 windows 搜索栏搜索 计划任务，或者快速运行窗口输入 taskschd.msc，打开任务计划程序\n  创建任务，勾选 隐藏，配置改为 win10\n触发器选 计算机启动时 或者 当前用户登录时，可以配置延迟启动;\n操作是 启动程序，程序或脚本选 C:\\Windows\\System32\\wsl.exe，添加参数写 -d Ubuntu -u {Ubuntu 用户名} sudo service ssh start；\n(可选) 条件中取消勾选 只有计算机在使用交流电时才启动此任务；\n(可选) 设置中勾选 允许按需允许任务；\n完成\n  其他需要后台启动的服务类似配置。\n","date":1598085663,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1598085663,"objectID":"cfbf4249bcab15700cacfd8c34718568","permalink":"https://szthanatos.github.io/topic/wsl2/coding_with_wsl2_03/","publishdate":"2020-08-22T16:41:03+08:00","relpermalink":"/topic/wsl2/coding_with_wsl2_03/","section":"topic","summary":"启用 root 用户 ubuntu 默认没有 root 密码，使用 sudo passwd root 设置 root 密码 配置国内镜像","tags":null,"title":"Ubuntu 易用性配置","type":"book"},{"authors":null,"categories":null,"content":" // TODO 吹一下 zsh\n 安装 zsh # 安装 zsh sudo apt install zsh -y # 修改默认 shell 为 zsh sudo chsh -s /bin/zsh  重启 wsl，或者干脆重启电脑生效。\n安装 oh-my-zsh sh -c \u0026quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\u0026quot;  可能需要代理。\n安装 zsh 插件 # 安装 powerlevel10k 主题 git clone --depth=1 https://github.com/romkatv/powerlevel10k.git $ZSH_CUSTOM/themes/powerlevel10k # 安装语法高亮 zsh-syntax-highlighting git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting # 安装自动建议 zsh-autosuggestions git clone git://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions  从 win10 下载并安装以下字体，以获得 powerlevel10k 主题更好的显示效果：\n MesloLGS NF Regular.ttf MesloLGS NF Bold.ttf MesloLGS NF Italic.ttf MesloLGS NF Bold Italic.ttf  配置 zsh 在 .zshrc 中编辑以下部分：\n# （可选）允许其他用户共用你的配置不弹出警告 ZSH_DISABLE_COMPFIX=\u0026quot;true\u0026quot; # 默认情况下，zsh 会试图在低优先级运行后台任务，但是 Windows 不允许，所以将以下内容添加到. zshrc 文件开头可以改变 zsh 的行为 case $(uname -a) in *Microsoft*) unsetopt BG_NICE ;; esac # 启用 powerlevel10k 主题 ZSH_THEME=\u0026quot;powerlevel10k/powerlevel10k\u0026quot; # 启用插件 plugins=( # 按 z+{模糊文件夹名称} 快速跳转 z # git 补全 git # 忘了加 sudo 的时候按两下 esc sudo # docker 补全 docker docker-compose # 按 x 解压任意类型压缩包 extract # 彩色 man 手册 colored-man-pages zsh-autosuggestions zsh-syntax-highlighting ) # 配置终端颜色 export TERM=\u0026quot;xterm-256color\u0026quot;  输入 source .zshrc 让配置生效，\n输入 p10k configure 配置 Powerlevel10k 主题设置。\n完成后，拷贝 .zshrc 和 .p10k.zsh 文件到 root 用户根目录下，让 root 也使用相同配置，当然也可以分别设置。\n一键启用 / 停用代理 Linux 下配置代理本来就略麻烦，Wsl2 又是完整的虚拟机，每次重启内部网络都会重新生成\u0026hellip; 换句话说每次 Windows 和 Linux 的内网 IP 都在变化\u0026hellip;\n不过还是能配置好的。\n将以下内容加入到你的 .zshrc 文件中，将 20809 改为你的代理的端口：\nproxyon() { local host_ip=$(cat /etc/resolv.conf |grep \u0026quot;nameserver\u0026quot; |cut -f 2 -d \u0026quot; \u0026quot;) export ALL_PROXY=\u0026quot;http://${host_ip}:20809\u0026quot; export all_proxy=\u0026quot;http://${host_ip}:20809\u0026quot; echo -e \u0026quot;Acquire::http::Proxy \\\u0026quot;http://${host_ip}:20809\\\u0026quot;;\u0026quot; | sudo tee -a /etc/apt/apt.conf \u0026gt; /dev/null echo -e \u0026quot;Acquire::https::Proxy \\\u0026quot;http://${host_ip}:20809\\\u0026quot;;\u0026quot; | sudo tee -a /etc/apt/apt.conf \u0026gt; /dev/null curl ip.sb } proxyoff() { unset ALL_PROXY unset all_proxy sudo sed -i -e '/Acquire::http::Proxy/d' /etc/apt/apt.conf sudo sed -i -e '/Acquire::https::Proxy/d' /etc/apt/apt.conf curl ip.sb }  执行 proxy 即可开启代理，wget，curl，git，apt 都会走代理。\n执行 unproxy 关闭。\n参考  Oh My ZSH 官网 powerlevel10k 项目主页  ","date":1598085665,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1598085665,"objectID":"877c5d52d4327f3732b0b4c0467dc2e3","permalink":"https://szthanatos.github.io/topic/wsl2/coding_with_wsl2_04/","publishdate":"2020-08-22T16:41:05+08:00","relpermalink":"/topic/wsl2/coding_with_wsl2_04/","section":"topic","summary":"// TODO 吹一下 zsh 安装 zsh # 安装 zsh sudo apt install zsh -y # 修改默认 shell 为 zsh sudo chsh -s /bin/zsh","tags":null,"title":"使用 Zsh 作为默认 shell","type":"book"},{"authors":null,"categories":null,"content":"版本    软件 版本 更新日期 备注     Redis 4.0.11 2018-08-03 必装   Ruby 2.5.1 2018-03-28 可选, 集群执行 rb 脚本的节点安装即可   rubygem 2.7.7 2018-05-18 同上   gem-redis 4.0.2 2018-08-13 同上    安装   以 CentOS 7 为例\n  从上述链接下载 redis 文件\n  安装环境依赖 yum install -y gcc gcc-c++ tcl\n  tar -xvzf {redis.tar.gz} 解压\n  进入 redis 目录，执行 make \u0026amp;\u0026amp; make install 进行安装\n如果 make 出错，通过 make test 检查：\n 尝试只用单核运行：taskset -c 1 sudo make test 更改 tests/integration/replication-psync.tcl 文件, 把对应报错的那段代码中的 after 100 改成 after 500    完成单节点安装\n  配置 默认配置文件为位于 redis 目录下的 redis.conf\n最小配置 一个最小的 redis.conf 配置如下：\n# 节点监听的端口号 port {your_port} # 是否以进程守护方式 (后台) 运行 daemonize yes # 允许访问的 IP 地址，设置为 0.0.0.0 的时候可以从任意 IP 访问 redis，多个 ip 用逗号隔开 bind {your_ip} # 工作目录，数据存放位置 dir {your_dir} # 进程文件名称，固定为 redis_监听的端口号. pid pidfile /var/run/redis_{your_port}.pid  完成以上配置即可启动单节点 redis。\n集群配置 集群需要在 redis.conf 中配置以下部分：\n# 以集群模式启动 cluster-enabled yes # 集群配置存放的文件名，一般为 node - 端口号. conf cluster-config-file nodes-{port}.conf # 集群超时 cluster-node-timeout 15000 # 是否启用 aof 方式持久化，建议开启 appendonly yes  启动 防火墙 redis 需要使用指定端口号以及指定端口号 + 10000 进行通讯，以 6379 端口为例，如果开启了防火墙，需要执行：\nfirewall-cmd --zone=public --add-port=6379/tcp --permanent firewall-cmd --zone=public --add-port=16379/tcp --permanent firewall-cmd --reload  单结点启动 执行\nredis-server {dir}/redis.conf  启动 redis\n集群启动 ruby 环境 redis 集群是通过 Ruby 编写的脚本进行联通的（但不需要在每隔节点都执行），所以集群中起码一个节点，应该具备 ruby 环境、rubygem 包管理软件、rubygem 中的 redis 包。\nruby 环境搭建过程如下：\n  yum 安装 ruby 环境及包\nyum -y install ruby ruby-devel rubygems    修改 ruby 源，使用国内镜像\ngem sources --add https://gems.ruby-china.org/ --remove https://rubygems.org/ # 如果修改失败将 https 换为 http 重试 gem sources --add http://gems.ruby-china.org/ --remove http://rubygems.org/    检查源列表，确保只有 gems.ruby-china.org\ngem sources -l    安装 ruby 的 redis 包：\ngem install redis    联通集群   启动所有节点上的 redis 服务\n  进入 redis 安装路径下 src 文件夹，执行集群命令：\n# --replicas 1 表示主从复制比例为 1:1，即一个主节点对应一个从节点 ./redis-trib.rb create --replicas 1 {node1_ip:port} {node2_ip:port} ...    默认会自动分配主从节点，确认的话输入 yes 完成集群的创建\n  检查集群状态 # -c 表示连接的是集群 redis-cli -c -h {ip} -p {port} # 查看集群节点 \u0026gt; cluster nodes # 查看集群信息 \u0026gt; cluster info  相关命令 除了使用 rb 脚本，其实可以直接在 redis 节点上 通过命令操作集群，个人更推荐这个做法。\n主要用到的是\n 谨慎使用 rb 脚本对 redis 进行修复，从来没修复成功过\u0026hellip;\n它还会把你的哈希槽按顺序平均分配到所有节点上，本来可能是 A 节点管理 0-6000，B 节点 6001-12000\u0026hellip;fix 完了之后就成了 A 节点：1，3，5，7\u0026hellip; 终端都被坑到无法阅读了。\n  附注 离线安装 redis 环境 离线情况需要本地下载如下 rpm 包 (版本号以最新为准):\ncpp-4.8.5-16.el7.x86_64.rpm gcc-4.8.5-16.el7.x86_64.rpm gcc-c++-4.8.5-16.el7.x86_64.rpm glibc-2.17-196.el7.i686.rpm glibc-2.17-196.el7.x86_64.rpm glibc-common-2.17-196.el7.x86_64.rpm glibc-devel-2.17-196.el7.x86_64.rpm glibc-headers-2.17-196.el7.x86_64.rpm libgcc-4.8.5-16.el7.i686.rpm libgcc-4.8.5-16.el7.x86_64.rpm libgomp-4.8.5-16.el7.i686.rpm libgomp-4.8.5-16.el7.x86_64.rpm libstdc++-4.8.5-16.el7.i686.rpm libstdc++-4.8.5-16.el7.x86_64.rpm libstdc++-devel-4.8.5-16.el7.i686.rpm libstdc++-devel-4.8.5-16.el7.x86_64.rpm nspr-4.13.1-1.0.el7_3.x86_64.rpm nss-softokn-freebl-3.28.3-8.el7_4.i686.rpm nss-softokn-freebl-3.28.3-8.el7_4.x86_64.rpm tcl-8.5.13-8.el7.i686.rpm tcl-8.5.13-8.el7.x86_64.rpm  如果 gem 安装 redis 包时，提示 ruby 版本太低   卸载 yum 过时的 ruby 环境\nyum remove ruby ruby-devel rubygems    下载 ruby 源码\n  解压，编译安装:\ntar -zxvf {latest_ruby.tar.gz} cd {latest_ruby} ./configure make make install    下载 gem 源码\n  解压，安装：\ntar -zxvf {latest_rubygem.tgz} cd {latest_rubygem} ruby setup.rb    重新 gem install redis 或者离线下载 gem-redis 的包，本地安装\n  ","date":1535618448,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1535618448,"objectID":"777574bc9a109c4943582b750d6c08fe","permalink":"https://szthanatos.github.io/topic/redis/03-operation/install/","publishdate":"2018-08-30T16:40:48+08:00","relpermalink":"/topic/redis/03-operation/install/","section":"topic","summary":"版本 软件 版本 更新日期 备注 Redis 4.0.11 2018-08-03 必装 Ruby 2.5.1 2018-03-28 可选, 集群执行 rb 脚本","tags":null,"title":"Redis 单机 \u0026 集群安装","type":"book"},{"authors":null,"categories":null,"content":"Tmux 是一个终端复用软件。比如你开一个 terminal 窗口，相当于和本地的或远程的 Linux 建立了一次会话连接。\n如果你想多做几件事，比如一个窗口运行服务，一个窗口运行客户端，对不起，你得再开一个窗口，再建立一个连接。\ntmux 就是解决这个问题的工具，它可以让你的终端 (Terminal) 给复用 (mux) 了，在一次连接里面做无数多件不同的事情。\nUbuntu 自带 Tmux，无需额外安装。\n概念 Tmux 有这么几个概念：\n Session：输入 tmux 后就创建了一个会话，一个会话是一组窗体的集合。 Window：会话中一个可见的窗口，你的屏幕一次只会看到一个窗口的内容。 Pane: 一个窗口可以分成多个窗格。  使用 tmux 的过程可以分为：\n 控制模式（按下或者按住前缀 (tmux-prefix)，默认 ctrl+b, 下文用※表示），也就是用快捷键执行动作； 命令模式（输入 tmux 后接命令），执行内部命令，好理解； 一般模式，就是把窗格内的东西当一般 terminal 用；  配置 添加配置文件 .tmux.conf，内容如下：\n#-- base --# # (可选) 设置 zsh 为默认 shell set -g default-shell /bin/zsh #-- settings --# # 开启鼠标切换窗格，按住 shift 复制粘贴 set -g mouse on # 窗口编号从 1 开始计数 set -g base-index 1 # 关掉某个窗口后，编号重排 set -g renumber-windows on # 窗格编号从 1 开始计数 set -g pane-base-index 1 # PREFIX-Q 显示编号的驻留时长，单位 ms set -g display-panes-time 5000 # 进入复制模式的时候使用 vi 键位（默认是 EMACS） setw -g mode-keys vi # 禁止活动进程修改窗口名 # setw -g allow-rename off # 禁止自动命名新窗口 setw -g automatic-rename off # 开启 256 colors 支持 set -g default-terminal \u0026quot;tmux-256color\u0026quot; #-- bindkeys --# # 以下 3 行设置 ctrl+x 代替 ctrl+b 的快捷键 set -g prefix C-x unbind C-b bind C-x send-prefix # 设置 tmux-prefix + \\ 垂直分割窗格 unbind % bind \\\\ split-window -h # 设置 tmux-prefix + - 水平分割窗格 unbind '\u0026quot;' bind - split-window -v # 设置 ctrl+vim 方式切换窗格 bind -n C-h select-pane -L bind -n C-j select-pane -D bind -n C-k select-pane -U bind -n C-l select-pane -R  有了这个配置文件立刻就能生效。\n常用操作 下面用 ※ 代表 tmux 前缀，也就是 ctrl+x，默认是 ctrl+b。\n鼠标 tmux 中执行有些正常 terminal 中的鼠标操作需要按住 shift，多试试。\n窗格的分割线可以直接用鼠标拖动。\n命令 会话  tmux 新建无名称会话 tmux new -s demo 新建名称为 demo 的会话 tmux detach 断开当前会话，既※ + d tmux a 默认进入第一个会话 tmux a -t demo 进入到名称为 demo 的会话 tmux list-session 查看所有会话 tmux ls 同上，简写  结束  tmux kill-server 关闭服务器，所有的会话都将关闭 tmux kill-session -t demo 关闭 demo 会话 tmux kill-window 关闭窗口 tmux kill-pane 关闭窗格  控制 会话 (Session)  ※ + d 休眠 ※ + s 以菜单方式显示和选择会话 ※ + L 切换回上一次的会话  窗口 (Windows)  ※ + c 创建新窗口 ※ + n 选择下一个窗口 ※ + p 选择前一个窗口 ※ + l 最近一次活跃窗口之间进行切换 ※ + 0~9 选择几号窗口 ※ + , 重命名窗口 ※ + . 更改窗口的编号，但只能更改成未使用的编号，所以要交换窗口的话，得更改多次进行交换 ※ + \u0026amp; 关闭窗口 ※ + w 以菜单方式显示及选择窗口 ※ + f 在所有窗口中查找内容  窗格 (Pane)  ※ + z 最大化 / 还原当前窗格 ※ + \u0026quot; 模向分隔窗格，替换为了 - ※ + % 纵向分隔窗格，替换为了 \\ ※ + o 跳到下一个分隔窗格 ※ + x 关闭窗格 ※ + ; 切换到最后一个使用的窗格 ※ + 上下键 上一个及下一个分隔窗格 ※ + 空格键 切换窗格布局  tmux 插件 之前还用过一段时间 Tmux 的插件，后来发现需要长期停留在 Tmux 的时候很少，所以后面没用了，\n配置文件还是放出来留给有缘人：\n# plugins # tmux plugin manager 插件管理 set -g @plugin 'tmux-plugins/tpm' set -g @plugin 'tmux-plugins/tmux-sensible' # 保存布局插件，tmux-prefix + ctrl+s/tmux-prefix + ctrl+r 保存 / 恢复 set -g @plugin 'tmux-plugins/tmux-resurrect' # 自动保存插件 set -g @plugin 'tmux-plugins/tmux-continuum' # tmux-resurrect 配置 # 恢复 shell 的历史记录, 只有无前台任务运行的窗格 才能被保存 set -g @resurrect-save-bash-history 'on' # 恢复窗格内容, 目前使用该功能时，请确保 tmux 的 default-command 没有包含 \u0026amp;\u0026amp; 或者 || 操作符， # 否则将导致 bug。（查看 default-command 的值，请使用命令 tmux show -g default-command。） set -g @resurrect-capture-pane-contents 'on' # 恢复 vim 会话 set -g @resurrect-strategy-vim 'session' # set -g @resurrect-save 'S' # set -g @resurrect-restore 'R' # tmux-continuum 配置 # 开启自动恢复 set -g @continuum-restore 'on' # 设置备份间隔（分钟，0 为不自动备份） set -g @continuum-save-interval '240' # 状态栏查看备份状态 # Initialize TMUX plugin manager (keep this line at the very bottom of tmux.conf) set -g status-right 'Continuum status: #{continuum_status}' run '/etc/.tmux/plugins/tpm/tpm'  tpm 通过 git 安装：\ngit clone https://github.com/tmux-plugins/tpm /etc/.tmux/plugins/tpm  安装 tpm 后需要重新读取配置文件生效：\n 进入 tmux，输入 ※ + : 进入命令模式； 再输入 source-file ~/.tmux.conf 手动刷新配置文件； 最后输入 ※ + shift + u 进入 tpm 插件升级页面进行升级。  ","date":1598090039,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1598090039,"objectID":"af38eb6123f7382f3ccc7f3bb6163c8a","permalink":"https://szthanatos.github.io/topic/wsl2/coding_with_wsl2_05/","publishdate":"2020-08-22T17:53:59+08:00","relpermalink":"/topic/wsl2/coding_with_wsl2_05/","section":"topic","summary":"Tmux 是一个终端复用软件。比如你开一个 terminal 窗口，相当于和本地的或远","tags":null,"title":"使用 tmux 复用终端","type":"book"},{"authors":null,"categories":null,"content":"在前面的部分已经配置好了 Python 的死蛇源，所以现在已经可以使用 Ubuntu 作为 Python 基础环境了。\n基本配置 安装最新版本 Python：\nsudo apt install python3.x sudo apt install python3.x-distutils sudo apt install python3-pip  修改 pypi 源，使用清华大学的镜像：\npip install pip -U pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple  Pycharm 连接 Pycharm 2019.1.X+ 版本已经支持直接连接 wsl 的 python 环境，无需通过 ssh\n","date":1598090795,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1598090795,"objectID":"fcdbddaa4fcccb6110a5035f00d0ad2f","permalink":"https://szthanatos.github.io/topic/wsl2/coding_with_wsl2_06/","publishdate":"2020-08-22T18:06:35+08:00","relpermalink":"/topic/wsl2/coding_with_wsl2_06/","section":"topic","summary":"在前面的部分已经配置好了 Python 的死蛇源，所以现在已经可以使用 Ubuntu 作","tags":null,"title":"直接使用 Ubuntu Python 作为开发环境","type":"book"},{"authors":null,"categories":null,"content":"数据结构 不同数据类型对应的操作的时间复杂度也不一样，选择合适的数据类型可以降低很多时间成本：\nString    命令 时间复杂度     SET key value [EX seconds] [PX milliseconds] [NX|XX] O(1)   SETNX key value O(1)   SETEX key seconds value O(1)   PSETEX key milliseconds value O(1)   GET key O(1)   GETSET key value O(1)   STRLEN key O(1)   APPEND key value 平均 O(1)   SETRANGE key offset value 短字符串平均 O(1)/ 长字符串 O(N)，N 为 value 长度   GETRANGE key start end O(N)，N 为返回值长度   INCR key O(1)   INCRBY key increment O(1)   INCRBYFLOAT key increment O(1)   DECR key O(1)   DECRBY key decrement O(1)   MSET key value [key value …] O(N)   MSETNX key value [key value …] O(N)   MGET key [key …] O(N)    List    命令 时间复杂度     LPUSH key value [value …] O(1)   LPUSHX key value O(1)   RPUSH key value [value …] O(1)   RPUSHX key value O(1)   LPOP key O(1)   RPOP key O(1)   RPOPLPUSH source destination O(1)   LREM key count value O(N)   LLEN key O(1)   LINDEX key index O(N)，N 为到达下标 index 过程中经过的元素数量   LINSERT key BEFORE|AFTER pivot value O(N)，N 为寻找 pivot 过程中经过的元素数量   LSET key index value 头尾元素 O(1)，其他 O(N)   LRANGE key start stop O(S+N)，S 为偏移量 start ， N 为指定区间内元素的数   LTRIM key start stop O(N)   BLPOP key [key …] timeout O(1)   BRPOP key [key …] timeout O(1)   BRPOPLPUSH source destination timeout O(1)    Hash    命令 时间复杂度     HSET hash field value O(1)   HSETNX hash field value O(1)   HGET hash field O(1)   HEXISTS hash field O(1)   HDEL key field [field …] O(N)   HLEN key O(1)   HSTRLEN key field O(1)   HINCRBY key field increment O(1)   HINCRBYFLOAT key field increment O(1)   HMSET key field value [field value …] O(N)   HMGET key field [field …] O(N)   HKEYS key O(N)   HVALS key O(N)   HGETALL key O(N)   HSCAN key cursor [MATCH pattern] [COUNT count] O(1)    Set    命令 时间复杂度     SADD key member [member …] O(N)   SISMEMBER key member O(1)   SPOP key O(1)   SRANDMEMBER key [count] 无 conut 时 O(1)，有 conut 时 O(N)   SREM key member [member …] O(N)   SMOVE source destination member O(1)   SCARD key O(1)   SMEMBERS key O(N)   SSCAN key cursor [MATCH pattern] [COUNT count] O(1)   SINTER key [key …] O(N*M)， N 为给定集合当中基数最小的集合， M 为给定集合的个数   SINTERSTORE destination key [key …] O(N*M)   SUNION key [key …] O(N)   SUNIONSTORE destination key [key …] O(N)   SDIFF key [key …] O(N)   SDIFFSTORE destination key [key …] O(N)    ZSet    命令 时间复杂度     ZADD key score member [[score member] [score member] …] O(M*log(N))，N 是有序集的基数， M 为成功添加的新成员的数量   ZSCORE key member O(1)   ZINCRBY key increment member O(log(N))   ZCARD key O(1)   ZCOUNT key min max O(log(N))   ZRANGE key start stop [WITHSCORES] O(log(N)+M)，N 为有序集的基数，而 M 为结果集的基数   ZREVRANGE key start stop [WITHSCORES] O(log(N)+M)   ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count] O(log(N)+M)   ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count] O(log(N)+M)   ZRANK key member O(log(N))   ZREVRANK key member O(log(N))   ZREM key member [member …] O(M*log(N))   ZREMRANGEBYRANK key start stop O(log(N)+M)   ZREMRANGEBYSCORE key min max O(log(N)+M)   ZRANGEBYLEX key min max [LIMIT offset count] O(log(N)+M)，N 为有序集合的元素数量， 而 M 则是命令返回的元素数量   ZLEXCOUNT key min max O(log(N))   ZREMRANGEBYLEX key min max O(log(N)+M)，N 为有序集合的元素数量， 而 M 则为被移除的元素数量   ZSCAN key cursor [MATCH pattern] [COUNT count] O(1)   ZUNIONSTORE destination numkeys key [key …] [WEIGHTS weight [weight …]] [AGGREGATE SUM|MIN|MAX] O(N)+O(M log(M))，N 为给定有序集基数的总和， M 为结果集的基数   ZINTERSTORE destination numkeys key [key …] [WEIGHTS weight [weight …]] [AGGREGATE SUM|MIN|MAX] O(NK)+O(Mlog(M))， N 为给定 key 中基数最小的有序集， K 为给定有序集的数量， M 为结果集的基数    模拟类型 除了直接使用 redis 数据类型，其他的一些常见数据结构也可以用固定操作模拟出来：\n 堆栈：lpush + lpop = Stack 队列：lpush + rpop = Queue 有限集合：lpush + ltrim = Capped Collection 消息队列1：lpush + brpop = Message Queue  负载 redis 基本的逻辑存储单位是键 (Key) 对象，键底层的编码方式会随着键的类型 / 大小而改变：\n   编码方式 (C 语言实现) 情况     String 类型    int(long 类型整数) long 能存下的整数值   embstr(embstr 类型的简单动态字符串 SDS) \u0026lt;=32 字节的字符串   raw(简单动态字符串 SDS)    List 类型    ziplist(压缩列表) 列表内元素不超过 512 个并且所有元素长度都小于 64 字节   linkedlist(双端链表)    Hash 类型    ziplist 哈希内不超过 512 个键值对并且所有键值对的键和值的长度都小于 64 字节   hashtable(字典)    Set 类型    intset(整数集合) 集合内元素不超过 512 个并且所有元素都是整数值   hashtable    ZSet 类型    ziplist 有序集合内元素不超过 128 个并且所有元素的长度都小于 64 字节   skiplist(跳跃表和字典)     所以简单的来说，String 长度小于 32 字节，其他复合类型元素个数不超过 512 个 (ZSet 不超过 128 个) 并且元素小于 64 字节或者是整数 (Set) 的时候，是 redis 认为的一个 key 的合理值，超过这个范围 redis 也是允许的，但是关注点就放在存储而不是性能上了。\n大键会拖累存储性能。尤其是在时间复杂度不是 O(1)的操作上，性能损失是线性 (eg: LREM) 甚至指数 (eg: ZINTERSTORE) 上升的。\n过小 (零碎) 的键也不合适，它是对性能的一种浪费，比如要存放 用户: 用户信息，直接将每个用户存为一个 String，相比用 Hash 把所有用户存储在一个键上，想要实现 hgetall 这样的操作既复杂，效率也更低。\n集群倾斜 \u0026amp; 热点问题 在集群中，redis 是划分出 16384 个哈希槽，然后将哈希槽平均 (也可以手动指定) 分配到集群节点上。键会通过 crc16 算法计算并将结果对 16384 取余，由此将键映射到编号为 0~16383 的哈希槽中。\n大键会造成集群倾斜，也就是大键所在节点的内存可能被占满了，而其他节点还空着。极端情况下如果一个键所占空间超过了节点分配的内存，那这个集群可能会永远 fail 下去——虽然有大量内存空着，但是没有一个节点能放下这个键了。\n大键越多，分布越不均匀，在集群中就越容易出现热点问题 (另一种角度的倾斜)，简单来说，就是\n 由于数据都集中在一个键 → 对数据的操作都集中在一个键 → 键位于某个哈希槽 → 哈希槽所在的节点读写压力非常大 → 集群其他节点都在划水  假设是 3 个 master 的集群，本来的处理能力可能是 100000 q/s * 3，这样的情况下实际发挥出来的就只有 100000 q/s 了。\n针对大键 \u0026amp; 倾斜问题可以有以下措施：\n 将可能的大键进行拆分，比如将一个大 List 拆成 List0~List9； 在集群配置中开启 readonly 以降低主节点读压力 (详见 《Redis 集群相关命令》)； 根据实际情况，修改 redis 变更编码类型的阈值，比如设定 list-max-ziplist-entries=1024 让元素在 1024 以内的列表都用 ziplist 编码；    redis5 中提供新的数据结构 Stream，直接实现了 Kafka 那种支持多播的消息队列\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":1552892675,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1552892675,"objectID":"b2df59bc013e82669b7cb13f729e1aad","permalink":"https://szthanatos.github.io/topic/redis/04-advanced/improve-01/","publishdate":"2019-03-18T15:04:35+08:00","relpermalink":"/topic/redis/04-advanced/improve-01/","section":"topic","summary":"数据结构 不同数据类型对应的操作的时间复杂度也不一样，选择合适","tags":null,"title":"优化指南 - 设计","type":"book"},{"authors":null,"categories":null,"content":"操作 批量操作 传统数据库也存在批量操作效率高于单次操作的情况，但是 redis 由于执行效率更高，批量操作带来的提升也更夸张。举个不是很恰当的例子，还是按 redis 每秒能处理 10k 请求来算——\n假设客户端和服务端不在同一机器，网络通信存在额外 1ms 延时：\n   操作 时间     1000 次 get 1000 1 + 1000 0.01 = 1010 (ms)   10 次 100 个键值对的 mget 10 (1 1 + 100 * 0.01) = 20 (ms)   1 次 1000 个键值对的 mget 1 1 + 1000 0.01 = 11 (ms)    如果一条条去执行，这时 redis 每秒只能处理 1000 / 1.01 ≈ 990 次请求，只发挥了实际计算力的 0.99%。\nMulti-action vs Pipeline vs Transaction 批量操作有 3 种实现方式：\nMulti-action\n也就是 m 开头的命令，比如 mget\n优点：\n 效率是最高的，因为它只需要解析一条命令  缺点：\n 只能做一件事 一次操作的 key 太多的话会导致 redis 实例的响应能力等比下降 不具有原子性，存在部分成功部分失败的情况  Pipeline\n管道式的操作\n优点：\n 可以处理多类数据 可以将大量命令分解为多个包依次发送执行 使用灵活  缺点：\n 不保证事务，其他客户端发送的命令可能在 pipeline 执行期间被执行 不具有原子性，存在部分成功部分失败的情况  Transaction\n事务\n优点：\n 原子性，要么全执行要么不执行 乐观锁  缺点：\n 命令会被分批发送给服务端，最后统一执行，性能是最低的 (但还是远高于执行 n 次命令) 随着竞争激烈程度的上升，乐观锁会导致性能相应下降 在集群中，只有同属于一个哈希槽的键才能使用事务，多数客户端支持的不好  另外，因为 Pipeline 是基于 redis 自定义的 RESP 协议实现的，而 Transaction 是命令实现，所以给了我们组合使用的机会。相比直接使用事务会快上一点点，没有太大区别。\n总的来说，实现批量执行的核心肯定是 Pipeline，请尽可能的使用。\n放上一组官方测试结果以供参考：\n# Intel(R) Xeon(R) CPU E5520 @ 2.27GHz (with pipelining) $ ./redis-benchmark -r 1000000 -n 2000000 -t get,set,lpush,lpop -P 16 -q \u0026gt; SET: 552028.75 requests per second \u0026gt; GET: 707463.75 requests per second \u0026gt; LPUSH: 767459.75 requests per second \u0026gt; LPOP: 770119.38 requests per second # Intel(R) Xeon(R) CPU E5520 @ 2.27GHz (without pipelining) $ ./redis-benchmark -r 1000000 -n 2000000 -t get,set,lpush,lpop -q \u0026gt; SET: 122556.53 requests per second \u0026gt; GET: 123601.76 requests per second \u0026gt; LPUSH: 136752.14 requests per second \u0026gt; LPOP: 132424.03 requests per second  减少阻塞 另一方面，针对每条命令，由于 redis 是单进程单线程的模式，命令是依次执行的，想象一下星巴克排队，只要有一个客人堵在那，后面的不管买多买少都只能排着\u0026hellip;\n可能造成阻塞的命令包括：\n del，这个删除是在前台阻塞式的删除，在 redis4.0 以后应该使用 unlink 后台非阻塞的标记删除 keys、hgetall、smembers，这类返回所有结果的命令都会占用大量资源，都应该用 scan、hscan、sscan 等命令替换 sinter/sunion/sdiff 的结果如果会重复使用的话，用 sinterstore/sunionstore/sdiffstore 将结果保存起来 sort，可以先取到本地再排序 能用 mget/mhset 的情况下就不要用 get/set 总之，所有时间复杂度大于 O(log n) 的操作都应该考虑有没有更低占用的实现  除了命令本身，造成阻塞的原因还有：\n CPU 饱和：cpu 占用率 100% 了 CPU 竞争：和其他服务竞争资源 持久化带来的 IO 阻塞  fork 阻塞：rdb/aof 文件重写的时候 fork 出的子进程长时间不能完成，导致的主进程阻塞 AOF 阻塞：数据变动剧烈的时候 fsync 持续写硬盘导致的 HugePage 阻塞：如果 linux 内核里启用了 transparent_hugepage，会对内存和延迟带来很大影响   内存交换：物理内存不够用了，部分数据被写到 Linux 的虚拟内存，也就是 swap，但是内存和磁盘的读写速度起码差了 5 个量级 网络问题  这些就需要在使用过程中不断监测和发现了。\n策略 过期回收 随着时间增长，碎片化的无用 key 的数量也会持续上升，直到最终你的内存被垃圾 Key 占满。 所以一个好习惯是给不需要持久存储 (redis 本身就不是用来持久化的) 的 Key 都加上过期时间。\n   命令 注释     EXPIRE \u0026lt;KEY\u0026gt; \u0026lt;TTL\u0026gt; 将键的生存时间设为 ttl 秒   PEXPIRE \u0026lt;KEY\u0026gt; \u0026lt;TTL\u0026gt; 将键的生存时间设为 ttl 毫秒   EXPIREAT \u0026lt;KEY\u0026gt; \u0026lt;timestamp\u0026gt; 将键的过期时间设为 timestamp 所指定的秒数时间戳   PEXPIREAT \u0026lt;KEY\u0026gt; \u0026lt;timestamp\u0026gt; 将键的过期时间设为 timestamp 所指定的毫秒数时间戳.    但是需要注意，过期键的内存空间默认并不会被立即回收。redis 的内存回收策略主要是这两个：\n 被动删除，读 / 写过期键时触发删除； 主动删除，每隔 100ms 检查 20 个带过期时间的键，如果有超过四分之一的键过期，则重复上面步骤；  另外，设置 maxmemory 最大内存，可以在达到内存阈值的时候触发强制删除机制 (配置项 maxmemory-policy)：\n noeviction，禁止强制删除，默认策略； volatile-ttl，从带过期时间的键中删除最接近过期的； volatile-lru，从带过期时间的键中删除最近最久未使用的 (Least Recently Used)； volatile-lfu，从带过期时间的键中删除最近最少使用的 (Least Frequently Used)； volatile-random，从带过期时间的键中随机删除； allkeys-lru，从所有键中删除最近最久未使用的； allkeys-lfu，从所有键中删除最近最少使用的； allkeys-random，从带过期时间的键中随机删除；  持久化 redis 数据落到硬盘依赖两种持久化机制：RDB 和 AOF。\n    RDB AOF     存储内容 数据 写操作日志   性能影响 小 大   恢复速度 高 低   存储空间 小 大   可读性 低 高   安全程度 较低，保存频率低 较高，保存频率高   默认开启 是 否   存储策略 save 900 1：九百秒内一次修改即保存 save 300 10：三百秒内十次修改即保存 \u0026lt; br\u0026gt;save 60 10000：六十秒内一万次修改即保存 \u0026lt; br \u0026gt; 允许自定义 always：逐条保存 \u0026lt; br\u0026gt;or\neverysec：每秒保存 \u0026lt; br\u0026gt;or\nno：系统自己决定什么时候保存    RDB 的 save 策略配合大键有时候简直性能地狱。必要时请重写触发机制。\nAOF 的日志文件会膨胀的非常厉害，所以会定期重写。如果文件变动过于剧烈，你会发现 swap 比内存更先被吃干净。\nredis4.0 以后支持一个叫 aof-use-rdb-preamble 的参数，意思就是在重写 AOF 文件的时候，会把早期日志写成 RDB 格式，新增加的继续使用 AOF。这样一来可以替高重写和恢复的速度。某种意义上有了这个就不必单独开启 RDB 持久化了。\n内存清理 在 redis4.0 之后，可以通过将配置里的 activedefrag 设置为 yes 开启自动清理，或者通过 memory purge 命令手动清理。\n","date":1552892675,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1552892675,"objectID":"f573760fcff2c909f6b294c203e08e92","permalink":"https://szthanatos.github.io/topic/redis/04-advanced/improve-02/","publishdate":"2019-03-18T15:04:35+08:00","relpermalink":"/topic/redis/04-advanced/improve-02/","section":"topic","summary":"操作 批量操作 传统数据库也存在批量操作效率高于单次操作的情况，","tags":null,"title":"优化指南 - 使用","type":"book"},{"authors":null,"categories":null,"content":"监控 为了发现前面所说的问题，需要开发 / 运维人员不断的监控 redis 运行情况。\nredis-cli 查询 部分信息无法通过 redis 命令直接获取，但是可以通过 redis-cli [参数] 获取：\n–-bigkeys\n后台 scan 出每种数据类型中较大的 key\n--latency\n服务端响应延时\nslowlog 命令 在客户端执行 slowlog get [n] 可以获取最慢的 n 条执行命令的记录\ninfo 命令 返回服务器信息，性能监测的时候注意其中的几个部分：\nmemory：mem_fragmentation_ratio\n内存碎片率，used_memory_rss(系统分配内存总量) 和 used_memory(Redis 分配器分配的内存总量) 的比值。\n在 1-1.5 之间都是合理值，\u0026lt;1 则说明内存已经占满，正在和硬盘进行内存交换，性能下降严重，\u0026gt;1.5 则说明碎片过多需要清理了。\nstats：latest_fork_usec\n最近一次 fork 操作耗时\npersistence：aof_delayed_fsync\n被延迟的 fsync 调用数量\nclients：connected_clients，blocked_clients\n已连接客户端的数量和正在等待阻塞命令的客户端的数量\nmonitor 命令 可以用来监测一个节点一段时间内执行的命令，从而统计出热点 key。但是 monitor 自己也是有内存占用的，所以不能频繁、持续的使用。\n部署 网络 影响 redis 性能的最主要因素是网络。\n按官方基准测试来说，对于 10kb 以内的数据，redis 的处理能力在 100000q/s 以上。\n那么假设每次 set/get 的 4kb 大小的字符串，这时占用的带宽就有 3.2 Gbit/s ，千兆网卡 (1 Gbit/s) 就不够用了，得换万兆网卡 (10 Gbit/s) 才能满足需求，可见想跑满 redis 的 CPU 计算力对网络的要求是很夸张的。\n当然，这个例子比较极端，redis 官方推荐的网络环境下每次传输的包最好不超过一个 MTU(大约 1500 bytes)。\n如果完全抛开网络因素，客户端服务端都在单机上时，使用 Unix 域套接字 (Unix domain sockets，也叫 IPC(inter-precess communication) socket 进程间通信套接字) 替换默认的 TCP/IP 连接方式，能额外再有 50% 的吞吐量提升(不过在大量使用 pipeline 的情况下就没差这么多了)。\n启用 Unix 域套接字需要在配置文件中取消注释：\n# unixsocket 路径 unixsocket /tmp/redis.sock # unixsocket 权限 unixsocketperm 700  之后就可以在客户端使用指定方式连接了，以 python 客户端为例：\nimport redis redis_connect = redis.Redis(unix_socket_path='/tmp/redis.sock') pass  CPU redis 更倾向于具有更大缓存而不是更多核的 CPU，在多核的情况下，redis 性能会受 NUMA 配置和进程所处位置的影响，指定客户端和服务器使用同一 CPU 的两个不同核心可以使从 L3 缓存获得的收益最大化。\n另外，redis 在 Inter 和 AMD 的 CPU 上的表现也有差别，在某些情况下在 AMD 的 CPU 上性能可能只有 Inter 的一半。\n内存 只有在面对大于 10KB 的数据的时候，内存频率 / 带宽才会影响 redis 性能，所以一般不用去考虑。内存大小只会影响能存放的数据量。\n连接数 redis 可以在 60000 多个连接时维持 50000 q/s 的性能，但是根据官方测试，具有 30000 个连接的 redis 实例只能处理 100 个连接实例可实现的吞吐量的一半。\n虚拟化 虚拟机中的 redis 性能肯定是低于实机上的，系统调用和中断上面浪费的太多。\n","date":1552892675,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1552892675,"objectID":"2fcc76be0d956ef2c3cbc55241305eed","permalink":"https://szthanatos.github.io/topic/redis/04-advanced/improve-03/","publishdate":"2019-03-18T15:04:35+08:00","relpermalink":"/topic/redis/04-advanced/improve-03/","section":"topic","summary":"监控 为了发现前面所说的问题，需要开发 / 运维人员不断的监控 redis 运","tags":null,"title":"优化指南 - 运维","type":"book"},{"authors":null,"categories":null,"content":"嗯，是的，其实可以直接在 Windows 下运行 Docker 而无需 Wsl。但是 Wsl2 会提供更好的性能——\n如果开启 Wsl2，Docker 会默认把自己的文件系统迁移到 wsl 上（因为在 Win 下的本质也是开了个 Hyper-V 的虚拟机在运行）\n——另一方面，咱们前面配好的终端环境也比 Windows 的终端好使\u0026hellip;\n看到说 Powershell 好的人有，但是真拿它写东西的人好像没见到过\u0026hellip;\n再一个是 Docker Desktop 可以访问到 Windows 下的文件，而如果直接在 wsl2 中安装 Docker 就没有这份福利了\u0026hellip;\n所以 Docker Desktop + Wsl2 是最合适的一个组合。\n安装  下载安装 Docker Desktop edge 版本 打开设置，检查 General 中 use the WSL2 base egine 应该是默认勾选的状态； 在 Resources-WSL INTEGRATION 中检查 Enable integration with my default WSL Distro 应该是勾选状态，并将 Linux 发行版置为 Enable 状态; 点击 Apply \u0026amp; Restart，完成~  Docker Desktop 重启之后，在任意终端 (Windows \u0026amp; Linux) 都可以执行 Docker 命令啦~\n配置连接 Docker 在 设置-构建、执行、部署 下找到 Docker 配置，可以直接连接 Docker for window：\n编写环境镜像 最简运行环境 最简运行环境 Dockerfile 如下：\nFROM python:3.8-buster LABEL author=\u0026quot;Lex Wayne\u0026quot; WORKDIR /app COPY . /app RUN pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple \u0026amp;\u0026amp;\\ pip install -U pip \u0026amp;\u0026amp;\\ pip install --no-warn-script-location -r /requirements.txt  但是这种比较适用于稳定项目，因为每次更改都会需要重新生成镜像。\n代码写到一半，新 import 一个第三方包，还得先编辑 requirements.txt ，重新生成镜像，才能有提示\u0026hellip;画面未免太美。\n个人开发环境 我惯用的开发环境 Dockerfile 如下：\nFROM python:3.8-buster LABEL version=\u0026quot;1.1\u0026quot; \\ authors=\u0026quot;Lex Wayne\u0026quot; \\ ARG DEBIAN_FRONTEND=noninteractive RUN echo \u0026gt;/etc/apt/sources.list \u0026quot;\\n\\ deb http://mirrors.tuna.tsinghua.edu.cn/debian/ buster main contrib non-free\\n\\ deb http://mirrors.tuna.tsinghua.edu.cn/debian/ buster-updates main contrib non-free\\n\\ deb http://mirrors.tuna.tsinghua.edu.cn/debian/ buster-backports main contrib non-free\\n\\ deb http://mirrors.tuna.tsinghua.edu.cn/debian-security buster/updates main contrib non-free\\n\\ \u0026quot; \u0026amp;\u0026amp;\\ apt-get update \u0026amp;\u0026amp;\\ apt-get upgrade -y \u0026amp;\u0026amp;\\ apt-get install -y sudo vim openssh-server openssh-client \u0026amp;\u0026amp;\\ mkdir -p /var/run/sshd \u0026amp;\u0026amp;\\ echo 'root:123456' | chpasswd \u0026amp;\u0026amp;\\ sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config \u0026amp;\u0026amp;\\ sed 's@session\\s*required\\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd \u0026amp;\u0026amp;\\ echo \u0026quot;export VISIBLE=now\u0026quot; \u0026gt;\u0026gt; /etc/profile RUN pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple EXPOSE 22 CMD [\u0026quot;/usr/sbin/sshd\u0026quot;, \u0026quot;-D\u0026quot;]  使用时相当于后台长期运行一个 Linux 容器环境，通过 ssh 进行远程调试，默认密码 123456 请修改掉。\n运行 Docker 容器 完成 Docker 配置后会在左下方底栏新增一个 Services，没有的话从顶部 视图-工具窗口 中也能找到，\n双击连接 Docker，右键运行环境容器；\n点击侧边绿色三个箭头的图标即可使用 Dockerfile 部署。\n参考  Docker 官方文档: Docker Desktop WSL 2 backend Vs Code 团队博客: Using Docker in WSL 2  ","date":1598090861,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1598090861,"objectID":"6e984e7f62dc0df462a2890b247e2870","permalink":"https://szthanatos.github.io/topic/wsl2/coding_with_wsl2_07/","publishdate":"2020-08-22T18:07:41+08:00","relpermalink":"/topic/wsl2/coding_with_wsl2_07/","section":"topic","summary":"嗯，是的，其实可以直接在 Windows 下运行 Docker 而无需 Wsl。但是 Wsl2 会提供","tags":null,"title":"使用 Docker 开发环境","type":"book"},{"authors":null,"categories":null,"content":"选项 大小写敏感 File -\u0026gt; Settings -\u0026gt; Editor -\u0026gt; General -\u0026gt; Code Completion\n取消后全小写也能自动补全，不过为了养成好习惯建议还是开首字母。\n行分隔符 File -\u0026gt; Settings -\u0026gt; Editor -\u0026gt; Code Style\nWindows 下默认换行是 CRLF 即 \\r\\n，改成 Unix 的 LF(\\n)\n头部模板 File -\u0026gt; Settings -\u0026gt; Editor -\u0026gt; File and Code Templates -\u0026gt; Python Script\n写入以下内容作为 Python 默认头部模板：\n#!/usr/bin/env python3 # -*- coding: utf-8 -*- \u0026quot;\u0026quot;\u0026quot; @Author : ${USER} @File : ${NAME}.py @Project: ${PROJECT_NAME} @Time : ${DATE} ${TIME} \u0026quot;\u0026quot;\u0026quot;  ${USER} 是系统用户名，你也可以写死。\n鼠标缩放 File -\u0026gt; Settings -\u0026gt; Editor -\u0026gt; General -\u0026gt; Change font size(Zoom) with Ctrl+Mouse Wheel\n按住 Ctrl 滚轮缩放。\n插件 市场插件  .env file support: .env 文件格式支持 .ignore: git .ignore 模板 Chinese (Simplified) Language Pack EAP: 汉化 CodeGlance: Sublime 式的小地图 Key Promoter X: 使用功能时显示对应快捷键 Rainbow Brackets: 不同层级括号不同颜色 Requirement: 自动检查 Requirement 文件是否和实际环境匹配 Translation: 翻译插件  外部插件 另外建议使用 Black 让强制统一代码风格，多人协作的时候非常有用。\n运行 Black 需要 Python 环境，到底放 Windows 还是 Wsl 还是 Docker 都行，看你有多骚了。\n集成步骤直接按 文档 走就好。摘抄如下：\n  pip install black\n  记录 Black 位置\nWindows 下可能在 C:\\Users\\{用户名}\\AppData\\Local\\Programs\\Python\\{Python 版本}\\Scripts\\black.exe\nLinux 和 MacOS 可能在 /usr/local/bin/black\n  File -\u0026gt; Settings -\u0026gt; Tools -\u0026gt; External Tools，新建内容如下：\nName: Black Description: Black is the uncompromising Python code formatter. Program: \u0026lt;第二步的位置\u0026gt; Arguments: \u0026quot;$FilePath$\u0026quot;  建议取消 Advanced Options 中的 打开工具输出控制台\n  配置快捷键，我建议是直接替换 Ctrl+Alt+l 格式化\n  监视文件更改自动执行，在 File -\u0026gt; Settings -\u0026gt; Tools -\u0026gt; File Watchers 下新建：\nName: Black File type: Python Scope: Project Files Program: \u0026lt;第二步的位置\u0026gt; Arguments: $FilePath$ Output paths to refresh: $FilePath$ Working directory: $ProjectFileDir$  建议不勾选 Advanced Options 中的 Auto-save edited files to trigger the watcher\n  快捷键 File -\u0026gt; Settings -\u0026gt; Keymap -\u0026gt; Editor Action\n我用 Pycharm 默认键位很习惯，只加了:\n 向左: Ctrl + ; 向右: Ctrl + Shift + ;  ","date":1598104268,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1598104268,"objectID":"476ac4ecb1000eada5ccf09a278a4e5f","permalink":"https://szthanatos.github.io/topic/wsl2/coding_with_wsl2_08/","publishdate":"2020-08-22T21:51:08+08:00","relpermalink":"/topic/wsl2/coding_with_wsl2_08/","section":"topic","summary":"选项 大小写敏感 File -\u0026gt; Settings -\u0026gt; Editor -\u0026gt; General -\u0026gt; Code Completion 取消后全小写也能自动补全，","tags":null,"title":"Pycharm 易用性设置","type":"book"},{"authors":[],"categories":[],"content":"我觉得网上技术教程都很有坑。\n比如官方文档。如果只想尽快使用上某种技术产品，入门章节一般都是实验级别的，不太够用，而其余章节就有点过于细节;\n要么是零碎的个人笔记，基本只写自己关心的那一部分，叙述角度和内容都非常零散。\n所以我到底想要什么样的教程呢？\n对于我个人而言，我期望的是一个比个人笔记长，比官方文档短的一个教程，读起来不会太累；\n内容可以不深入，但是要系统和全面，看完了能让读者有一个整体的概念；\n而对于不同领域的知识，通过同样的叙述方式，降低认知负担，快速定位自己关心的部分；\n教程都统一叫指北，不全面也不权威，和系统学习官方文档背道而驰，但是30分钟建立一个感性认识完全足够了。\n所以我拟定了这样的一个思路：\n作为我个人博客的指北专题的固定格式，\n也期望通过这样的方式更好的帮助自己建立和分享知识体系。\n生成目录的脚本如下：\n#!/bin/bash create_page(){ cat \u0026gt; ${1}/${2}.md \u0026lt;\u0026lt;EOF --- title: linktitle: ${3} summary: date: $(date '+%Y-%m-%d %H:%M:%S') lastmod: $(date '+%Y-%m-%d %H:%M:%S') draft: false toc: true type: book weight: ${4} --- EOF } doc_title=\u0026quot;$1\u0026quot; mkdir -p content/$1 cd content/$1 dir_list=( 01-design 02-useage 03-operation 04-advanced 05-troubleshooting ) for chapter in ${dir_list[*]} do mkdir -p $chapter done # chapter create_page \u0026quot;${PWD}\u0026quot; _index \u0026quot;简介\u0026quot; 1 create_page 01-design _index \u0026quot;设计\u0026quot; 10 create_page 02-useage _index \u0026quot;使用\u0026quot; 40 create_page 03-operation _index \u0026quot;运维\u0026quot; 70 create_page 04-advanced _index \u0026quot;进阶\u0026quot; 100 create_page 05-troubleshooting _index \u0026quot;排错\u0026quot; 130 # page create_page 01-design concept \u0026quot;概念\u0026quot; 10 create_page 01-design architecture \u0026quot;架构\u0026quot; 20 create_page 01-design component \u0026quot;组件\u0026quot; 30 create_page 02-useage install-and-config \u0026quot;安装/配置\u0026quot; 40 create_page 02-useage operate \u0026quot;操作\u0026quot; 50 create_page 02-useage example \u0026quot;用例\u0026quot; 60 create_page 03-operation update-and-rollback \u0026quot;升级/降级\u0026quot; 70 create_page 03-operation backup-and-restore \u0026quot;备份/恢复\u0026quot; 80 create_page 03-operation observability \u0026quot;观测性\u0026quot; 90 create_page 04-advanced optimize \u0026quot;优化\u0026quot; 100 create_page 04-advanced trick\u0026quot;技巧\u0026quot; 110 create_page 04-advanced reference \u0026quot;参考\u0026quot; 120 cd ../../  如果你也使用 hugo 和 wowchemy，那么在项目主目录执行 ./create_book.sh [文档名] 就会在 content/[文档名] 下生成所有相关文件和文件夹，并配置好目录顺序。\n","date":1609153394,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1609153394,"objectID":"2d6391bbefd6d826f978658b55a5f6e0","permalink":"https://szthanatos.github.io/post/incomplete-guide/","publishdate":"2020-12-28T19:03:14+08:00","relpermalink":"/post/incomplete-guide/","section":"post","summary":"我觉得网上技术教程都很有坑。 比如官方文档。如果只想尽快使用上","tags":[],"title":"指北系列指南","type":"post"},{"authors":[],"categories":["Linux"],"content":"报错信息 之前运维给做了几台测试服务器，远程连接的时候速度特别慢，ssh 之后需要接近 1 分钟才能连上。\n原因 使用 ssh -v \u0026lt;服务器\u0026gt; 显示连接过程：\n$ ssh -v 123.456.789.0 OpenSSH_6.6.1, OpenSSL 1.0.1e-fips 11 Feb 2013 debug1: Reading configuration data /etc/ssh/ssh_config debug1: /etc/ssh/ssh_config line 56: Applying options for * debug1: Connecting to 123.456.789.0 [123.456.789.0] port 22. debug1: Connection established. debug1: permanently_set_uid: 0/0 debug1: identity file /root/.ssh/id_rsa type -1 debug1: identity file /root/.ssh/id_rsa-cert type -1 debug1: identity file /root/.ssh/id_dsa type -1 debug1: identity file /root/.ssh/id_dsa-cert type -1 debug1: identity file /root/.ssh/id_ecdsa type -1 debug1: identity file /root/.ssh/id_ecdsa-cert type -1 debug1: identity file /root/.ssh/id_ed25519 type -1 debug1: identity file /root/.ssh/id_ed25519-cert type -1 debug1: Enabling compatibility mode for protocol 2.0 debug1: Local version string SSH-2.0-OpenSSH_6.6.1 debug1: Remote protocol version 2.0, remote software version OpenSSH_6.6.1 debug1: match: OpenSSH_6.6.1 pat OpenSSH_6.6.1* compat 0x04000000 debug1: SSH2_MSG_KEXINIT sent debug1: SSH2_MSG_KEXINIT received debug1: kex: server-\u0026gt;client aes128-ctr hmac-md5-etm@openssh.com none debug1: kex: client-\u0026gt;server aes128-ctr hmac-md5-etm@openssh.com none debug1: kex: curve25519-sha256@libssh.org need=16 dh_need=16 debug1: kex: curve25519-sha256@libssh.org need=16 dh_need=16 debug1: sending SSH2_MSG_KEX_ECDH_INIT debug1: expecting SSH2_MSG_KEX_ECDH_REPLY debug1: Server host key: ECDSA 3f:00:c1:54:09:7a:aa:50:93:a2:53:83:74:b5:07:8f debug1: Host '123.456.789.0' is known and matches the ECDSA host key. debug1: Found key in /root/.ssh/known_hosts:2 debug1: ssh_ecdsa_verify: signature correct debug1: SSH2_MSG_NEWKEYS sent debug1: expecting SSH2_MSG_NEWKEYS debug1: SSH2_MSG_NEWKEYS received debug1: Roaming not allowed by server debug1: SSH2_MSG_SERVICE_REQUEST sent debug1: SSH2_MSG_SERVICE_ACCEPT received debug1: Authentications that can continue: publickey,gssapi-keyex,gssapi-with-mic,password debug1: Next authentication method: gssapi-keyex # 0 debug1: No valid Key exchange context debug1: Next authentication method: gssapi-with-mic # 1 debug1: Unspecified GSS failure. Minor code may provide more information No Kerberos credentials available debug1: Unspecified GSS failure. Minor code may provide more information No Kerberos credentials available debug1: Unspecified GSS failure. Minor code may provide more information debug1: Unspecified GSS failure. Minor code may provide more information No Kerberos credentials available debug1: Next authentication method: publickey # 2 debug1: Trying private key: /root/.ssh/id_rsa debug1: Trying private key: /root/.ssh/id_dsa debug1: Trying private key: /root/.ssh/id_ecdsa debug1: Trying private key: /root/.ssh/id_ed25519 debug1: Next authentication method: password # 3  发现卡住的位置是 debug1: Next authentication method: gssapi-with-mic 附近。\n证明是由于 gssapi 认证带来的问题。\n从网上找到相关的解释：\n   GSSAPI(Generic Security Services Application Programming Interface) 是一套通用网络安全系统接口。 该接口是对各种不同的客户端服务器安全机制的封装，以消除安全接口的不同，降低编程难度。\n  OpenSSH 在用户登录的时候会验证 IP，它根据用户的 IP 使用反向 DNS 找到主机名，再使用 DNS 找到 IP 地址，最后匹配一下登录的 IP 是否合法。\n   进行身份认证的时候，OpenSSH 虽然说的是 publickey,gssapi-keyex,gssapi-with-mic,password，\n但默认顺序是：gssapi-with-mic → hostbased → publickey → keyboard-interactive → password\n上面连接过程我也标出了 0123，实际顺序的确如此。\ngssapi 的认证是基于 Kerberos 的，没见到人用过，\n另一方面，客户端反向 DNS 的过程也会在连接 DNS 服务器 / 查询客户端域名 (没域名可就会一层层 DNS 查上去) 上花费时间。\n解决办法 客户端，编辑 /etc/ssh/ssh_config 文件：\n 方式 1：将 GSSAPIAuthentication 改为 no； 方式 2：编辑 / 新增 PreferredAuthentications 为 publickey 或者 password，改变认证优先度;  服务端，编辑 /etc/ssh/sshd_config 文件：\n 将 UseDNS 改为 no； (可选) 将 GSSAPIAuthentication 改为 no(所有连接都不做 gssapi 认证了)； 重启 sshd 服务；  实际效果，关闭 GSSAPIAuthentication 让连接时间从 1 分钟下降到 8 秒左右，关闭 UseDNS 后几乎接近秒连。\n","date":1573809485,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1573809485,"objectID":"ece58a690194fc7db09ac460a095a165","permalink":"https://szthanatos.github.io/post/ssh_speed_up/","publishdate":"2019-11-15T17:18:05+08:00","relpermalink":"/post/ssh_speed_up/","section":"post","summary":"报错信息 之前运维给做了几台测试服务器，远程连接的时候速度特别","tags":["ssh"],"title":"加速 ssh 连接","type":"post"},{"authors":[],"categories":[],"content":"目录  硬件需求 0. 工具准备 1. 配置 Nginx 负载均衡 2. 使用 RKE 安装 K8S 3. 初始化 helm 4. 配置 ca 证书 5. 安装 rancher 6. 添加主机别名    硬件需求 rancher ha 推荐的架构是单独搭建一个 K8s 集群部署 Rancher，然后再用这个 Rancher 去管理其他的 K8s 集群。\nrancher 集群的配置和能管理的集群规模之间的关系如下：\n   规模 集群 节点 虚拟 CPU 核数 内存     Small 最多 5 个 最多 50 个 2 8 GB   Middle 最多 15 个 最多 200 个 4 16 GB   Large 最多 50 个 最多 500 个 8 32 GB   X-Large 最多 100 个 最多 1000 个 32 128 GB   XX-Large 100+ 1000+ 联系 Rancher 联系 Rancher    单节点部署的 Rancher 只支持中小规模 (S,M) 的集群。\n我这次部署的机器配置如下：\n   主机名 虚拟 CPU 核数 内存     loadbalance 2 8G   server-01 4 16 GB   server-02 4 16 GB   server-03 4 16 GB    一个负载均衡服务器，3 个服务器组成 K8S 集群。\n操作系统均为 RancherOS 1.54(Console 是 Ubuntu，因为 Longhorn 只支持这个)，Docker 版本 18.09。\n0. 工具准备 在任意一节点 (我这里都是在 server-01 上) 上准备以下工具：\n   工具 说明 版本     kubectl Kubernetes 命令行工具 kubernetes-v1.16.0   rke Rancher 出品的用于构建 Kubernetes 集群的命令行工具 Release v0.2.8   helm Kubernetes 包管理工具 Helm v2.14.3      kubectl 安装：\nwget https://dl.k8s.io/v1.16.0/kubernetes-client-linux-amd64.tar.gz tar -zxvf kubernetes-client-linux-amd64.tar.gz sudo ln -s $(pwd)/kubernetes/client/bin/kubectl /usr/local/bin/kubectl    rke 安装：\nwget https://github.com/rancher/rke/releases/download/v0.2.8/rke_linux-arm64 sudo ln -s $(pwd)/rke_linux-amd64 /usr/local/bin/rke    helm 安装：\nwget https://get.helm.sh/helm-v3.0.0-beta.3-linux-amd64.tar.gz tar -zxvf helm-v2.14.3-linux-amd64.tar.gz sudo ln -s $(pwd)/linux-amd64/helm /usr/local/bin/helm    1. 配置 Nginx 负载均衡 在 loadbalance 主机上编写 nginx.conf 配置文件：\nworker_processes 4; worker_rlimit_nofile 40000; events { worker_connections 8192; } stream { upstream rancher_servers_http { least_conn; server \u0026lt;IP_NODE_1\u0026gt;:80 max_fails=3 fail_timeout=5s; server \u0026lt;IP_NODE_2\u0026gt;:80 max_fails=3 fail_timeout=5s; server \u0026lt;IP_NODE_3\u0026gt;:80 max_fails=3 fail_timeout=5s; } server { listen 80; proxy_pass rancher_servers_http; } upstream rancher_servers_https { least_conn; server \u0026lt;IP_NODE_1\u0026gt;:443 max_fails=3 fail_timeout=5s; server \u0026lt;IP_NODE_2\u0026gt;:443 max_fails=3 fail_timeout=5s; server \u0026lt;IP_NODE_3\u0026gt;:443 max_fails=3 fail_timeout=5s; } server { listen 443; proxy_pass rancher_servers_https; } }  即使用 stream 方式让 nginx 转发 80/443 端口的 http/https 流量。\n启动 nginx：\ndocker run -d \\ --name lb-nginx \\ --restart =unless-stopped \\ -p 80:80 \\ -p 443:443 \\ -v /nginx.conf:/etc/nginx/nginx.conf \\ nginx:1.14  2. 使用 RKE 安装 K8S 三个作为 rancher-server 的服务器需要配置相互免密。ssh-keygen 生成密钥附加到 authorized_keys 上，不赘述。\n在 server-01 节点，编写 rancher-cluster.yml，告诉 rke 要如何创建集群：\nnodes: - address: \u0026lt;IP_NODE_1\u0026gt; internal_address: \u0026lt;IP_NODE_1\u0026gt; user: rancher role: [controlplane,worker,etcd] - address: \u0026lt;IP_NODE_2\u0026gt; internal_address: \u0026lt;IP_NODE_2\u0026gt; user: rancher role: [controlplane,worker,etcd] - address: \u0026lt;IP_NODE_3\u0026gt; internal_address: \u0026lt;IP_NODE_3\u0026gt; user: rancher role: [controlplane,worker,etcd] services: etcd: snapshot: true creation: 6h retention: 24h  节点的配置项中，\ninternal_address 非必填，如果没有内网 IP 的话可以删去。\n如果没有配置 ssh_key_path，则会默认使用 $HOME/.ssh/id_rsa 建立连接。\n执行\nrke up --config ./rancher-cluster.yml  完成创建，中间如果失败了可以多执行几次，直到最后看到消息\nFinished building Kubernetes cluster successfully.\n说明安装完毕。\nK8S 创建成功后会在根目录生成集群信息 rancher-cluster.rkestate 和配置文件 kube_config_rancher-cluster.yml，\n这两个文件包含访问 K8S 的凭据。\n3. 初始化 helm helm 是由客户端 helm 和服务端 tiller 组成，我们之前安装了 helm 可以调用 helm 命令了。\n为了保存和管理 helm 软件包 (helm charts)，我们还需要在本地启动一个服务端。\n# 创建名为 tiller 的 serviceaccount kubectl -n kube-system create serviceaccount tiller # 授予 tiller 帐户对集群的访问权限 kubectl create clusterrolebinding tiller \\ --clusterrole=cluster-admin \\ --serviceaccount=kube-system:tiller # 安装 tiller，官方国内用的是阿里的源 # helm init --service-account tiller --tiller-image registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:\u0026lt;tag\u0026gt; helm init \\ --service-account tiller \\ --upgrade \\ --tiller-image gcr.azk8s.cn/kubernetes-helm/tiller:v2.14.3 \\ --stable-repo-url https://mirror.azure.cn/kubernetes/charts/ # 测试是否安装成功 kubectl -n kube-system rollout status deploy/tiller-deploy helm version  4. 配置 ca 证书 rancher 支持三种来源的证书，rancher 自生成 / 来自 Let’s Encrypt 的 / 来自文件的。\n前两种都需要额外安装 CERT-MANAGER。\n这里我们采用第一种方式，依据 cert-manager 官方文档：\n# Install the CustomResourceDefinition resources separately kubectl apply --validate=false -f https://raw.githubusercontent.com/jetstack/cert-manager/release-0.11/deploy/manifests/00-crds.yaml # Create the namespace for cert-manager kubectl create namespace cert-manager # Add the Jetstack Helm repository helm repo add jetstack https://charts.jetstack.io # Update your local Helm chart repository cache helm repo update # Install the cert-manager Helm chart helm install \\ --name cert-manager \\ --namespace cert-manager \\ --version v0.11.0 \\ jetstack/cert-manager  使用 kubectl get pods --namespace cert-manager 测试是否安装成功，\n应该能看到 cert-manager，cert-manager-webhook，cert-manager-cainjector 运行中。\n注意 cert-manager 使用的镜像来自 quay.io，可以编辑 charts 中的 values.yaml 来修改镜像源，或者提前从国内源下载好镜像放到服务器上。\n5. 安装 rancher # 在 helm 中添加 rancher 源，建议使用 stable helm repo add rancher-stable https://releases.rancher.com/server-charts/stable helm repo update # 安装 rancher helm install rancher-stable/rancher \\ --name rancher \\ --namespace cattle-system \\ --set hostname=\u0026lt;你的域名\u0026gt;  等待一段时间，可以运行 kubectl -n cattle-system rollout status deploy/rancher 查看安装进度。\n6. 添加主机别名 由于没有内部 DNS 服务器，我们还需要为 Agent Pod 添加主机别名 (/etc/hosts)。\n不然\n K8S 集群运行起来之后，因为 cattle-cluster-agent Pod 和 cattle-node-agent 无法通过 DNS 记录找到 Rancher Server URL, 最终导致无法通信。\n 所以我们需要 (以下步骤直接复制于 Rancher2.0-CN 文档)：\n   cattle-cluster-agent Pod 和 cattle-node-agent 需要在 LOCAL 集群初始化之后才会部署，所以先通过 Rancher Server URL 访问 Rancher Web UI 进行初始化。\n  执行以下命令为 Rancher Server 容器配置 hosts:\n#指定 kubectl 配置文件 export kubeconfig=xxx/xxx/xx.kubeconfig.yml kubectl --kubeconfig=$kubeconfig -n cattle-system \\ patch deployments rancher --patch '{ \u0026quot;spec\u0026quot;: { \u0026quot;template\u0026quot;: { \u0026quot;spec\u0026quot;: { \u0026quot;hostAliases\u0026quot;: [ { \u0026quot;hostnames\u0026quot;: [ \u0026quot;xxx.cnrancher.com\u0026quot; ], \u0026quot;ip\u0026quot;: \u0026quot;192.168.1.100\u0026quot; } ] } } } }'    通过 Rancher Server URL 访问 Rancher Web UI，设置用户名密码和 Rancher Server URL 地址，然后会自动登录 Rancher Web UI；\n  在 Rancher Web UI 中依次进入 local 集群 / system 项目，在 cattle-system 命名空间中查看是否有 cattle-cluster-agent Pod 和 cattle-node-agent 被创建。如果有创建则进行下面的步骤，没有创建则等待；\n  cattle-cluster-agent pod\nexport kubeconfig=xxx/xxx/xx.kubeconfig.yml kubectl --kubeconfig=$kubeconfig -n cattle-system \\ patch deployments cattle-cluster-agent --patch '{ \u0026quot;spec\u0026quot;: { \u0026quot;template\u0026quot;: { \u0026quot;spec\u0026quot;: { \u0026quot;hostAliases\u0026quot;: [ { \u0026quot;hostnames\u0026quot;: [ \u0026quot;demo.cnrancher.com\u0026quot; ], \u0026quot;ip\u0026quot;: \u0026quot;192.168.1.100\u0026quot; } ] } } } }'    cattle-node-agent pod\nexport kubeconfig=xxx/xxx/xx.kubeconfig.yml kubectl --kubeconfig=$kubeconfig -n cattle-system \\ patch daemonsets cattle-node-agent --patch '{ \u0026quot;spec\u0026quot;: { \u0026quot;template\u0026quot;: { \u0026quot;spec\u0026quot;: { \u0026quot;hostAliases\u0026quot;: [ { \u0026quot;hostnames\u0026quot;: [ \u0026quot;xxx.rancher.com\u0026quot; ], \u0026quot;ip\u0026quot;: \u0026quot;192.168.1.100\u0026quot; } ] } } } }'     这几步花的时间比较长，需要耐心等待。安装过程到此结束。\n","date":1569509919,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1569509919,"objectID":"5146ba62c0f267593c7568eb9cdd8e5c","permalink":"https://szthanatos.github.io/post/rancher_ha/","publishdate":"2019-09-26T22:58:39+08:00","relpermalink":"/post/rancher_ha/","section":"post","summary":"目录 硬件需求 0. 工具准备 1. 配置 Nginx 负载均衡 2. 使用 RKE 安装 K8S 3. 初始化","tags":["rancher"],"title":"基于 Rancher HA 搭建容器云平台","type":"post"},{"authors":[],"categories":[],"content":"目录  介绍 安装 使用  ros 系统服务 docker   cloud-config    介绍 RancherOS 是 Rancher 推出的一个轻量级的 Linux 内核操作系统，专为容器环境而设计。\n按官网的说法，它具有如下特性：\n   官方说法 瞎翻译     Minimalist OS 极简系统 ——当前版本 (v1.5.4) 镜像也只有 146M，还内置了各类虚拟机工具和 N 个版本的 Docker 环境   Comprehensive System Services 综合系统服务——所有的系统服务都可以通过 Compose 文件声明和启动   Improved Security 更安全——没有额外的工具 / 代码，所有应用都跑在容器里，当然更安全   Up-to-Date Version of Docker \u0026amp; Linux 集成最新的 Docker\u0026amp;Linux 发行版——装完系统直接就有 Docker 用，还是最新的，美滋滋   Automated OS Configuration 自动化系统配置——使用 cloud-init 工具解析 cloud-config 文件，统一管理系统级的所有配置，比如网络，docker 源\u0026hellip;   24x7 Enterprise-level Support 不解释\u0026hellip;    简单的来说，当我们开始使用容器化的方式来管理应用和服务的时候，我们自然而然的会发现，我们对操作系统其实没什么需求了 ——环境依赖和工具链由镜像提供，GUI 界面或者浏览器毫无作用，系统内置的各种工具也就是启动一个容器的事\u0026hellip;\n把这些七七八八的都去掉，最后剩下：一个 Linux 内核 + Docker 环境 + 精简但是统一的配置管理 = RancherOS\nRancherOS 的架构也非常简单，除了内核，就是两个 Docker。\n一个系统级的 Docker(system-docker) 接管了系统的绝大部分功能，比如在一般 Linux 上你会用 systemctl restart 重启服务，在这里就是用 system-docker restart 重启一个容器了。\n用户级别的 Docker 也作为一个服务运行在 system-docker 之上，也就是我们一般意义上跑应用的 docker，正常使用。\n安装   在 RancherOS Gitlab 页面 下载对应版本镜像。\n  新建虚拟机，加载 ISO 镜像，默认会以 rancher 用户身份进入一个运行在内存之上的临时 RancherOS，所以建虚拟机的时候内存可以适当大一点，比如 2G\n  新建 / 上传一个 cloud-config.yml 文件，主要内容就是写入你的 ssh 公钥，因为 RancherOS 安装之后就只能通过 ssh + 公钥的方式登陆 (是的，你在虚拟机控制台都进不去)，一个最简单的示例如下：\n# cloud-config ssh_authorized_keys: - ssh-rsa AAA...    没有其他配置了的话，\nsudo ros config valicate -i cloud-config.yml 校验没有格式错误，\nsudo ros install -c cloud-config.yml -d /dev/sda 将 RancherOS 安装到硬盘。\n一路只有 2 个选项，是否要安装？Y，是否要重启？N，因为重启比你卸载光驱还快\u0026hellip; 直接就又进入一个新的临时 RancherOS 了\u0026hellip;\n  手动 sudo poweroff，卸载光驱，重启，看到熟悉的牛头 LOGO，恭喜完成~\n   如果一定要为 rancher 设置一个密码的话，将安装命令替换为：\nsudo ros install -c cloud-config.yml -d /dev/sda --append=rancher.password = 密码\n   我遇到的一个情况，在 Vmware 上安装时，临时 RancherOS 默认没有网， 需要手动配置网卡：\n修改 /etc/network/interfaces 文件，在末尾添加：\nauto eth0 iface eth0 inet static # IP address xxx.xxx.xxx.xxx # 子网掩码 netmask xxx.xxx.xxx.xxx # 广播地址 (可选) broadcast xxx.xxx.xxx.xxx # 所在网段 (可选) network xxx.xxx.xxx.xxx # 网关 gateway xxx.xxx.xxx.xxx # dns 服务器 dns-nameservers xxx.xxx.xxx.xxx  配置好执行 sudo ifup eth0 即可连上网络。\n  使用 整个 RancherOS 自底向上分三个层面进行管理\n   层面 工具 管理     系统管理 ros cloud-config.yml   服务管理 system-docker 类 Compose 文件   应用管理 docker 直接 run    ros ros 是对系统进行管理的工具，所以必须要以 root 权限执行，具体用法可以 help 看一下：\n$ sudo ros help NAME: ros - Control and configure RancherOS built: '2019-08-22T07:44:10Z' USAGE: ros [global options] command [command options] [arguments...] VERSION: v1.5.4 AUTHOR(S): Rancher Labs, Inc. COMMANDS: config, c configure settings # 配置管理 console manage which console container is used # 切换命令行 engine manage which Docker engine is used # 切换 Docker 版本 service, s # 系统服务管理 os operating system upgrade/downgrade # 内核管理 tls setup tls configuration # tls 管理 install install RancherOS to disk # 安装系统 help, h Shows a list of commands or help for one command GLOBAL OPTIONS: --help, -h show help --version, -v print the version  ros config $ ros config NAME: ros config - configure settings USAGE: ros config command [arguments...] COMMANDS: get get value # 获取配置 set set a value # 设定配置 images List Docker images for a configuration from a file # 没用过 generate Generate a configuration file from a template # 没用过 export export configuration # 输出配置，比直接看 cloud-config.yml 全面 merge merge configuration from stdin # 合并配置文件 syslinux edit Syslinux boot global.cfg # 没用过 validate validate configuration from stdin # 校验配置文件格式  所有面向系统的设置都是通过 ros config 进行管理的，默认的配置存放在 /var/lib/rancher/conf/cloud-config.yml 中。未记录的配置修改都会在重启后失效 (是的，sudo passwd 也不能让你下次直接用户名密码登陆，不过有别的办法)\n简单的修改配置可以直接执行 ros config set \u0026lt;key\u0026gt; \u0026lt;value\u0026gt;，比如\nros config set rancher.docker.tls true；\n多个值写成列表，比如\nros config set rancher.network.dns.nameservers \u0026quot;['8.8.8.8','8.8.4.4']\u0026quot;；\n复杂一点的可以写一个小的 yml，然后执行 ros config merge -i \u0026lt;文件\u0026gt; 进行合并， 理论上也可以手动添加到 /var/lib/rancher/conf/cloud-config.yml 中。 但是个人不推荐这样做，因为现在版本的 cloud-config.yml 和 ros config export 输出的不是一回事，待研究。\nros service $ ros service NAME: ros service - USAGE: ros service command [command options] [arguments...] COMMANDS: enable turn on an service # 启用服务 disable turn off an service # 禁止服务 list list services and state # 服务列表 delete delete a service # 删除服务 build Build or rebuild services # 构建 / 重构服务 create Create services # 创建服务 up Create and start containers # 创建并启动服务 start Start services # 启动服务 logs View output from containers # 查看服务日志 restart Restart services # 重启服务 stop Stop services # 停止服务 rm Delete services # 删除服务及镜像 pull Pulls service images # pull 服务镜像 kill Kill containers # 杀死服务容器 ps List containers # 列出服务容器 OPTIONS: --tls Use TLS; implied by --tlsverify --tlsverify Use TLS and verify the remote [$DOCKER_TLS_VERIFY] --tlscacert value Trust certs signed only by this CA --tlscert value Path to TLS certificate file --tlskey value Path to TLS key file --configdir value Path to docker config dir, default ${HOME}/.docker --verbose, --debug --help, -h show help  控制的是随系统启动的服务，用法包括声明文件的写法基本和 Docker Compose 一样，把它理解成 Docker Compose 的替代品就对了。\n别的命令不解释了\u0026hellip;\n系统服务 $ ros s list disabled amazon-ecs-agent disabled container-cron disabled open-iscsi disabled zfs disabled kernel-extras disabled kernel-headers disabled kernel-headers-system-docker enabled open-vm-tools disabled hyperv-vm-tools disabled qemu-guest-agent disabled rancher-server disabled rancher-server-stable disabled amazon-metadata disabled volume-cifs disabled volume-efs disabled volume-nfs disabled modem-manager disabled waagent disabled virtualbox-tools disabled pingan-amc  上面说到系统级的服务都是用 ros s 控制启停，而想要自定义一个系统级的服务的话:\n 用 Docker Compose 语法编写服务的 xxx.yml 文件，一般存放到 /var/lib/rancher/conf/ ros service enable /var/lib/rancher/conf/xxx.yml 启用该服务 ros service up \u0026lt;serviceName\u0026gt; 启动服务，如果一个 Compose 里定义了多个服务，那么需要 ros service up \u0026lt;serviceName1\u0026gt; \u0026lt;serviceName2\u0026gt; \u0026lt;serviceName3\u0026gt; ... 来同时启动  docker 没啥好说的\u0026hellip;Just use it.\ncloud-config 额外说一下这个 cloud-config。\n现有的公有云 / 虚拟化厂商大多支持 cloud-init 工具进行系统配置初始化 (某种意义上的事实标准)。cloud-config 就是为 cloud-init 服务的。RancherOS 在 system-docker 中运行了一个 cloud-init 容器，它会在启动时查找可能位置上的 cloud-config 文件并依此配置系统配置项。\ncloud-config 的语法格式就是标准的 YAML 语法，一个我在用的、比较完整的 cloud-config 的示例如下：\n 使用时请删除掉中文注释\u0026hellip; 给别人演示的时候懒得删注释结果 validate 没问题，但是配置就是不生效\u0026hellip;   # 主机名 hostname: ros-test # 系统配置 rancher: # 替换控制台为 alpine，也可以是 ubuntu/centos/debian... console: alpine # 初始 Docker 源 bootstrap_docker: registry_mirror: \u0026quot;http://dockerhub.azk8s.cn/\u0026quot; # 系统 Docker 源 system_docker: registry_mirror: \u0026quot;http://dockerhub.azk8s.cn/\u0026quot; # 用户 Docker 源 docker: registry_mirror: \u0026quot;http://dockerhub.azk8s.cn/\u0026quot; # 网络 network: interfaces: eth0: # IP 要是 CIDR 格式，要是和子网掩码对不上就上不了网 address: 192.168.0.1/24 # netmask: 255.255.255.0 # broadcast: 192.168.0.255 gateway: 192.168.0.254 mtu: 1500 dhcp: false dns: nameservers: - 114.114.114.114 - 8.8.8.8 # # 扩容现有磁盘不要用 fdisk，除非你想把系统格式化了，用这个就能调整磁盘大小 # resize_device: /dev/sda # 可登录的机器公钥 ssh_authorized_keys: - ssh-rsa ... - ssh-rsa ... # # 挂载新磁盘 # mounts: # - [\u0026quot;/dev/vdb\u0026quot;, \u0026quot;/mnt/s\u0026quot;, \u0026quot;ext4\u0026quot;, \u0026quot;\u0026quot;] # 写文件 write_files: # 修改 apk 使用国内镜像 - path: /etc/apk/repositories permissions: \u0026quot;0755\u0026quot; owner: root content: | https://mirrors.ustc.edu.cn/alpine/latest-stable/main https://mirrors.ustc.edu.cn/alpine/latest-stable/community # 设置 CST 时区 - path: /etc/profile permissions: \u0026quot;0755\u0026quot; owner: root content: | export CHARSET=UTF-8 export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin export PAGER=less # 显示样式 export PS1=\u0026quot;\\[\\e[37m\\][\\[\\e[32m\\]\\u\\[\\e[37m\\]@\\h \\[\\e[36m\\]\\w\\[\\e[0m\\]]\\\\$\u0026quot; # 时区 export TZ='CST-8' umask 022 for script in /etc/profile.d/*.sh ; do if [-r $script] ; then . $script fi done # 确保 ssh 连接时会读取. bashrc - path: /home/rancher/.bash_profile permissions: \u0026quot;0755\u0026quot; owner: rancher content: | # If the shell is interactive and .bashrc exists, get the aliases and functions if [[$- == *i* \u0026amp;\u0026amp; -f ~/.bashrc]]; then . ~/.bashrc fi # 配置. bashrc - path: /home/rancher/.bashrc permissions: \u0026quot;0755\u0026quot; owner: rancher content: | # .bashrc # User specific aliases and functions alias d=\u0026quot;docker\u0026quot; alias di=\u0026quot;docker image\u0026quot; alias dc=\u0026quot;docker container\u0026quot; alias dv=\u0026quot;docker volumn\u0026quot; alias dn=\u0026quot;docker netwrok\u0026quot; # Source global definitions if [-f /etc/bashrc]; then . /etc/bashrc fi # 启动时执行命令 runcmd: # # 两种写法 # - [touch, /home/rancher/test1] # - echo \u0026quot;test\u0026quot; \u0026gt; /home/rancher/test2 # 开机更新 apk 源 - apk update # 启动定时任务服务 - crond  ","date":1567323590,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1567323590,"objectID":"9069bd3a6e93ed1c918cdd04192ab2c0","permalink":"https://szthanatos.github.io/post/rancheros/","publishdate":"2019-09-01T15:39:50+08:00","relpermalink":"/post/rancheros/","section":"post","summary":"目录 介绍 安装 使用 ros 系统服务 docker cloud-config 介绍 RancherOS 是 Rancher 推出的一个轻量级的 Linux","tags":["os","rancher"],"title":"RancherOS 初步使用小结","type":"post"},{"authors":null,"categories":null,"content":"报错信息  Error: Connection reset by peer\n 原因 读写操作发生在连接断开后。\n解决办法  用 info/cluster info 命令检查连接数是否过多 检查 redis-server 是否正确监听配置文件 检查配置文件中 bind 部分，如果是 bind 127.0.0.1 则只允许本地访问 检查配置文件中 protected-mode 部分是否为 no 重启 redis-server  ","date":1560697601,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1560697601,"objectID":"f861d115429da68fcf5c536cadc20043","permalink":"https://szthanatos.github.io/topic/redis/05-troubleshooting/connection_reset/","publishdate":"2019-06-16T23:06:41+08:00","relpermalink":"/topic/redis/05-troubleshooting/connection_reset/","section":"topic","summary":"报错信息 Error: Connection reset by peer 原因 读写操作发生在连接断开后。 解决办法 用 info/cluster","tags":null,"title":"connection reset by peer","type":"book"},{"authors":[],"categories":["KG"],"content":"目录  基本环境 安装 配置 基本用法 加载诸神图 一些基本操作  增操作 删操作   查询    基本环境 底层数据库基于 HBase，检索服务基于 Elasticserach。\n系统运行服务大致如下：\n[root@xnode208 ~] jps 21584 GremlinServer 27857 DataNode 23218 Jps 3251 HMaster 27283 NameNode 21707 Console 17131 Elasticsearch 29503 SecondaryNameNode  安装 下载 janusgraph0.22 安装包 并解压\nwget https://github.com/JanusGraph/janusgraph/releases/download/v0.2.2/janusgraph-0.2.2-hadoop2.zip unzip janusgraph-0.2.2-hadoop2.zip cd janusgraph-0.2.2-hadoop2  配置 在这里我们采用的是启动 gremlin-server 服务时，加载指定配置文件的方法创建图表，所以需要设置 gremlin-server 端以及图表的配置文件。\n  创建 gremlin-server 端配置文件 janusgraph-0.2.2-hadoop2/conf/gremlin-server/socket-gremlin-server.yaml，这里我们复制 gremlin 服务默认的配置文件，在此基础上进行修改\ncp conf/gremlin-server/gremlin-server.yaml conf/gremlin-server/socket-gremlin-server.yaml    修改 socket-gremlin-server.yaml：在配置文件中添加 graphManager; 并在 graphs 项中添加 graph 键及其值，一个键值代表一个图表，值表示对图表的设置 (可添加多个图表，每一个图表都有自己的配置文件)，如：\ngraphManager: org.janusgraph.graphdb.management.JanusGraphManager graphs: { blablabla, graph: conf/gremlin-server/socket-jg-hbase_fyk-server-configraph.properties }    准备上述 socket-gremlin-server.yaml 中对图表进行设置的 properties 文件，conf/gremlin-server/socket-jg-hbase_fyk-server-configraph.properties 文件内容如下：\ngremlin.graph=org.janusgraph.core.JanusGraphFactory graph.graphname=graph storage.backend=hbase # 设置我们本地启动的 hbase 作为底层数据库 storage.hostname=127.0.0.1 index.search.backend=elasticsearch # 设置 Janus graph 自带的 es 作为我们的检索服务 index.search.hostname=127.0.0.1 cache.db-cache = true cache.db-cache-clean-wait = 20 cache.db-cache-time = 180000 cache.db-cache-size = 0.5    基本用法 依次启动 hbase,elasticsearch 以及 gremlin-server，最后进入 gremlin.sh 客户端对图表进行操作\n  hbase\n[root@xnode208 ~] start-hbase.sh    elasticsearch.(注：Janusgraph 自带的 elastic search 服务启动时为确保安全被禁止使用 root 用户)\n[zkr@xnode208 ~] cd /usr/local/janusgraph-0.2.2-hadoop2 [zkr@xnode208 elasticsearch] ./bin/elasticsearch    gremlin-server(启动成功后，会创建我们在配置文件中设计的图表)\n[zkr@xnode208 janusgraph0.2] ./bin/gremlin-server.sh ./conf/gremlin-server/socket-gremlin-server.yaml    gremlin.sh(进入 gremlin 交互式客户端)\n[root@xnode208 janusgraph0.2] ./bin/gremlin.sh gremlin\u0026gt;    加载诸神图 # 连接 gremlin server gremlin\u0026gt; :remote connect tinkerpop.server conf/remote.yaml session ==\u0026gt;Configured localhost/127.0.0.1:8182-[f6db862e-752c-48db-839b-1b5b16f1786a] gremlin\u0026gt; :remote console ==\u0026gt;All scripts will now be sent to Gremlin Server - [localhost/127.0.0.1:8182]-[f6db862e-752c-48db-839b-1b5b16f1786a] - type ':remote console' to return to local mode # 加载诸神图到我们创建的空图表中 gremlin\u0026gt; GraphOfTheGodsFactory.load(graph) ==\u0026gt;null  示例数据描述了一部分希腊诸神以及他们居住的诸神殿的相关关系。\n   符号 含义     粗体键 带索引的键   星标粗体键 具有唯一值的带索引的键   带下划线的键 以顶点为核心的带索引的键   空心箭头边 不能有多个指向的唯一边   尾部划线的边 单向边    在 JanusGraph 中，实体以顶点表示，关系以边表示，顶点和边都可以具有属性。\n一些基本操作 增操作 # 添加顶点 v1 = graph.addVertex(label, 'student'); # 创建第一个顶点 v1 并增加标签 v2 = graph.addVertex(); # 创建第二个顶点没有标签 # 为顶点添加属性 v1.property('id', '1'); # 为顶点 v1 添加 id 属性，值为 1 v3 = graph.addVertex(label,'girl','name','huahua'); # 创建第三个顶点并且增加标签，属性以及属性值 v4 = graph.addVertex(label,'boy','name','wuyanzu','age',18) # 创建第四个顶点添加标签以及多个属性属性值 # 添加边 t1 = v1.addEdge('friends', v2); # 为 v1 添加关系到 v2, 并定义这个关系为 t1 t2 = v1.addEdge('boyfriend', v2); # 两个顶点之间可以增加多种关系 # 为边增加属性 t1.property('reason','cool'); # 为 t1 增加属性 v3.addEdge('boyfriend',v4,'reason','because the reason'); # v3 添加关系到 v4 并且增加关系属性及属性值 # 提交修改 graph.tx().commit();  删操作 # 清空 g.V().drop(); # 删除所有点 / 图 g.E().drop(); # 删除所有边 graph1.close(); JanusGraphFactory.drop(graph1); # 清空图中的所有数据 # 删除顶点 pluto = g.V().has('name','pluto').next();g.V(pluto).drop().iterate(); # 删除 name 属性为 \u0026quot;pluto\u0026quot; 的顶点 g.V().has('keys','ll').drop().iterate(); # 删除 keys 属性为 \u0026quot;ll\u0026quot; 的顶点 g.V().hasLabel('student').has('name','ll').drop().iterate(); # 删除标签为 student，并且顶点属性 name 的值为 \u0026quot;ll\u0026quot; 的顶点 # 删除边 g.E().has('uuu','because the reason').drop().iterate(); # 删除边属性 uuu 的属性值为 because the reason 的边 g.E().hasLabel('boyfriend').has('event','the reason').drop().iterate(); # 删除边标签为 boyfriend 并且边属性 event 的值为 the reason 的边 # 删除顶点标签以及顶点属性 g.V().hasLabel('girl').drop(); # 删除标签 girl 以及标签为 girl 的所有顶点 g.V().properties('name').drop(); # 删除顶点属性 name # 删除边标签、边属性以及属性值 g.E().hasLabel('boyfriend').drop(); # 删除边标签 boyfriend g.E().properties('uuu').drop(); # 删除边属性 uuu g.E().hasLabel(\u0026quot;friend\u0026quot;).properties().drop(); # 删除边标签为 friend 的所有属性以及属性值 g.E().values('because the reason').drop(); # 删除边属性值为 because the reason 以及对应的属性 graph.tx().commit(); # 提交  查询 # 设置 g=graph.traversal(), 方便查询 gremlin\u0026gt; g = graph.traversal() ==\u0026gt;graphtraversalsource[standardjanusgraph[hbase:[127.0.0.1]], standard] # 顶点标签查询 g.V(); # 查看所有顶点 id g.V().label(); # 查看所有顶点标签 g.V().hasLabel(\u0026quot;god\u0026quot;); # 查看所有标签为 god 的顶点 id g.V().filter(label().is('god')); # 用 filter 查看所有标签为 god 的顶点 id g.V().has('name','hercules'); # 查看属性为 name, 值为 hercules 的顶点 # 顶点属性及属性值查询 g.V().valueMap(); # 遍历每个顶点的属性及属性值 (若没有展示空集) g.V().properties(); # 查看所有顶点的属性及属性值 (不展示空) g.V().hasLabel(\u0026quot;god\u0026quot;).values(); # 查看所有顶点标签为 god 的属性值 g.V().hasLabel(\u0026quot;god\u0026quot;).properties(); # 查看顶点标签为 god 的所有顶点属性以及属性值 g.V().values('id'); # 查看顶点属性为 id 的属性值 g.V().properties('id') # 查看顶点属性为 id 的属性及属性值 # 边标签查询 g.E(); # 查看所有顶点之间的边 顶点 id---\u0026gt; 边 ---\u0026gt; 顶点 id g.E().label(); # 查看所有边的标签 (关系) g.E().hasLabel(\u0026quot;battled\u0026quot;) # 查看标签为 battled 的所有边 g.E().filter(label().is('battled')); # 用 filter 查看标签为 battled 的所有边 g.E().has('time',12); # 查看属性 time 的值为 12 的所有边 # 边属性及属性值查询 g.E().valueMap(); # 遍历所有边属性及属性值 g.E().properties(); # 查看所有边属性及属性值 g.E().hasLabel(\u0026quot;battled\u0026quot;).values(); # 查看所有标签为 battled 的边属性值 g.E().hasLabel(\u0026quot;battled\u0026quot;).properties(); # 查看所有标签为 battled 的边属性以及属性值 g.E().values('reason'); # 查看边属性为 reason 的属性值 g.E().properties('reason'); # 查看边属性为 reason 的属性及属性值  ","date":1552830619,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1552830619,"objectID":"0fc099bb9b2b783e1e33cbd161d548d3","permalink":"https://szthanatos.github.io/post/janusgraph/","publishdate":"2019-03-17T21:50:19+08:00","relpermalink":"/post/janusgraph/","section":"post","summary":"目录 基本环境 安装 配置 基本用法 加载诸神图 一些基本操作 增操作 删操","tags":["graphdb","janusgraph","knowledge graph"],"title":"JanusGraph 搭建及简单使用","type":"post"},{"authors":[],"categories":[],"content":"理解Git没有比从三棵树开始更好的了。\n完整的话还是看git文档比较好，说的蛮清楚了。\n三棵树和正向流程    树 用途     HEAD 上一次提交的快照，下一次提交的父结点   Index 预期的下一次提交的快照   Working Directory 沙盒    git的核心工作就是管理这三棵树。git add就是把你工作目录(Working Directory)的修改提交到暂存区(Index)，git commit就是把暂存区的内容同步到仓库里作为一个快照，并移动HEAD指向新快照；额外说一下这个HEAD指针，每一次commit都相当于在仓库(Repository)里生成一个快照， 把N个快照想象成一个右进左出的队列(List)，再想象有一个指针，默认指向队首(最新快照)，告诉你当前到底用的是哪一个版本快照。\nreset 显然，git reset就是对上述行为的反向操作。\nreset的本质其实是移动HEAD指针指向哪个快照，而通过\n --soft——只改变指针指向的快照； --mixed——移动指针的同时也把快照内容同步到暂存区； --hard——三棵树全同步为指针指向的快照；  参数来递进的控制改变是发生在哪几颗树上。再强调一遍，reset的改变的是HEAD指针，而不是文件。即使git reset File的写法是有效的，但它的本质是git reset --mixed HEAD File的缩写，即将File从HEAD指向的快照复制到索引中。HEAD指针永远只能指向一个快照，但是快照是可以局部修改它里面的文件的。\nHEAD~表示前一个快照，HEAD~2表示前两个，依此类推。\ncheckout checkout的本质就有所不同，它关心的是分支(branch)，它的主要作用是让HEAD在不同分支间移动(默认三棵树都会更新)。\n还是拿刚才那个队列举例，分支相当于是平行的一条队列，现在把他放在你脑子里之前那个队列的上方， 由于HEAD指针只能指向一个快照，所以这个时候它可能会在两个队列间“跳动”，checkout就是控制指针上下移动的命令，而reset则是控制指针在当前队列左右(前后)移动。同样的，checkout后面也可以跟一个文件，和git reset --hard [branch] file可能会产生的效果一样。\n","date":1546668801,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1546668801,"objectID":"174a4cfb6476bb134bc3eda05efdeeac","permalink":"https://szthanatos.github.io/post/git/git_trees/","publishdate":"2019-01-05T14:13:21+08:00","relpermalink":"/post/git/git_trees/","section":"post","summary":"理解Git没有比从三棵树开始更好的了。 完整的话还是看git文","tags":["Git"],"title":"Git三棵树和reset/checkout命令","type":"post"},{"authors":[],"categories":["Academic","Hugo"],"content":" 本文是对 Academic 文档 - Writing content 章节 的个人翻译，基于个人理解，不保证绝对准确。\n原文见上方连接。\n  目录  副标题 强调 有序列表 无序列表 图片 图片集 视频  本地视频文件 Youtube Vimeo   链接  标签和分类   Emojis 段落引用 高亮引用 脚注 嵌入文档  Speaker Deck   代码高亮  高亮选项   Twitter tweet GitHub gist LATEX 数学公式  多行方程式 论文摘要   表格 警报 目录    Academic 支持使用 Markdown、LaTeX 数学公式和 Hugo 代码段编写内容。 此外，可以使用 HTML 以实现高级样式。 本文概述最常见的格式选项。\n副标题 ## Heading 2 ### Heading 3 #### Heading 4 ##### Heading 5 ###### Heading 6  强调 # 下划线内为斜体 Italics with _underscores_. # * 内为粗体 Bold with **asterisks**. # 粗体和斜体可以组合 Combined emphasis with **asterisks and _underscores_**. # 双波浪符内为删除线 Strikethrough with ~~two tildes~~.  有序列表 1. First item 2. Another item  无序列表 我个人更习惯用 - * First item * Another item  图片 图片可以存放在你的媒体库 static/img 或你的 页面文件夹。 使用以下任一方式即可引用图片：\n假设图片来自你的 static/img 媒体库：\n{{\u0026lt; figure library=\u0026quot;1\u0026quot; src=\u0026quot;image.jpg\u0026quot; title=\u0026quot;A caption\u0026quot; \u0026gt;}}  假设图片来自你的页面文件夹 (比如 content/post/hello/)\n{{\u0026lt; figure src=\u0026quot;image.jpg\u0026quot; title=\u0026quot;A caption\u0026quot; \u0026gt;}}  带编号和标题的图片：\n{{\u0026lt; figure src=\u0026quot;image.jpg\u0026quot; title=\u0026quot;A caption\u0026quot; numbered=\u0026quot;true\u0026quot; \u0026gt;}}  一般图片：\n![alternative text for search engines](/media/image.jpg)  图片集 为页面包增加一个图片集：\n 在 页面包(也就是你的页面文件夹) 内创建图片集文件夹； 将图片放入图片集文件夹； 粘贴 {``{\u0026lt; gallery album=\u0026quot;\u0026lt;ALBUM FOLDER\u0026gt;\u0026quot; \u0026gt;}``} 到文章中你想要它出现的地方，将 album 参数修改为你文件集的名称；  可选的，要为你的图片集添加标题的话，将下面的实例添加到你扉页的尾部:\n[[gallery_item]] album = \u0026quot;\u0026lt;ALBUM FOLDER\u0026gt;\u0026quot; image = \u0026quot;\u0026lt;IMAGE NAME\u0026gt;.jpg\u0026quot; caption = \u0026quot;Write your image caption here\u0026quot;  另外，想要在图片集中使用网络位置 / 媒体库中的图片；\n  将图片添加到 static/img/ 文件夹；\n  在文章的扉页尾部声明图片引用：\n[[gallery_item]] album = \u0026quot;1\u0026quot; image = \u0026quot;my_image.jpg\u0026quot; caption = \u0026quot;Write your image caption here\u0026quot; [[gallery_item]] album = \u0026quot;1\u0026quot; image = \u0026quot;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-dark.png\u0026quot; caption = \u0026quot;Dark theme\u0026quot;    在正文要显示的位置使用 {``{\u0026lt; gallery album=\u0026quot;1\u0026quot;\u0026gt;}``}\n  视频 页面可以添加以下几种类型的视频。\n本地视频文件 要添加视频，将它放在 static/img/ 媒体库或者页面文件夹内，使用以下任一方式即可引用。\n位于 static/img/ 文件夹下的视频：\n{{\u0026lt; video library=\u0026quot;1\u0026quot; src=\u0026quot;my_video.mp4\u0026quot; controls=\u0026quot;yes\u0026quot; \u0026gt;}}  位于页面文件夹下的视频：\n{{\u0026lt; video src=\u0026quot;my_video.mp4\u0026quot; controls=\u0026quot;yes\u0026quot; \u0026gt;}}  Youtube {{\u0026lt; youtube w7Ft2ymGmfc \u0026gt;}}  Vimeo {{\u0026lt; vimeo 146022717 \u0026gt;}}  链接 [I'm a link](https://www.google.com) [A post]({{\u0026lt; ref \u0026quot;post/hi.md\u0026quot; \u0026gt;}}) [A publication]({{\u0026lt; ref \u0026quot;publication/hi.md\u0026quot; \u0026gt;}}) [A project]({{\u0026lt; ref \u0026quot;project/hi.md\u0026quot; \u0026gt;}}) [Another section]({{\u0026lt; relref \u0026quot;hi.md#who\u0026quot; \u0026gt;}})  想要链接到一个文件，比如 PDF，首先将它放到 static/files/ 文件夹下，然后使用下面方式链接：\n{{% staticref \u0026quot;files/cv.pdf\u0026quot; \u0026quot;newtab\u0026quot; %}}Download my CV{{% /staticref %}}  staticref 的 \u0026quot;newtab\u0026quot; 参数将使链接在新页面打开。\n标签和分类 使用 {``{\u0026lt; list_tags\u0026gt;}``} 生成标签链接列表，使用 {``{\u0026lt; list_categories \u0026gt;}``} 生成分类链接列表。\nEmojis 可用 Emojis 见 Emoji cheat sheet。 下面的这个示例在实际使用时需要把: 和表情名之前的空格去掉：\nI : heart : Academic : smile :  I ❤️ Academic 😄\n段落引用 \u0026gt; This is a blockquote.   This is a blockquote.\n 高亮引用 This is a {{\u0026lt; hl\u0026gt;}}highlighted quote{{\u0026lt; /hl \u0026gt;}}.  This is a highlighted quote.\n脚注 I have more [^1] to say. [^1]: Footnote example.  嵌入文档 下面几种类型的文档可以被嵌入到页面中。\n要插入 谷歌文档 (比如幻灯片) 点击 Google Docs 中的 File \u0026gt; Publish to web \u0026gt; Embed 并复制 src=\u0026quot;...\u0026quot; 部分中的 URL。 之后粘贴到下面代码中：\n{{\u0026lt; gdocs src=\u0026quot;https://docs.google.com/...\u0026quot; \u0026gt;}}  Speaker Deck {{\u0026lt; speakerdeck 4e8126e72d853c0060001f97 \u0026gt;}}  代码高亮 将语言的代码，比如 python，作为参数放在三个反引号之后：(打出来 ``` 就会被解析，只能加空格了)\n` ` `python # Example of code highlighting input_string_var = input(\u0026quot;Enter some data:\u0026quot;) print(\u0026quot;You entered: {}\u0026quot;.format(input_string_var)) ` ` `  效果：\n# Example of code highlighting input_string_var = input(\u0026quot;Enter some data:\u0026quot;) print(\u0026quot;You entered: {}\u0026quot;.format(input_string_var))  高亮选项 Academic 主题使用 highlight.js 作为高亮的来源，并且默认为所有页面启用。 并且，有一些更细粒度的选项可以控制 highlight.js 的显示效果。\n下表列出了 highlight.js 支持的一些选项，包含他们的类型和简短描述。 config.toml 列中的 \u0026ldquo;yes\u0026rdquo; 表示允许在 config.toml 中全局设置， preamble 列中的 \u0026ldquo;yes\u0026rdquo; 表示可以设定在特定页面中。\n   option type description config.toml preamble     highlight boolean 启用 / 禁用高亮 yes yes   highlight_languages slice 选择额外语言 yes yes   highlight_style string 选择高亮样式 yes no    highlight 选项 highlight 选项允许在全局或者特定页面启动 / 禁止语法高亮。 如果没有明确指定的话，默认会认为你设置了 highlight = true。 也就是说，highlight.js 的 javascript/css 文件会出现在每一个页面文件中。 如果你只希望那些真的需要使用的页面才有语法高亮， 你可以在 config.toml 中设置 highlight = false， 之后在需要的页面的扉页覆盖为 highlight = true。 相反，你也可以全局启用语法高亮，在不需要的页面中禁用。 下面给出一张展示不同全局和单独页面设置下，页面是否高亮。\n   config.toml page preamble highlighting enabled for page?     unset or true unset or true yes   unset or true false no   false unset or false no   false true yes    highlight_languages 选项 highlight_languages 选项允许你指定 highlight.js 支持的，但是不是默认支持的常见的语言。 比如，你想在所有页面高亮 Go 和 clojure 语言，那就在 config.toml 中设置 highlight_languages = [\u0026quot;go\u0026quot;, \u0026quot;clojure\u0026quot;]。 另外，如果你想为页面只启用特定的语法高亮，那就去页面扉页设置 highlight_languages。\n在 config.toml 和扉页设置的 highlight_languages 是累加的。 也就是说，如果 config.toml 里设置了 highlight_languages = [\u0026quot;go\u0026quot;]，而扉页设置了 highlight_languages = [\u0026quot;ocaml\u0026quot;]， 那么这个页面会包含两者的高亮文件。\n当你设置了 highlight_languages 之后，相应的高亮脚本会由 cdnjs 服务 提供。 要查看支持的语言，访问 cdnjs page 页面并查找包含 \u0026ldquo;languages\u0026rdquo; 关键字的链接。\nhighlight_languages 选项通过 CDN 提供了一种方便又容易的方式来满足附加语言的高亮需求。 如果 cdnjs 提供的默认的文件不能满足你的需求，你可以通过 个性化指南 中的方法来使用自己的 javascript 文件。\nhighlight_style 选项 highlight_style 选项允许你使用备选的高亮样式。 比如，如果你想使用 solarized-dark 样式，你可以在 config.toml 中设置 highlight_style = \u0026quot;solarized-dark\u0026quot;。\n如果未设置 highlight_style，默认会使用 Academic 提供的或者在你的 static 文件夹下的 /css/highlight.min.css。 Academic 提供的默认样式和 github 是一致的。\n如果设置了 highlight_style，/css/highlight.min.css 就会被忽略，相应的样式会由 cdnjs 服务 提供。 要查看支持的样式列表，访问 cdnjs page 页面并查找包含 \u0026ldquo;styles\u0026rdquo; 关键字的链接。\n可以在 highlight.js demo page 上查看可用样式。\n 不是所有 highlight.js demo page 上列出的样式都在 cdnjs 服务 上可用。 如果你想使用不是由 cdnjs 提供的样式，那么保持 highlight_style 未设置，然后将相应文件放到 /static/css/highlight.min.css。    如果你不想更换 Academic 附带的样式，但是还是想由 cdnjs 提供服务，那么在 config.toml 中设置 highlight_style = \u0026quot;github\u0026quot;。   只有在 config.toml 中设置的 highlight_style 才会生效，在扉页设置的 highlight_style 不会生效。\nTwitter tweet {{\u0026lt; tweet 666616452582129664 \u0026gt;}}  GitHub gist {{\u0026lt; gist USERNAME GIST-ID \u0026gt;}}  LATEX 数学公式 $$\\left [– \\frac{\\hbar^2}{2 m} \\frac{\\partial^2}{\\partial x^2} + V \\right ] \\Psi = i \\hbar \\frac{\\partial}{\\partial t} \\Psi$$   $$\\left [– \\frac{\\hbar^2}{2 m} \\frac{\\partial^2}{\\partial x^2} + V \\right ] \\Psi = i \\hbar \\frac{\\partial}{\\partial t} \\Psi$$  另外，单行的数学公式可以只用单个 $ 包裹：\nThis is inline: $\\mathbf{y} = \\mathbf{X}\\boldsymbol\\beta + \\boldsymbol\\varepsilon$  This is inline: $\\mathbf{y} = \\mathbf{X}\\boldsymbol\\beta + \\boldsymbol\\varepsilon$\n注意 Markdown 的特殊符号需要使用反斜杠转义，才能被识别为数学公式而非 Markdown 关键字。 比如 * 和 _ 应该被替换为 \\* 和 \\_。\n多行方程式 标准 LaTeX 的双反斜杠换行应该被替换为 6 个反斜杠：\n$$f(k;p\\_0^\\*) = \\begin{cases} p\\_0^\\* \u0026amp; \\text{if }k=1, \\\\\\\\\\\\ 1-p\\_0^\\* \u0026amp; \\text {if}k=0.\\end{cases}$$  $$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\\\\n1-p_0^* \u0026amp; \\text {if}k=0.\\end{cases}$$\n论文摘要 由于 Hugo 和 Academic 会尝试解析摘要中的 TOML, Markdown, 以及 LaTeX 内容，论文的 abstract 和 abstract_short 部分应当遵循下面两个方针：\n LaTeX 的反斜杠 \\ 应该被转义为双反斜杠，也就是 \\\\ LaTeX 的下划线 _ 应该被转义为双反斜杠加下划线，也就是 \\\\_  因此，abstract = \u0026quot;${O(d_{\\max})}$\u0026quot; 就会变成 abstract = \u0026quot;${O(d\\\\_{\\\\max})}$\u0026quot;。\n表格 代码：\n| Command | Description | | --------------- | ------------------- | | `hugo` | Build your website. | | `hugo serve -w` | View your website. |  效果：\n   Command Description     hugo Build your website.   hugo serve -w View your website.    警报 在你为文章添加提示、注意项、警告时，警报是一个非常有用的功能。 尤其是对于教程性质的文章。 使用对应的短代码以在文章中显示警报：\n{{% alert note %}} Here's a tip or note... {{% /alert %}}  这会显示为如下 注意 项：\n Here\u0026rsquo;s a tip or note\u0026hellip;   {{% alert warning %}} Here's some important information... {{% /alert %}}  这会展示为如下 警告 项：\n Here\u0026rsquo;s some important information\u0026hellip;   目录 目录对于长文章或者教程 / 文档可能特别有用，在你 Markdown 正文的任何位置使用 {``{% toc %}``} 短代码自动生成目录。\n","date":1546318469,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1546318469,"objectID":"99b7771e3814fdf15ef26819a895b7f2","permalink":"https://szthanatos.github.io/post/academic/trans_writing_content/","publishdate":"2019-01-01T12:54:29+08:00","relpermalink":"/post/academic/trans_writing_content/","section":"post","summary":"本文是对 Academic 文档 - Writing content 章节 的个人翻译，基于个人理解，不保证绝对","tags":["Translation","Academic","Hugo"],"title":"(翻译)Academic 文档 - 内容编写","type":"post"},{"authors":[],"categories":["Academic","Hugo"],"content":" 本文是对 Academic 文档 - Managing content 章节 的个人翻译，基于个人理解，不保证绝对准确。\n原文见上方连接。\n  目录  精选图片 标题图片 数学公式和代码 页面特性 创建一个出版物  自动 手动 关联其它资源   创建博文 创建项目 创建演讲 创建幻灯片 创建课程或文档 创建小部件页面 创建其他页面 (e.g. 简历) 管理列表页 移除内容 查看站点更新 部署站点    这是一个使用 Academic 框架管理你的文章的简短指南。 Academic 提供的内容模板包括出版物、项目、宣讲、新闻 / 博客文章、以及小部件页。 之后，你可能同样对 使用 Markdown、LaTeX 数学公式和代码段进行创作 感兴趣。\n Hugo V0.49 版本在使用本指南中的 hugo new 命令时存在一个 bug，请升级到 V0.50 及以上。   精选图片 要在文章页显示一个精选图片，简单的将名为 featured.*(e.g. featured.jpg) 的图片文件拖拽到文章文件夹即可。\n 如果你的页面在它所属的分类文件夹下没有自己的文件夹 (页面包)， 你可以创建一个和你页面 NAME.md 同名的文件夹 NAME，并将页面文件放入文件夹中，变为 NAME/index.md。 这里有一个 自动迁移工具。 使用页面包需要 Academic v3+ 以及 Hugo v0.50 以上。   想要为图片添加标题或者设置一个焦点以控制图片的裁剪？ 将下方的参数添加到扉页 (也就是 md 文件 +++ 括起来的部分) 的底部以自定义图片的外观。 标题 (caption) 参数支持使用 Markdown 为图片添加标题或描述。 焦点 (focal_point) 参数确保图片自动缩放的时候主要内容始终可见。\n# Featured image # To use, add an image named `featured.jpg/png` to your page's folder. [image] # Caption (optional) caption = \u0026quot;Photo by [Academic](https://sourcethemes.com/academic/)\u0026quot; # Focal point (optional) # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight focal_point = \u0026quot;Smart\u0026quot; # Show image only in page previews? preview_only = false  标题图片 将下面的 header 参数添加到扉页的末尾，以在页面顶部展示一个占据全部宽度的标题图片。 图片文件默认会从静态图片文件库 static/img/ 读取 (所以不必写全)，所以下面例子的图片文件的完整路径是 static/img/header.png。 标题参数作用和精选图一致。\n[header] image = \u0026quot;header.png\u0026quot; caption = \u0026quot;Image credit: [**Academic**](https://github.com/gcushen/hugo-academic/)\u0026quot;  数学公式和代码 要在页面中启用 LaTeX 渲染数学公式，在页面的扉页中应该申明 math = true，如同示例网站的例子一样。 或者，在 config.toml 中设置 math = true，以在全局范围内允许数学公式渲染。\n在 config.toml 中设置 highlight = false 以全局禁用代码高亮。你可以在需要代码高亮的页面的扉页单独设置 highlight = true。 查看 code-highlighting docs 以获取更多细节。\n页面特性 将下述参数添加到页面扉页以管理页面特性：\nreading_time = false # 显示估计阅读时间 share = false # 显示分享按钮 profile = false # 显示作者信息 comments = false # 显示评论区  创建一个出版物 自动 先进的文献管理工具可以帮助你将你的出版物转化为开源的 BibTeX 格式。 如果你是新手的话我们推荐你使用流行的开源工具 Zotero 来管理你的文献。\n在你的文献管理工具中创建你自己的出版物列表并导出为 *.bib 格式的 BibTeX 文件。\n工具需要 Python3 环境，所以请先 安装 Python3。 同样，为了让你有机会检查 Academic 管理工具产生的改变，你需要备份你的站点，或者确保它已经处于 Git 的管理之中。\n打开你的终端或者命令提示符应用，安装 Academic 管理工具：\npip3 install -U academic  使用 cd 命令进入你的站点目录。\n之后，导入你的出版物：\nacademic import --bibtex \u0026lt;path_to_your/publications.bib\u0026gt;  这个工具尚处于测试阶段，目的是为了给你提供辅助。 所以在发布你的站点之前你应该检查 publications 文件夹下产生的内容。 你同样可以看看下一章节 手动 部分有关扉页参数的细节，以想办法增强展示效果。\n想要支持这个工具或者提供建议 / 反馈，请查看 Academic admin tool 项目主页。\n手动 另一种选择，使用命令手动的创建出版物：\nhugo new --kind publication publication/\u0026lt;my-publication\u0026gt;  \u0026lt;my-publication\u0026gt; 是你得出版物的名称，使用 - 代替空格。\n之后，编辑 content/publication/\u0026lt;my-publication\u0026gt;/index.md 内含有你的出版物信息的参数。主要参数如下：\n title: 标题 date: 发布日期 (必须使用有效的 TOML 日期格式) publication_types: 使用图例来说明你出版物的类型, e.g. conference proceedings publication: 你的出版物发布在什么地方 - 允许使用 Markdown 以标注斜体或其他. abstract: 摘要  使用 Markdown 格式将你出版物的细节写到文档的正文部分 (在 +++ 部分之后)。 内容会出现在你的出版物页之上。\n要使访客能够阅读到你的作品，将作品的 PDF 链接填入 url_pdf，或者将作品 PDF 文件放置到出版物目录并统一为相同命名，这样会自动生成 PDF 的链接。 举例，如果你的出版物说明位于 publication/photons/index.md，将 PDF 文件重命名并放到 publication/photons/photons.pdf。\n关联其它资源 使用 url_ 链接以指向本地 / 网络内容。 要关联本地内容的话将之复制到出版物文件夹并使用例如 url_code = \u0026quot;code.zip\u0026quot; 的方式添加引用。\n你也可以将下面的代码块添加到扉页，以使用自定义链接按钮：\nurl_custom = [{name = \u0026quot;Custom Link 1\u0026quot;, url = \u0026quot;http://example.org\u0026quot;}, {name = \u0026quot;Custom Link 2\u0026quot;, url = \u0026quot;http://example.org\u0026quot;}]   想要在扉页的参数中使用双引号或者反斜杠需要额外添加一个反斜杠，例子懒得翻，更多信息请参阅 TOML 文档。   创建博文 要创建一篇新文章：\nhugo new --kind post post/my-article-name  然后用你的完整标题和内容填充新生成的 content/post/my-article-name.md 文件。\nAcademic 会自动生成内容摘要并显示在主页上。 如果你不满意自动生成的摘要内容，你可以在文章内容中放置 \u0026lt;!``--more--\u0026gt; 以限定摘要的长度， 或者像这样：\nsummary = \u0026quot;Summary of my post.\u0026quot;  在扉页内添加 summary 参数以覆盖自动生成的摘要。\n要为特定的文章禁止评论，在扉页添加 disable_comments = true 参数。 要全局的禁止评论的话，在 config.toml 中设置 disqusShortname = \u0026quot;\u0026quot; 或者 disable_comments = true。\n创建项目 要创建一个项目：\nhugo new --kind project project/my-project-name  之后编辑新生成的 content/project/my-project-name.md 文件。 在扉页将 external_link = \u0026quot;http://external-project.com\u0026quot; 设置成已经存在的项目网址， 或者也可以手动在正文中介绍项目的情况。\n创建演讲 要创建一个演讲：\nhugo new --kind talk talk/my-talk-name  然后用你的完整标题和内容填充新生成的 content/talk/my-talk-name.md 文件。 你会注意到演讲的很多参数和出版物是类似的。\n创建幻灯片 可以使用 Markdown 非常高效的创建幻灯片并通过你的网站分享给观众。 甚至还包括演讲者笔记。\n查看 slides demo ——尽管你可以注意到这个幻灯片是由 Hugo 团队制作的，并且他们缩减了一些功能。 运行 themes/academic/exampleSite/ 下的示例站点以查看完整的包含演讲者笔记的示例。\n查看 themes/academic/exampleSite/content/slides/example-slides.md 内的 example slide deck 以开始学习。\n在演讲 / 出版物页面使用 url_slides 参数来关联到幻灯片。 比如，url_slides = \u0026quot;slides/example-slides\u0026quot; 可以关联到上面的示例站点。 在 这里 可以看到包含 url_slides 的完整扉页的示例。\n创建课程或文档 文档 是用来 分享知识 的。常见例子包括在线课程、教程、软件文档以及知识库。\n你现在阅读的这个页面 (不是我翻译之后的这个) 就是用_文档_的方式来展现 Academic 相关的。 同样，这里也有一个 在线课程 的例子。\n查看 themes/academic/exampleSite/content/tutorial/ 的示例以学习如何开始。\n如果你是一名使用 R 语言的数据分析师 / 数据科学家 (e.g. RStudio and RMarkdown)，我们推荐你阅读 R boilerplate project on GitHub。\n创建小部件页面 你是否想利用 Academic 的小部件系统，创建一个和 Academic 主页类似的页面？\n在你的 content 文件夹下创建一个新的，以你的页面命名的文件夹。在这个例子中我们将创建 content/tutorials/ 文件夹以创建我们的 tutorials 页。\n在新建的 content/tutorials/ 文件夹下创建一个名为 _index.md 的文件，内容如下：\n+++ title = \u0026quot;Tutorials\u0026quot; # Add a page title. date = 2017-01-01T00:00:00 # Add today's date. widgets = true # Page type is a Widget Page. summary = \u0026quot;\u0026quot; # Add a page description. +++  将你的小部件放入 content/tutorials/ 文件夹，可以通过复制 content/home/ 下的小部件或者从 Github 上下载来实现。\n创建其他页面 (e.g. 简历) 其他类型内容的话，可以创建自己的自定义页面。 例如，我们在 content 文件夹下创建一个 cv.md 简历页面。复制任意一个文章的扉页，根据需要进行调整，然后在下面编辑 Markdown 内容。 再之后，您可以使用 [My CV]{``{\u0026lt; ref \u0026quot;cv.md\u0026quot; \u0026gt;}} 代码将简历添加到任何现有页面的内容上。\n或者，在上面的例子中，我们可以使用简历的 PDF 文件。为此，在 static 文件夹中创建名为 files 的文件夹，并将名为 cv.pdf 的 PDF 文件移动到该位置。 然后可以使用以下代码将 PDF 文件链接到你的任意内容中：{``{% staticref \u0026quot;files/cv.pdf\u0026quot; %}}`` 下载我的简历 ``{``{% /staticref %}}。\n管理列表页 档案 (archive，我理解的就是列表) 页或者说节点页，是列出你所有内容的特殊页面。 博客文章、出版物、演讲都会有列表页。 如果存在一个小部件放不下的内容的话，主页上的小部件会自动链接到列表页。 因此，如果你没有足够多的内容的话你可能不会看到自动生成的链接—— 不过你也可以在文章中用一般的 Markdown 链接格式，手动的链接他们。\n你可以通过将以下 _index.md 文件从示例站点复制到你的 content/ 文件夹中的相同位置，来编辑标题并添加自己的内容（比如简介）：\n/themes/academic/exampleSite/content/post/_index.md /themes/academic/exampleSite/content/publication/_index.md /themes/academic/exampleSite/content/talk/_index.md  之后，根据需要编辑每个 _index.md 中的 title 参数，并在扉页之后添加任何内容。 你可能注意到 _index.md 文件略有不同，其中一些具有可用于关联内容类型的特殊选项。 例如，publication/_index.md 包含用于设置出版物列表页面上显示的列表的引用样式的选项。\n移除内容 通常来说，要移除任意内容，简单的从你的 content/post、content/publication、content/project 或者 content/talk 文件夹中删除对应页面文件即可。\n查看站点更新 在你对站点做出修改之后，你可以通过执行 hugo server 并在浏览器中打开 http://localhost:1313/ 来看到效果。\n部署站点 最后，你可以 部署你的站点 了。\n","date":1546318451,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1546318451,"objectID":"e606c1cb482650d4c431e8646f99c1d8","permalink":"https://szthanatos.github.io/post/academic/trans_managing_content/","publishdate":"2019-01-01T12:54:11+08:00","relpermalink":"/post/academic/trans_managing_content/","section":"post","summary":"本文是对 Academic 文档 - Managing content 章节 的个人翻译，基于个人理解，不保证绝对","tags":["Translation","Academic","Hugo"],"title":"(翻译)Academic 文档 - 内容管理","type":"post"},{"authors":[],"categories":[],"content":"目录  简介 安装 tmux 基础概念 配置 常用控制  会话 窗口 窗格 tpm 插件   鼠标操作    简介 Tmux 是一个终端复用软件，默认的 Linux 终端一个会话只能干一件事，有了 tmux 就能在一个窗口同时管理多个前 / 后台程序了。\n安装 tmux 基础软件，跳过\n基础概念 见图\n Session：输入 tmux 后就创建了一个会话，一个会话是一组窗体的集合； Window：会话中一个可见的窗口； Pane: 一个窗口可以分成多个窗格；  用 win10 任务视图 (Win+Tab 调出) 的概念来类比，\nPane 就是一个个应用窗口，在一个桌面上可以同时开多个 (但是不能堆叠，)；\nWindow 就是一组组桌面，同一时间你只能看到一个桌面\nSession 就是一个用户，区别就是 win10 同一个账户只能登陆一次，tmux 里相当于一个用户登陆 N 次。\n为了控制这些元素，tmux 分为三种模式：\n 控制模式: （按下或者按住前缀 (tmux-prefix)，默认 ctrl+b, 下文用 ※ + X 表示按下前缀之后按 X，※※ + Y 表示按住前缀的同时按 Y）相当于各种热键； 命令模式: （输入 tmux 后接命令，或者在 tmux 内输入 ※ + shift + :）也就是输入命令，但是执行的不是系统命令，而是 tmux 自身的命令； 一般模式: 正常打字；  配置 和 zsh 一样，得先配置才能用的舒坦。下面是我个人用的配置文件。\nCtrl+b 被我替换为 Ctrl+x，横竖分割窗格我分别设置为 - 和 \\，刚好一横一竖嘛，并且启用了 tpm 管理 tmux 插件。\n#-- base --# # (可选) 设置 zsh 为默认 shell set -g default-shell /bin/zsh #-- settings --# set -g mouse on # 开启鼠标切换窗格，按住 shift 复制粘贴 set -g base-index 1 # 窗口编号从 1 开始计数 set -g renumber-windows on # 关掉某个窗口后，编号重排 set -g pane-base-index 1 # 窗格编号从 1 开始计数 set -g display-panes-time 5000 # PREFIX-Q 显示编号的驻留时长，单位 ms setw -g mode-keys vi # 进入复制模式的时候使用 vi 键位（默认是 EMACS） setw -g allow-rename off # 禁止活动进程修改窗口名 setw -g automatic-rename off # 禁止自动命名新窗口 set -g default-terminal \u0026quot;tmux-256color\u0026quot; # 开启 256 colors 支持 #-- bindkeys --# # 以下 3 行设置 ctrl+x 代替 ctrl+b 的快捷键 set -g prefix C-x unbind C-b bind C-x send-prefix # 设置 tmux-prefix + \\ 垂直分割窗格 unbind % bind \\ split-window -h # 设置 tmux-prefix + - 水平分割窗格 unbind '\u0026quot;' bind - split-window -v # 设置 ctrl+vim 方式切换窗格 bind -n C-h select-pane -L bind -n C-j select-pane -D bind -n C-k select-pane -U bind -n C-l select-pane -R # plugins # tmux plugin manager 插件管理 set -g @plugin 'tmux-plugins/tpm' set -g @plugin 'tmux-plugins/tmux-sensible' # 保存布局插件，tmux-prefix + ctrl+s/tmux-prefix + ctrl+r 保存 / 恢复 set -g @plugin 'tmux-plugins/tmux-resurrect' # 自动保存插件 set -g @plugin 'tmux-plugins/tmux-continuum' # tmux-resurrect 配置 # 恢复 shell 的历史记录, 只有无前台任务运行的窗格 才能被保存 set -g @resurrect-save-bash-history 'on' # 恢复窗格内容, 目前使用该功能时，请确保 tmux 的 default-command 没有包含 \u0026amp;\u0026amp; 或者 || 操作符， # 否则将导致 bug。（查看 default-command 的值，请使用命令 tmux show -g default-command。） set -g @resurrect-capture-pane-contents 'on' # 恢复 vim 会话 set -g @resurrect-strategy-vim 'session' # set -g @resurrect-save 'S' # set -g @resurrect-restore 'R' # tmux-continuum 配置 # 开启自动恢复 set -g @continuum-restore 'on' # 设置备份间隔（分钟，0 为不自动备份） set -g @continuum-save-interval '240' # 状态栏查看备份状态 # Initialize TMUX plugin manager (keep this line at the very bottom of tmux.conf) set -g status-right 'Continuum status: #{continuum_status}' run '/etc/.tmux/plugins/tpm/tpm'  具体配置步骤如下：\n 编辑 .tmux.conf 文件放到你的根目录下； 使用 git clone https://github.com/tmux-plugins/tpm /etc/.tmux/plugins/tpm 将 tpm 安装到 etc 目录下 (或者随你喜欢，我是个人和 root 共用一套配置，所以放个公共的地)； 输入 tmux source-file ~/.tmux.conf 载入配置； 进入 tmux，输入 ※ + U 查看 tpm 插件更新，弹出页面默认打开命令模式，直接输入 all 完成更新；  常用控制  注意，下列所有快捷键区分大小写。   会话    按键 说明     ※ + d 休眠   ※ + s 以菜单方式显示和选择会话   ※ + L 切换回上一次的会话    窗口    按键 说明     ※ + c 创建新窗口   ※ + n 选择下一个窗口   ※ + p 选择前一个窗口   ※ + l 最近一次活跃窗口之间进行切换   ※ + 0~9 选择几号窗口   ※ + , 重命名窗口   ※ + . 更改窗口的编号，但只能更改成未使用的编号，所以要交换窗口的话，得多次更改进行交换   ※ + \u0026amp; 关闭窗口   ※ + w 以菜单方式显示及选择窗口   ※ + f 在所有窗口中查找内容    窗格    按键 说明     ※ + z 最大化 / 还原当前窗格   ※ + \u0026quot; 模向分隔窗格，替换为了 -   ※ + % 纵向分隔窗格，替换为了 \\   ※ + o 跳到下一个分隔窗格   ※ + x 关闭窗格   ※ + ; 切换到最后一个使用的窗格   ※ + ↑/↓/←/→ 切换到上 / 下 / 左 / 右的窗格   ※※ + h/j/k/l 自定义配置，vim 方式切换窗格   ※ + q 显示窗格编号，并在右上角显示窗格的长宽   ※ + 空格键 自动排布窗格，可多次执行尝试多种布局    tpm 插件    按键 说明     ※ + S 自定义配置，保存当前布局   ※ + R 自定义配置，还原保存的布局    鼠标操作 鼠标按住窗格的分割线可以修改窗格大小；\n如果你用 wsltty 或者其他软件，发现右键 / 中键失效，记得按住修饰键 (比如 Shift) 再试。\n","date":1546316825,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1546316825,"objectID":"3da3e4593fc1e22e7ffd06cafeaba9bd","permalink":"https://szthanatos.github.io/post/tmux/","publishdate":"2019-01-01T12:27:05+08:00","relpermalink":"/post/tmux/","section":"post","summary":"目录 简介 安装 tmux 基础概念 配置 常用控制 会话 窗口 窗格 tpm 插件 鼠标操作","tags":["Tmux"],"title":"Tmux in 10 minutes","type":"post"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1546300800,"objectID":"8576ec274c98b3831668a172fa632d80","permalink":"https://szthanatos.github.io/about/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/about/","section":"","summary":"real me","tags":null,"title":"about","type":"widget_page"},{"authors":[],"categories":[],"content":"目录  Deploy key/SSH key(github) 更换 git 协议 强制覆盖本地文件 撤销修改  add 之前撤销 commit 之前撤销 push 之前撤销   删除历史提交记录 忽略文件权限    Deploy key/SSH key(github) Deploy key 是在 项目主页-setting-Delpoy keys 下进行添加，如果勾选 Allow write access，则相当于具有对这个项目的读写权限 (否则只能 clone 不能 push)。作用范围是这个项目。\nSSH key 是在你 个人主页-Settings-SSH and GPG keys 下进行添加。作用范围是你的账户下的所有项目。\n同一个 公钥，只能作为整个账户的 SSH key，或者 一个项目 的 Deploy key。想为一台机器授予多个项目的读写权限的话，需要通过 ssh-keygen 生成多个密钥，分别作为不同项目的 Deploy key。\n更换 git 协议 使用 http/https 协议连接仓库相比 ssh 即不够安全，也会存在 push 的时候必须输入用户名密码的问题。\n使用 git remote -v 可以查看项目使用的协议。\n如果是新建的项目，推荐在一开始就使用 git@github.com:{USER}/{PROJECT}.git 进行 clone。这样默认都是用 ssh 了。\n如果是已有项目，使用 git remote set-url {repository} {url} 更改。\n$ git remote -v origin https://github.com/abc/bcd.git (fetch) origin https://github.com/abc/bcd.git (push) $ git remote set-url origin git@github.com:abc/bcd.git $ git remote -v origin git@github.com:abc/bcd.git (fetch) origin git@github.com:abc/bcd.git (push)  强制覆盖本地文件 啥都别说了，直接重来吧：\ngit fetch --all git reset --hard origin/master  撤销修改 add 之前撤销 # 单个文件 git checkout FileName # 所有文件 git checkout .  commit 之前撤销 # 取消暂存 git reset HEAD FileName # 撤销修改 git checkout FileName  push 之前撤销 git reset [--hard|soft|mixed] [commit|HEAD]  删除历史提交记录 commit 多了项目也会膨胀\u0026hellip; 清了一干二净。\n# 用 orphan 参数创建全新的分支 git checkout --orphan {new_branch} # 添加所有文件 git add -A # 提交 git commit -am \u0026quot;commit message\u0026quot; # 删除原始分支 git branch -D {old_branch} # 交换分支 git branch -m {old_branch} # 强制提交变更 git push -f origin {old_branch}  忽略文件权限 文件在系统间转移的时候可能由于权限改变而使文件全都处于 \u0026ldquo;modified\u0026rdquo; 状态。（比如从 linux 到 Windows，权限会从 644 变成 755）可以以项目为单位设置忽略文件权限：\ngit config core.filemode false  ","date":1544751332,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544751332,"objectID":"41ca8042ced159c6adfa318d52fa28c9","permalink":"https://szthanatos.github.io/post/git/git_tips/","publishdate":"2018-12-14T09:35:32+08:00","relpermalink":"/post/git/git_tips/","section":"post","summary":"目录 Deploy key/SSH key(github) 更换 git 协议 强制覆盖本地文件 撤销修改 add 之前撤销 commit 之前","tags":["Git"],"title":"Git Tips","type":"post"},{"authors":[],"categories":[],"content":"目录  Hugo 安装 / 更新  安装 / 更新 常用命令   Academic 安装 / 更新  通过 Netlify 通过 Git   部署到 Github Pages  原理 官方教程 (缩减版) 脚本   个性化配置  config.toml 主要配置项解释 修改网站 logo 给文章添加精选图 给文章添加头部背景 目录 注意 / 警告标识 消除短代码效果 修改模板      Hugo 安装 / 更新 Hugo 是使用 Go 语言开发的静态站点生成器。不过无需准备 Go 语言环境，可以直接通过二进制编译包进行跨平台部署。\n以下均以 Ubuntu18.0 为例。\n安装 / 更新  前往 Github 页面 下载最新版本，这里我们下载 hugo_0.52_Linux-64bit.deb; 使用命令 dpkg -i hugo_0.52_Linux-64bit.deb 安装 hugo; 更新即重复上面两步，覆盖安装即可;  常用命令  hugo： 编译项目生成静态网站，默认位置在项目的 public 目录下 hugo server： 启动你的网站服务，可以通过浏览器访问 http://127.0.0.1:1313/ 访问站点; hugo new {folder}/{name}.md: 创建新文章，使用 markdown 进行排版，一般默认放在 post 文件夹下；  基本没了，一般情况下用这三个命令就够了。\nAcademic 安装 / 更新 Academic 是一个 Hugo 主题，从名字就可以知道这个主题比较学院派，适合科研 / 学术人员发布个人信息 / 介绍科研项目，当然，拿来做个人博客也是没问题的。\n通过 Netlify Academic 推荐使用第三方博客管理平台 Netlify 安装，如果你没有域名或者没想建站，只是想自己使用，那我建议不使用它的服务——请直接跳到下一部分，否则跟随网站引导完成安装;\n通过 Git 安装  通过 git 安装的话，首先建议你在 GitHub 上 fork 成你自己的项目，默认的话，通过 git clone https://github.com/sourcethemes/academic-kickstart.git My_Website 将代码克隆到本地文件夹 My_Website (当然，更推荐使用 ssh 协议，更安全，也免于 push 时输入密码，这里暂时按官方的来) ; 进入文件夹，初始化项目：git submodule update --init --recursive，完成安装;  自动更新 说是自动，还是需要手动执行一条命令：git submodule update --remote --merge;\n这么做的前提条件是你是 install 的，也就是 git submodule update --init --recursive 过的，而不是直接把 academic 给 clone 到 themes 文件夹。\n手动更新 如果是 clone 到 themes 文件夹的话要这么更新：\n cd themes/academic; 将 origin 仓库重命名为 upstream：git remote rename origin upstream; 将更新下载到本地：git fetch upstream; 列出可用更新：git log --pretty=oneline --abbrev-commit --decorate HEAD..upstream/master; 更新：git pull upstream;  部署到 Github Pages 原理 网上介绍的办法很多，但核心其实就一句：\n将 hugo 命令生成的 public 文件夹上传到 GitHub pages 项目下。\npublic 文件夹相当于编译完成的静态网站，你在本地打开其实就能看。换句话说，你每次手动将这个目录下的内容上传到你的 GitHub page 项目也是可以的。\n然后为了达到这个目的，Academic 给出的做法是利用 git submodule 将你的 GitHub page 项目作为 My_Website 项目的子模块存放到 public 目录。那么当你更新你的文章之后，只提交 public 文件夹内的变更到 GitHub page 项目即可。\n官方教程 (缩减版) 原教程 看这里；\n  在 GitHub 上创建两个项目，一个是 fork 的 academic-kickstart，也就是你前面 clone 到本地的 My_Website，另一个即是以你用户名 / 组织名开头、以 .github.io 结尾的 GitHub page 项目。\n  在 My_Website 目录下执行 git submodule update --init --recursive 将子模块更新到最新状态；\n  将 config.toml 中的 baseurl 设置为你的 GitHub page 地址；\n  (实质) 删除 public 文件夹 (如果有的话)，将 GitHub page 项目添加为子模块：git submodule add -f -b master https://github.com/\u0026lt;USERNAME\u0026gt;/\u0026lt;USERNAME\u0026gt;.github.io.git public;\n 这时候你的 My_Website 项目实际上有两个子模块：作为主题依赖的 themes/academic 和作为网站的 \u0026lt;USERNAME\u0026gt;.github.io；\n有意思的是一般是子模块 themes/academic 更新了之后，你更新主项目 My_Website 的依赖；\n而你更新主项目 My_Website 的文章之后，再会手动的更新子模块 \u0026lt;USERNAME\u0026gt;.github.io，刚好反过来。\n   新增 / 编辑文章后，更新 academic-kickstart 项目：\ngit add . git commit -m \u0026quot;Initial commit\u0026quot; git push -u origin master    更新 GitHub page 项目：\nhugo cd public git add . git commit -m \u0026quot;Build website\u0026quot; git push origin master    实际上只有第六步是更新 GitHub page，每次重复执行这一部分就行 (如果你不把文章保存到 academic-kickstart 的话)。\n脚本 Hugo 官方把上面步骤打包到了一个脚本：\n#!/bin/bash echo -e \u0026quot;\\033[0;32mDeploying updates to GitHub...\\033[0m\u0026quot; # Build the project. hugo # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;` # Go To Public folder cd public # Add changes to git. git add . # Commit changes. msg=\u0026quot;rebuilding site `date`\u0026quot; if [$# -eq 1] then msg=\u0026quot;$1\u0026quot; fi git commit -m \u0026quot;$msg\u0026quot; # Push source and build repos. git push origin master # Come Back up to the Project Root cd ..  实际上我们干脆连第五步也放进去呗：\n#!/bin/bash # Receive args. if [$1 = \u0026quot;push\u0026quot;]; then if [$# -eq 1]; then TIME_NOW=$(date +%T\\ %F) MSG=\u0026quot;Change something nobody knows at ${TIME_NOW}...\u0026quot; EDITED_FILE=\u0026quot;.\u0026quot; elif [$# -eq 2]; then MSG=\u0026quot;$2\u0026quot; EDITED_FILE=\u0026quot;.\u0026quot; elif [$# -gt 2]; then MSG=\u0026quot;$2\u0026quot; shift 2 EDITED_FILE=\u0026quot;$*\u0026quot; else echo \u0026quot;WTF?\u0026quot; fi echo \u0026quot;\\033[0;32m --------------------------- Deploying to GitHub Page... --------------------------- \\033[0m\u0026quot; # Build the project. hugo # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;` # Go To Public folder cd public # Add changes to git. git add . # Commit changes. git commit -m \u0026quot;$MSG\u0026quot; # Push source and build repos. git push origin master # Come Back up to the Project Root cd .. echo \u0026quot;\\033[0;32m ----------------------------- Updating content to GitHub... ----------------------------- \\033[0m\u0026quot; # Add changes to git. git add $EDITED_FILE # Commit changes. git commit -m \u0026quot;$MSG\u0026quot; # Push source and build repos. git push origin master elif [$1 = \u0026quot;pull\u0026quot;]; then # Update main repo. git pull # Update submodule. git submodule update echo \u0026quot;Synchronize finish.\u0026quot; else echo \u0026quot;Determine What you wanna do.\u0026quot; fi  将脚本保存为 deploy.sh，放到项目根目录下，完成修改后执行 ./deploy.sh + pull/push 一键从服务器同步 / 提交 + 部署。\n参数的第一个是你要执行的动作，从远程服务器 down 到本地的话就是 ./deploy.sh pull，不用接别的。\n如果是要将更新上传到服务器并部署，那就执行 ./deploy.sh push + commit message，提交消息可以不写 (但最好还是写一下)：\n./deploy.sh push \u0026quot;{Your optional commit message}\u0026quot;。\n如果修改了多个文件，只想提交其中的一部分文件以保持 commit 的纯净，那就在 mesaage 后面附加你要提交的文件路径 (不超过 10 个\u0026hellip;)：\n./deploy.sh push \u0026quot;{Your optional commit message}\u0026quot; path1 path2...。\n个性化配置 项目目录结构大体如下：\n content 目录： 网站内容，home 是你的主页的小控件，post 是默认文章存放位置 public 目录： 生成的静态页面 resouces 目录： JS 资源存放位置 static 目录： 静态资源存放位置 themes 目录： 主题文件所在目录 config.toml: 全局配置文件  config.toml 主要配置项解释    配置项 说明     baseurl 你的站点的 url，不设置这个你的文章 / 资源可能相互引用不到   title 网站标题   defaultContentLanguage 默认语言，中文的话填 zh，在文件末尾还有一处配置要同时修改才行   hasCJKLanguage 是否有中 / 日 / 韩语   defaultContentLanguageInSubdir 目录是否允许用默认语言，true 就对了   highlight_languages 语法高亮，支持的语言可以去 highlight.js 查到   [[menu.main]] 这部分是你主页上标题栏显示的内容，url 默认和你 content/home 下的文件名对应   Languages 添加中文支持的话，把 [languages.zh] 部分解除注释，languageCode 写 \u0026quot;zh-cn\u0026quot;，添加其他语种的话，相同格式再写一组 [languages.XX] 即可，支持的语言代码可以在 themes\\academic\\i18n 查看    修改网站 logo 默认的 logo 是 Academic 的蓝色学位帽，想替换的话将你想用的 logo 保存为 icon.png(默认 3232 像素，大了也没关系) 和 icon-192.png(192192 像素)，并放到项目的 static/img 目录下\n给文章添加精选图 这个图片只能添加一个，名字必须是 featured.*(后缀 jpg/png 都行)，而且必须和文章放在同一个文件夹下。\n所以一般做法是把文章 aaa.md 改名为 index.md 并新建一个 aaa 目录，再和 featured.png 图片一起扔进去。\n显示的效果是在文章列表页，文章右侧有一个缩略图；打开文章，标题默认会居左，右边是精选图：\n给文章添加头部背景 这个是文章头部的横跨整个页面的大图，也就是文章头部这个黑底白字的大图。\n这个的图片可以放到 static/img 目录下，不过需要在你文件的 +++ 的部分添加如下代码：\n[header] image = \u0026quot;img 名称\u0026quot; caption = \u0026quot;标题说明\u0026quot;  顺便一提，文章内引用 static/img 下存储的图像的话，路径大致如此 ![example](/media/image_abc.png)\n目录 使用 {``{% toc %}} 加在文章的任何你想要的地方以自动生成目录\n注意 / 警告标识 被 {``{% alert note %}} 和 {``{% /alert %}} 包裹起来的内容即为注意项：\n 注意内容 blabla   被 {``{% alert warning %}} 和 {``{% /alert %}} 包裹起来的内容即为警告项：\n 警告内容 blabla   消除短代码效果 Hugo 是基于 Go 的 Template，所以所有以 {``{% %}} 或者 {``{\u0026lt; \u0026gt;}} 包裹的内容都会被解析为短代码块，而无法直接显示其代码。 那么我是怎么解决的呢，分情况：\n单行代码 你看到的 {``{% toc %}} 实际是由 `{` 和 `{% toc %}}` 组成的。\n而上面打出的 ` 其实是 双反引号 空格 反引号 空格 双反引号，就不再嵌套了。。。\n代码块 {{\u0026lt; figure library=\u0026quot;1\u0026quot; src=\u0026quot;image.jpg\u0026quot; title=\u0026quot;A caption\u0026quot; \u0026gt;}}  的本质是将 \u0026lt;\u0026gt; 或者 %% 内的内容用 /**/ 注释掉：\n{``{\u0026lt;/* figure library=\u0026quot;1\u0026quot; src=\u0026quot;image.jpg\u0026quot; title=\u0026quot;A caption\u0026quot; */\u0026gt;}}\n 谁知道 Markdown 的代码块怎么嵌套\u0026hellip; 比如外层一个 markdown 的代码块， 里面要显示包含反引号格式的 python 代码块\u0026hellip;   修改模板 比如你看到我每个文章结尾都有一个 CC4.0 协议 的标志，这个肯定不是一篇篇手动添加的，实际上我是自己写了一个 License 的 Widget，插入到文章的模板里面实现的。\n 不要直接修改 theme 里面的内容，否则更新主题的时候会非常尴尬。   正确的做法是在项目根目录建立 layouts 文件夹，将你想修改的模板从 themes/academic/layouts 拷贝过来再修改。\n现在 Academic 主题的 layouts 大概是这样的：\n _default: 默认文章相关模板； docs: 文档相关模板; home: 主页相关模板; partials: 小部件相关模板，页面头部 / 脚注 / 摘要等等的都在这;  额外的有一个 widgets 文件夹，里面是主页的 widget 的模板；   project: 项目相关模板; publication: 出版物相关模板; section: 摘要相关模板; shortcodes: Academic 提供的额外效果模板，你写的所有 {``{%%}} 的内容效果都出自这里; slides: 幻灯片相关模板; talk: 宣讲相关模板;  继续用我自己做例子，我新建了 layouts/partials/license.html，把 CC 协议相关内容存了进去， 接着，复制主题目录下的 layouts/_default/single.html 到对应位置，在合适地方插入一句 {{partial \u0026quot;license.html\u0026quot; .}}，表明我要在这里使用名为 license.html 的 partial。 再之后就是你们看到的效果了。\n","date":1544344482,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544344482,"objectID":"698f7fbd0cc48ca529327ed5a4c640db","permalink":"https://szthanatos.github.io/post/academic/academic_in_practice/","publishdate":"2018-12-09T16:34:42+08:00","relpermalink":"/post/academic/academic_in_practice/","section":"post","summary":"目录 Hugo 安装 / 更新 安装 / 更新 常用命令 Academic 安装 / 更新 通过 Netlify 通过 Git 部","tags":["Hugo"],"title":"Academic 实现 Github Page 个人博客","type":"post"},{"authors":[],"categories":["DataBase"],"content":"目录  简介 一般原则 命名空间 (NameSpace)  命名规范 示例   表 (Table)  命名规范 示例   行键 (Rowkey)  命名规范 示例 注意   列族 (ColumnFamily)  命名规范 示例 注意   列 (Qualifier)  命名规范 示例      简介 本指南是对在 HBase 进行字段设计而提供的指导性准则和建议。总体标准、设计方式参照 Google 开源项目风格指南 以及现有项目经验。所有条目均为个人总结，并不是一份官方标准性质的指南 。\nHBase 是建立在 Hadoop 文件系统（HDFS）之上的分布式、面向列的数据库。\n一般原则  无论是表或者是列或者其他，都应该使用名词或者动宾短语以代表一类对象; 尽量避免使用 (尤其是单独使用) 例如 int、join、select 等常见保留词; HBase 在性能和效率上更擅长处理 “高而瘦” 的表，而非 “矮而胖” 的表——以 Excel 类比，HBase 应该尽可能设计成只有很少的列 (瘦) 而有非常多行 (高) 的模式;  命名空间 (NameSpace) 命名规范  采用英文单词、阿拉伯数字的组合形式，其中，单词必须大写，并且首字符必须为英文字符，不能是数字; 不建议用连接符（下划线）拼接多个单词，简单语义的可采用单个单词，复杂语义的可采用多个单词的首字母拼接; 长度尽量限制在 4~8 字符之间; 命名空间一般可与项目名称、组织机构名称等保持一致; 一般情况下如果不指定命名空间，表会被放在默认 (default) 命名空间下;  示例 ZKR XJ917  表 (Table) 命名规范  采用英文单词、阿拉伯数字、连接符（_）的组合形式，其中，单词必须大写，并且首字符必须为英文字符，可用连接符拼接多个单词; 长度尽量限制在 8~16 字符之间; 尽量采用具有明确意义的英文单词，而不建议采用汉字的拼音字母或者拼音首字母组合; 无需以 TABLE 结尾;  示例 USER_INFO WEIBO_USER_FANS  行键 (Rowkey) 命名规范  采用英文单词、阿拉伯数字、非转义字符组合形式，不要求大小写，但首字符必须是英文字符或数字;  示例 123456-654321 dftf3a3l3rv3qr s.taobo.com/faefavc  注意 慎重将时间戳直接放入行键中 对于同一条数据，HBase 本身提供时间戳 (TimeStamp) 以在同一个 RowKey 下保存不同版本数据; 对于整体，存放旧数据的区域随着时间戳增大可能不再写入，而存放新数据的区域始终保持高负荷，这样降低了 HBase 整体的读写能力。\n一个推荐的方式是使用反向时间戳。\n权衡 hash 和 string 的效果 哈希化 (一般特指单项哈希) 的 Rowkey 能很好的避免热点问题，但是也会同时丢失直接使用 String 的 RowKey 的天然聚类和排序的能力。\n列族 (ColumnFamily) 命名规范  采用英文单词、阿拉伯数字的组合形式，其中，单词必须大写，并且首字符必须为英文字符，不能是数字; 长度尽量限制在 1~6 字符之间，过长的列族名称将占用更多的存储空间, 它们不应该像在典型的 RDBMS 中一样具有自我记录和描述性;  示例 DATA D1 # data1 WA # web args  注意 列族的数量应控制在 1-3 个 HBase 表不应该被设计成模拟 RDBMS 表，列族的数量在满足需求的情况下应该尽可能少。在存储时，一个列族会存储成一个 StoreFile，多个列族对应的多个文件在分裂时会对服务器造成更大的压力。\n列 (Qualifier) 命名规范  采用英文单词、阿拉伯数字、连接符（_）的组合形式，其中，单词必须 ** 小写 **，并且首字符必须为英文字符，不能是数字，可用连接符拼接多个单词; 所有列名都应该是名词或者以 is 开头的动宾短语 (表示判断)，不应该使用其他词性单词; 允许使用前缀，不允许使用后缀; 长度尽量限制在 1~16 字符之间; 尽量采用具有明确意义的英文单词，而不建议采用汉字的拼音字母或者拼音首字母组合;  示例 user_name is_str sound_type  ","date":1544343567,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544343567,"objectID":"bcc2384e562b7caba94eeba86a28363e","permalink":"https://szthanatos.github.io/post/hbase_design/","publishdate":"2018-12-09T16:19:27+08:00","relpermalink":"/post/hbase_design/","section":"post","summary":"目录 简介 一般原则 命名空间 (NameSpace) 命名规范 示例 表 (Table) 命名规范 示例 行键 (Rowkey)","tags":["HBase"],"title":"hbase 表设计风格指南","type":"post"},{"authors":[],"categories":[],"content":"目录  简介 最新情况 创始人 发展历程 产品内容  官方主页： Home | Palantir 产品线 解决方案      简介 Palantir 是全球第一大 大数据公司。曾经的全球四大独角兽之一（其它三家是 Uber，Airbnb 和小米）。中文名帕兰提尔，源于《指环王》中邪恶巫师萨鲁曼使用的可穿越时空、洞悉世间一切的水晶球 (Palantiri)。主要客户为政府机构和金融机构。\n最出名的案例是以大数据技术帮助美国军方成功定位和击毙基地组织首脑本 · 拉登，以及协助多家银行追回了纳斯达克前主席麦道夫 Bernie Madoff 的庞氏骗局中所隐藏起来的数十亿美元巨款。\n 最新情况   2018 年 10 月 29 日，Palantir 正在建立 ICE 的案例管理软件 —— AL DIA News\n  2018 年 10 月 23 日，亚马逊、微软、Palantir 等科技公司在特朗普的移民法案中起到重要作用 —— Common Dreams\n  2018 年 10 月 19 日，Palantir 或明年上市，估值达 410 亿美元 —— MAYA KOSOFF\n  2018 年 09 月 14 日，美国陆军决议中止对 Palantir2.06 亿美元的采购合同 —— LAW 360\n  2018 年 03 月 14 日，雷神、Palantir 拿下美国陆军 8.76 亿美元合同 —— reuters\n  2018 年 03 月 02 日，传 Palantir 在新奥尔良秘密测试犯罪预测技术，最神秘的独角兽再陷隐私风波 —— 猎云网\n  Palantir 发布 2017 年度报告 重点提到在哈维飓风的救援以及灾后重建工作，以及帮助世界粮食计划署运输食品以对抗饥饿的工作中所起到的作用。\n   创始人   Peter Thiel\n斯坦福本科及法学院 JD 的高材生，《从 0 到 1》的作者。创立了 Clarium Capital、Founders Fund、Valar Ventures、、Mithril Capital Management 等多支基金。Paypal 创始人之一并出任 CEO。2002 年 paypal 被收购之后，以投资人身份投资包括 Facebook、Asana、Quora、LinkedIn、Yelp、Yammer 在内的诸多当今一线公司。号称硅谷创投教父。\n  Alex Karp (CEO)\n哈佛本科毕业，斯坦福法学 JD 学位，德国法兰克福大学新古典社会理论方向博士学位，师从本世纪最伟大的哲学家之一哈贝马斯。早年继承家产后成为硅谷著名投资人，并在伦敦创立 Caedmon Group 基金管理投资。目前坚持保持单身，热爱气功、游泳以及与员工讲马克思还有带领员工在硅谷打太极。Peter Thiel 在斯坦福的室友。\n  Joe Lonsdale\n斯坦福计算机系毕业。除 Palantir 外，还曾创办另外两家高科技公司，和硅谷最大的面向亚洲的风投基金 Formation8、 8vc。管理着 5000 亿美元财富。此外，还是《福布斯》评选出的 12 位行业未来之星之一，还被美国媒体评为硅谷排名第二的天使投资人。\n  Stephen Cohen\n毕业于斯坦福计算机系的高级工程师。\n  Nathan Gettings\n来自于 PayPal 的的高级工程师。在 PayPal 负责风险和研发的总监，曾以开发了反欺诈的系统而闻名于世。\n   发展历程  2004 年 Palantir 公司创立于加利福尼亚州帕洛阿尔托。创业初期 Palantir 并不被人看好，融资过程也是屡屡受阻，包括红杉资本，凯鹏华盈两大 VC 基金都不看好 Palantir 的发展。经过多次奔走博弈，最终，Palantir 赢得了 CIA 的创投基金的 2 轮投资，从而走上了发展的正轨。 2004 到 2009 年，Palantir 主要业务还是服务于美国政府部门，提供情报分析，防欺诈、反恐等服务。 2010 年，Palantir 开始提供企业服务，实现业务多元化。 2010 年 7 月，当时已经拥有 250 位工程师的 Palantir 完成 9000 万美元的 D 轮融资，估值达到 7.35 亿美元。 2011 年 5 月 6 日，融资 5000 万美元，累计融资额达到了 1.75 亿美元。 2011 年 10 月 7 日，融资 7000 万美元，估值 25 亿美元。 2013 年 9 月 29 日，融资 1.96 亿美元，估值 60 亿美元。 2013 年 12 月，Palantir 新一轮融资 1.075 亿美元，同时估值达到 90 亿美元。此时 Palantir 的年收入已经超过 4.5 亿美元。 2014 年 11 月，Palantir 再拿到 5 亿美元投资，企业用户突破 14000 家，估值达到了 150 亿美元。 2015 年年底，Palantir 获得 8.8 亿美元的融资，市值达到 200 亿美元。成为继 Uber、小米、Airbnb 之后，全球估值第四高的创业公司。（截至 2018 年 11 月最后一笔融资） 2016 年 2 月，收购 Kimono Labs 2016 年 5 月，Buzzfeed 爆料, 数司百名员工离职，多个重要客户不再续约。 2016 年 8 月，Palantir 收购数据可视化公司 Silk。 2018 年 10 月，Palantir 预备明年下半年上市，公司估值或将达 410 亿美元   产品内容 官方主页： Home | Palantir 产品线 目前 Palantir 仅保留两条产品线：\n  Palantir Gotham 一个集成，管理，保护和分析多来源的企业数据的复合平台。命名来源于蝙蝠侠所在的哥谭市。作为后端，Gotham 平台可用于集成许多不同的数据源，以进行安全的协作分析；也可以存储企业的各类建模分析数据，充当企业知识库。而在前端, Gotham 平台提供了一套针对语义，时间，地理空间和全文分析的分析工具集合。为 Gotham 提供支撑的子产品包括：\n PHOENIX 支持 PB 级的数万亿条记录进行亚秒级查询的集群数据库； RAPTOR 提供对外部数据源进行联合查询, 并实时加入数据库的检索工具； SEARCH 提供对系统中结构化和非结构化数据的全文检索的搜索引擎； HORIZON 允许用户在数十亿个对象中查询并在约 10 秒内收到结果的, 类 Spark 设计的内存数据库； DYNAMIC ONTOLOGY 高度灵活和动态的数据建模工具； REVISIONING DATABASE RevDB 是 Gotham 平台的持久化数据管理工具，类似 Zookeeper 之于 Hadoop； ATLASDB 作为 RevDB 的具体数据存储单元，结合了 NoSQL 数据存储的简单性和可扩展性与传统 SQL 数据库的事务安全性和一致性； NEXUS PEERING 分布式系统平台，上面的各个组件都建立在这个平台之上；    Palantir Foundry ：数据集成 / 分析平台，将后端的数据存储和前端的数据分析打通，让任何人都能连接到不同数据源轻松进行建模分析。\n  解决方案 Palantir 面向以下领域直接提供解决方案：\n 汽车制造业 网络安全 金融合规 企业内部信息安全 商业情报分析 法律诉讼 并购支持 收入最大化 数据组织 国土防卫 欧盟通用数据保护监管 保险分析 公共执法 制造业 医药研发 航空业  ","date":1544000961,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544000961,"objectID":"3a0a3ff6504fdcc30a1757e8d02e8c1f","permalink":"https://szthanatos.github.io/post/palantir_intro/","publishdate":"2018-12-05T17:09:21+08:00","relpermalink":"/post/palantir_intro/","section":"post","summary":"目录 简介 最新情况 创始人 发展历程 产品内容 官方主页： Home | Palantir 产品线","tags":[],"title":"Palantir 一分钟印象","type":"post"},{"authors":[],"categories":["Python"],"content":"  添加 ppa 源：\n# 死蛇的源 sudo add-apt-repository ppa:deadsnakes/ppa # 或者，jonathonf 的源 sudo add-apt-repository ppa:jonathonf/python-3.x  如果提示没有 add-apt-repository 的话执行：\napt install software-properties-common    更新源并安装 python3.x，3.x 以你要安装的版本号为准：\nsudo apt update sudo apt install python3.x # 可选 sudo apt install python3.x-dev sudo apt install python3.x-venv    安装 pip:\nwget https://bootstrap.pypa.io/get-pip.py sudo python3.x get-pip.py    查看 python 和 pip 版本：\n# 也可以用 - V python --version python3 --version pip --version pip3 --version    如果关联版本不正确，备份 usr/bin 的软链接，重建软链接：\n# 设置默认 python3 对应 python 版本 sudo ln -s /usr/bin/python3.x /usr/bin/python3 # 设置默认 pip3 使用 pip 版本 sudo ln -s /usr/local/bin/pip3.x /usr/bin/pip3  注意 python 默认安装位置在 /usr/bin 下，pip 默认安装位置在 /usr/local/bin 下\n  pip 初始化设置：\nmkdir ~/.pip touch ~/.pip/pip.conf # python3.6/pip18 之后无需配置这个 echo [list]\u0026gt;\u0026gt;~/.pip/pip.conf echo format=columns\u0026gt;\u0026gt;~/.pip/pip.conf # 设置默认 pip 源为清华大学开源镜像 echo [global]\u0026gt;\u0026gt;~/.pip/pip.conf echo index-url = https://pypi.tuna.tsinghua.edu.cn/simple\u0026gt;\u0026gt;~/.pip/pip.conf    (可选) 一键升级所有过期的包：\nsudo pip freeze --local | grep -v '^\\-e' | cut -d = -f 1 | xargs pip install -U    ","date":1543651144,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1543651144,"objectID":"c5010c0959e1966312b2fb992ff8040e","permalink":"https://szthanatos.github.io/post/python/python_install_on_ubuntu/","publishdate":"2018-12-01T15:59:04+08:00","relpermalink":"/post/python/python_install_on_ubuntu/","section":"post","summary":"添加 ppa 源： # 死蛇的源 sudo add-apt-repository ppa:deadsnakes/ppa # 或者，jonathonf 的源 sudo add-apt-repository","tags":["Ubuntu"],"title":"Ubuntu 安装最新版本 Python","type":"post"},{"authors":[],"categories":[],"content":"这是我第四次，也可能是我最后一次博客迁移 (flag 已立←_←)。\n从大学时代开始，找个地方写点什么的蠢动心思就没消停过，但是也都消磨在了无关文字的地方。有一个 Geek 圈子的说法，yak-shaving，剪牦牛毛，放我身上非常合适——本来只是想写点什么，却发现不知道写哪好，就开始研究市面上的博客服务，又发现都不太好用不如自己搭，又开始研究自建网站，自建网站的过程中又发现自己需要一个服务器，又开始折腾主机\u0026hellip; 折腾个人域名\u0026hellip; 折腾 Linux\u0026hellip; 折腾 LAMP 环境\u0026hellip;——总之折腾到最后，走马观花的东西很多，写出来的东西寥寥无几。\nyak-shaving 的得失不提，到了现在的这个阶段，折腾的心思已经熄了很多，但是已经写出来的东西零零散散还是会难以忍受。也有一部分内容已经过时，或者回头再看理解已经完全不同\u0026hellip; 总而言之，借此机会，旧的内容安置妥当，咱们就此别过。未来的文章，短时间内也无虞搬迁之苦，踏踏实实的呆在实验室档案柜吧。\n以后笔记只分两部分存储：未经整理的内容继续保存在 OneNote 里，相对完整的东西再放到这里来。\n旧的博客文章大概 200 篇不到，但是想到要挨个过一遍还得翻新到 Hugo 的模板\u0026hellip;.. 就感觉\u0026hellip;\u0026hellip; 啊，还是鸽了吧\u0026hellip;\u0026hellip;（不过自己立的 flag 哭着也要做完的）\n说回个人博客。\n上一个博客的灵感是万智牌 （和长者），为自己设定的身份是掌握了东方神秘膜法的旅法师\u0026hellip; 所以取名叫做 \u0026ldquo;黑膜法师营地\u0026rdquo;，不过旅法师对决之后也已经好久没玩了。\n至于现在博客的设定，起源于最近重温 守望者。看到罗夏(罗夏帅爆!) 就想到老爷，看到笑匠就想到小丑(罗夏：致命玩笑←_←)，看到法老王\u0026hellip; 唔\u0026hellip; 蝙蝠侠对抗的智商爆表而且 ** 精神正常 ** 的反派\u0026hellip; 阿卡姆疯人院:\u0026ldquo;外面的都是神经病啊，不要放进来！\u0026quot;。\n脑洞扩展到 DCEU，嗯，超人，嗯，卢瑟，嗯，巴别塔\u0026hellip; 老爷不会只靠定情小氪石的，一定有后备方案，嗯，Lex Wayne，就这么定了。\n顺理成章，细节设定就是严肃的考 (wan) 证(geng)啦。\nKryptonite Lab 氪石实验室，没什么好说的，名字都是 Lex Wayne 了肯定患有氪石狂热啦 (雾！)，什么住在全是氪石的实验室啦，爱嚼氪石口香糖啦，肯定都是基本设定啦 (大雾！)。\n42 这个倒和 DCEU 没关——《银河系漫游指南》里宇宙的终极答案啊！十六进制的 ASCII 码 *，'theAnswertoLifetheUniverseandEverythingis' 问题本身的长度，感觉没有更赞的了 1。已经想好了，如果以后完善 Lab 的设定，里面的超算肯定叫深思 (Deep Thought)。\nWayne Manor B3, 1007 Mountain Drive, Gotham, NJ 12345, USA 一段一段说，\nWayne Manor B3 地下三层取自这个蝙蝠洞的设计图：放大可以看到地下从上往下数分别是\n -1 Main Level -2 Additional Hangar Aeras -3 Sub Level 1 \u0026hellip;  Sub Level 1 放的就是 Labs/Workshops/Library。\n1007 Mountain Drive, Gotham 韦恩庄园所在的 1007 Mountain Drive 这个地址来源于 92-95 年的蝙蝠侠动画 Batman: The Animated Series 第一季中的 The Demon's Quest 故事，应该也是目前蝙蝠侠相关作品中唯一正面出现的庄园地址。\n具体坐落在哥谭的什么位置可以参考 1999 年 Eliot R. Brown 制作的地图：而更新一点的设定可以参考诺兰的黑暗骑士的周边 《黑暗骑士手册》：总之，都在右上角啦←_←。\nNJ 12345, USA NJ 是新泽西的缩写，虽然哥谭给人的印象就是纽约（早于黑暗骑士的电影给人的感觉可能更像芝加哥），但新泽西的设定可以追溯到 1974 年的 DC 漫画惊奇世界 (详见维基)，NJ 12345 也是出自 93 年的 Batman: Shadow of the Bat 里的那个驾驶证：72 Faxcol Dr Gotham City, NJ 12345。\n其他彩蛋 其他的设定零零碎碎的，以后也会往里面填充更多内容啦。\nStar War 比如我个人介绍的 Python Knight \u0026amp; Go Padawan，这里的 Knight 显然和黑暗骑士什么的无关——Jedi！星战好像已经是老年人爱好了\u0026hellip; 但当年真的迷过一段时间，桌面都是拿星战的设定集原画做的\u0026hellip;\n另一方面是一时想不到 DCEU 里面和等级相关的设定了\u0026hellip; 星战就很明确啊， youngling 是幼徒，Padawan 是学徒，Knight 是武士，Master 是大师，简单明了~\n再有就是，Kryptonitesaber 什么的想想就很带感啊\u0026hellip; 以后绝对要补充这方面设定的！\n嗯\u0026hellip; 上面都是写给自己看的，\n陌生人， 欢迎翻阅氪石实验室 42 号档案柜。   《蜘蛛侠: 平行宇宙》也是 42 的梗，大家真的是很爱 42 啊\u0026hellip;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":1543636824,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1543636824,"objectID":"89a5c36beed57ab8d9a8e0a7113e33dd","permalink":"https://szthanatos.github.io/post/0x00/","publishdate":"2018-12-01T12:00:24+08:00","relpermalink":"/post/0x00/","section":"post","summary":"这是我第四次，也可能是我最后一次博客迁移 (flag 已立←_←)。 从大","tags":[],"title":"欢迎来到氪石实验室","type":"post"},{"authors":[],"categories":["Python"],"content":"目录  什么是单元测试 为什么要写单元测试 怎么写单元测试  原生测试框架 unittest/unittest2 第三方测试框架 py.test   单元测试标准  代码覆盖指标 代码覆盖率   小结     这是写给我组里的人看的，顺手粘过来   什么是单元测试  单元测试 (Unit Testing) 又称为模块测试，是针对程序模块（软件设计的最小单位）来进行正确性检验的测试工作。程序单元是应用的最小可测试部件。在过程化编程中，一个单元就是单个程序、函数、过程等；对于面向对象编程，最小单元就是方法，包括基类（超类）、抽象类、或者派生类（子类）中的方法。\n 一句话概括，单元测试也就是校验代码中具体的类 (甚至函数) 的输出值是否符合预期。\n为什么要写单元测试  “可能出错的事情最终一定会出错”\n——墨菲定律\n 代码随着时间的累计而增长，出现意想不到的问题的可能性也在指数级上升。代码的正确与否不应该靠人来保证，因为人是会犯错并且一定犯错的。如果每次新功能上线时不能回答 “所有功能都测试过了么” 的问题，那么最终整个项目的可靠性都将被摧毁。单元测试的意义就在于让你能够回答这个问题，并且，回答的更自动化。\n怎么写单元测试 原生测试框架 unittest/unittest2 在 python 语境中，官方提供 unittest 标准库完成单元测试。\n基础 需要理解的概念有如下四个：\n test fixture：单元测试所需上下文环境，比如临时数据库 / 网络连接等； test case：一个独立的单元测试最小单位； test suite：test case 的集合； test runner：执行并输出单元测试的程序；  详细定义请自行查阅 官网文档。\n官方单元测试用例如下，我们对 upper(将 string 转换为大写)、isupper(判断 string 是否全部为大写)、split(对 string 按空格切分为 list) 函数的功能进行校验\nimport unittest class TestStringMethods(unittest.TestCase): def test_upper(self): self.assertEqual('foo'.upper(), 'FOO') def test_isupper(self): self.assertTrue('FOO'.isupper()) self.assertFalse('Foo'.isupper()) def test_split(self): s = 'hello world' self.assertEqual(s.split(), ['hello', 'world']) # check that s.split fails when the separator is not a string with self.assertRaises(TypeError): s.split(2) if __name__ == '__main__': unittest.main()  断言 可以从上面的例子看出，单元测试判断结果是否符合预期的主要方式是通过断言 (assert) 实现。 以下是常见断言：\n   Method Checks that     assertEqual(a, b) a == b   assertNotEqual(a, b) a != b   assertGreater(a, b) a \u0026gt; b   assertGreaterEqual(a, b) a \u0026gt;= b   assertLess(a, b) a \u0026lt; b   assertLessEqual(a, b) a \u0026lt;= b   assertAlmostEqual(a, b) round(a-b, 7) == 0   assertNotAlmostEqual(a, b) round(a-b, 7) != 0   assertRegex(s, r) r.search(s)   assertNotRegex(s, r) not r.search(s)   assertTrue(x) bool(x) is True   assertFalse(x) bool(x) is False   assertIs(a, b) a is b   assertIsNot(a, b) a is not b   assertIsNone(x) x is None   assertIsNotNone(x) x is not None   assertIn(a, b) a in b   assertNotIn(a, b) a not in b   assertIsInstance(a, b) isinstance(a, b)   assertNotIsInstance(a, b) not isinstance(a, b)    setUp 和 tearDown test fixture 是通过 setUp 和 tearDown 来具体实现的。\nsetUp() 方法： 在执行每个测试用例 (test case) 之前被执行，除了 unittest.SkipTest 和 AssertionError 以外的任何异常都会当做是 error 并终止当前测试用例；\ntearDown() 方法： 执行了 setUp()方法后，执行 tearDown()方法 (进行清理)。对异常的处理和 setUp() 类似；\nsetUpClass(cls) 与 tearDownClass(cls) 类： 可以将 setUp 和 tearDown 定义在基类中避免重复定义，定义 setUpClass(cls) 与 tearDownClass(cls) 类时必须加上 classmethod 装饰符；\n对上面的例子进行简单的改造以演示 setUp 和 tearDown 的效果：\nimport unittest class TestStringMethods(unittest.TestCase): def setUp(self): print '1. setUp here' def tearDown(self): print '2. tearDown here' def test_upper(self): self.assertEqual('foo'.upper(), 'FOO') ...  执行后效果如下：\ntest_isupper (mytest.TestStringMethods) ... 1. setUp here 1. tearDown here ok  缺点 基本的一个单元测试可以用这四步概括：\n 新建单元测试脚本 导入单元测试依赖 继承单元测试类 实现单元测试方法  而这个过程非常不 pythonic：\n 必须新建单独的测试文件 测试必须继承自 unittest 类，即使再简单的测试 断言只能使用 unittest 的 Assertion 最最关键和难以忍受的：unitunit 内的命名规则和 pep 8 相悖  造成这些问题的原因一言以蔽之：python 的测试框架是完全仿照 Java 实现的。\n第三方测试框架 py.test 实际上，通过使用 py.test，我们可以非常 pythonic 的实现单元测试：\n# content of test_sample.py def inc(x): return x + 1 def test_answer(): assert inc(3) == 5  直接在测试文件所在目录执行 py.test 得到如下结果：\n$ pytest =========================== test session starts ============================ platform linux -- Python 3.x.y, pytest-3.x.y, py-1.x.y, pluggy-0.x.y rootdir: $REGENDOC_TMPDIR, inifile: collected 1 item test_sample.py F [100%] ================================= FAILURES ================================= _______________________________ test_answer ________________________________ def test_answer(): \u0026gt; assert inc(3) == 5 E assert 4 == 5 E + where 4 = inc(3) test_sample.py:6: AssertionError ========================= 1 failed in 0.12 seconds =========================  就是这么简单，更进一步的，py.test 支持自动生成对指定目录下所有测试文件的统一测试脚本，更具体的用法参见 pytest 文档\n总的来说，py.test 具有如下特点：\n 非常容易上手，入门简单，文档丰富，文档中有很多实例可以参考 能够支持简单的单元测试和复杂的功能测试 支持参数化 执行测试过程中可以将某些测试跳过，或者对某些预期失败的 case 标记成失败 支持重复执行失败的 case 支持运行由 nose , unittest 编写的测试 case 具有很多第三方插件，并且可以自定义扩展 方便的和持续集成工具集成  单元测试标准 业界通常使用代码覆盖 (率) 来评判测试的好坏。\n代码覆盖指标 单独的一两个测试完全无法体现测试的优势。而对所有可能的情况编写单元测试既不现实也无必要。所以明确测试覆盖哪些指标非常重要。我们在此指定以下四个指标必须被覆盖：\n  函数覆盖（Function Coverage）\n每一个函数都必须被测试；\n  语句覆盖（Statement Coverage）\n被测代码中每个可执行语句都应该被执行测试。例如\ndef foo(x:int, y:int): z = 0 if x\u0026gt;0 and y \u0026gt;0: z = x return z  中，如果测试为 assertEqualst(0, foo(2,-1))，则 if 内的代码就没有被覆盖到；\n  决策覆盖（Decision Coverage）\n指每一个逻辑分支都应该被测试覆盖。类似上面的例子，如果想要达到决策覆盖，我们起码应该执行两次测试：\n assertEquals(2, foo(2, 2)) # 决策 1 assertEqualst(0, foo(2,-1)) # 决策 2    条件覆盖（Condition Coverage）\n每一个逻辑分支的每一个条件都应该被覆盖。条件覆盖不需要满足条件表达式所有的排列组合，而只需将每个条件表达式的结果为 true/false 的情况进行测试就可以了。依旧使用上面的例子，如果想要达到条件覆盖，我们应该执行至少三次测试：\n  assertEquals(2, foo(2, 2)) # 决策 1 条件 true\n  assertEqualst(0, foo(2,-1)) # 决策 2(没有条件)\n  assertEquals(0, foo(-1, -1)) # 决策 1 条件 false\n如果没有第三个测试，那么只能达到决策覆盖，不能达到条件覆盖。\n    代码覆盖率 在满足代码覆盖指标的基础上，只有保证一定的代码覆盖率才能保证测试的完整。满足代码覆盖指标相当于是 “质”，而代码覆盖率则是保证 “量”。目前要求代码覆盖率不应该低于 75%\n我们选定 coverage.py 来统计代码覆盖率。由于主要使用 py.test，需要额外安装 pytest-cov 插件。安装过程非常简单，对照文档直接 pip 安装即可，不多介绍。\n完成安装后，使用 py.test 的时候增加 \u0026ndash;cov=myproj 参数即可。 效果如下：\n-------------------- coverage: ... --------------------- Name Stmts Miss Cover ---------------------------------------- myproj/__init__ 2 0 100% myproj/myproj 257 13 94% myproj/feature4286 94 7 92% ---------------------------------------- TOTAL 353 20 94%  详细用法可参照 官方文档\n小结 总结一下，通过对单元测试的必要性、编写方法、评判标准等一系列的介绍，确立了以下三点：\n 使用 py.test+unittest 编写单元测试，使用 coverage 统计、分析单元测试编写情况； 单元测试应覆盖最基本的四项指标 (函数覆盖、语句覆盖、分支覆盖、条件覆盖)； 在覆盖基本指标的基础上，需要达到 75% 的代码覆盖率；  ","date":1534733390,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1534733390,"objectID":"1d163cc095fb33531a2d24b7b49de76d","permalink":"https://szthanatos.github.io/post/python/unit_testing/","publishdate":"2018-08-20T10:49:50+08:00","relpermalink":"/post/python/unit_testing/","section":"post","summary":"目录 什么是单元测试 为什么要写单元测试 怎么写单元测试 原生测试框","tags":["unit testing"],"title":"python 单元测试标准及实现","type":"post"},{"authors":null,"categories":null,"content":"报错信息  MISCONF Redis is configured to save RDB snapshots, but it is currently not able to persist on disk.\n 原因 绝大多数情况是写磁盘写满了，并且 redis 默认 stop-writes-on-bgsave-error 配置为 yes，无法正确的存储 rdb 文件的时候也就拒绝客户端的请求了。\n解决办法 解决 rdb 保存问题 有重要数据的时候不能直接清空重来，先检查磁盘空间是否足够，然后指定一个新的 rdb 文件，重新 bgsave：\n# 1. 更改工作目录位置 CONFIG SET dir /tmp/some/directory/other/than/var # 2. 设置 rdb 文件名 CONFIG SET dbfilename temp.rdb # 3. 保存新的 rdb 文件 BGSAVE  以上修改会在重启 redis 后失效，根据实际情况处理吧。\n(临时) 解决无法写入问题 关闭 rdb 保存失败拒绝写入的功能：\nconfig set stop-writes-on-bgsave-error no  ","date":1526614970,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1526614970,"objectID":"91d3936afad4265f1395d7e9a5dff8ff","permalink":"https://szthanatos.github.io/topic/redis/05-troubleshooting/persist_on_disk/","publishdate":"2018-05-18T11:42:50+08:00","relpermalink":"/topic/redis/05-troubleshooting/persist_on_disk/","section":"topic","summary":"报错信息 MISCONF Redis is configured to save RDB snapshots, but it is currently not able to persist on disk. 原因 绝大多数情况","tags":null,"title":"not able to persist on disk","type":"book"},{"authors":[],"categories":["Python"],"content":"遇到一个报错：\n PicklingError: Can't pickle \u0026lt;type'instancemethod'\u0026gt;: attribute lookup __builtin__.instancemethod failed\n 当时的情况是想写一个多进程的解析代码，爬虫爬到的内容给扔过来就不管了，差不多这个意思：\n# !/usr/bin/env python # -*- coding: utf-8 -*- from concurrent.futures import ProcessPoolExecutor class PageProcess(object): def __init__(self, worker): self.max_worker = worker def single_process(self, page): pass def multi_process(self, page_list): with ProcessPoolExecutor(max_workers=self.max_worker) as pp: result = pp.map(self.single_process, page_list)  这个错误是这么造成的：\n 在类中使用进程池； 进程池使用 Queue 管理任务队列； Queue 要求传递的内容必须都是可以被序列化的；  那么问题来了，哪些类型是可以被序列化的呢？\n根据 官方文档，可序列化的类型包括：\n   类型 原文     布尔型和空值 None, True, and False   数字类型中的整数，浮点数和复数 integers, floating point numbers, complex numbers   字符串类型和二进制类型 (字节流，字节数组) strings, bytes, bytearrays   只包含可序列化对象的元组、集合、列表、字典 tuples, lists, sets, and dictionaries containing only picklable objects1   模块中最顶层声明的非匿名函数 functions defined at the top level of a module (using def, not lambda)   模块中最顶层声明的内置函数 built-in functions defined at the top level of a module   模块中最顶层声明的类 classes that are defined at the top level of a module   __getstate__ 的结果或 __dict__ 是可序列化的这样的类的实例 instances of such classes whose __dict__ or the result of calling __getstate__() is picklable    破案了，上面代码中，我们的进程池要序列化的是类中的函数，就不符合最顶层定义的函数的要求。\n所以最直接的解决办法也很简单，把要并行的函数抽外面去就行了：\n# !/usr/bin/env python # -*- coding: utf-8 -*- from concurrent.futures import ProcessPoolExecutor def single_process(page): pass class PageProcess(object): def __init__(self, worker): self.max_worker = worker def multi_process(self, page_list): with ProcessPoolExecutor(max_workers=self.max_worker) as pp: result = pp.map(single_process, page_list)    英文这种语序 / 标点我老是搞不懂，这个 containing only picklable objects 到底是指 dictionaries 还是前面全部，就当是全部吧\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":1521533775,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1521533775,"objectID":"e887903f65e926a617e00a75eb54bd97","permalink":"https://szthanatos.github.io/post/python/pickled/","publishdate":"2018-03-20T16:16:15+08:00","relpermalink":"/post/python/pickled/","section":"post","summary":"遇到一个报错： PicklingError: Can't pickle \u0026lt;type'instancemethod'\u0026gt;: attribute lookup __builtin__.instancemethod failed 当时的情况是想写一个多进程的解","tags":["PicklingError","序列化","多进程"],"title":"可序列化类型和多进程 PicklingError","type":"post"},{"authors":[],"categories":["Python"],"content":"对列表的去重很简单，set() 一下再 list() 回来就可以了，但是如果要保留原始列表的顺序呢？\n举例，对 [\u0026quot;b\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;] 这个列表进行原序去重，得到结果应该是 ['b', 'c', 'a']。\n有下面这几种写法：\n二次排序 也就是对去重结果再按原列表 sort 一次：\ndef sort_1(list_in): return sorted(list(set(list_in)), key=list_in.index)  匿名函数 使用匿名函数将列表里不重复的元素累加到一个新列表中：\ndef sort_2(list_in): return reduce(lambda x, y: x if y in x else x + [y], [[], ] + list_in)  借用字典 有序字典 使用 OrderedDict 排序：\ndef sort_3(list_in): return list(collections.OrderedDict.fromkeys(list_in).keys())  defaultdict 类似的, 我们使用 defaultdict 进行排序：\ndef sort_4(list_in): return list(collections.defaultdict.fromkeys(list_in).keys())  直接使用 dict 在 python3.6 之前， dict 的 key 的顺序并不保证一定是插入顺序，所以只有在 python3.6 之后才可以直接用 dict 实现这个操作；\ndef sort_5(list_in): return list(dict.fromkeys(list_in).keys())  完整性能测试代码如下：\n# !/usr/bin/env python # encoding: utf-8 from timeit import repeat from functools import reduce from collections import defaultdict, OrderedDict example = [\u0026quot;b\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;] def sort_1(list_in): return sorted(list(set(list_in)), key=list_in.index) def sort_2(list_in): return reduce(lambda x, y: x if y in x else x + [y], [[], ] + list_in) def sort_3(list_in): return list(OrderedDict.fromkeys(list_in).keys()) def sort_4(list_in): return list(defaultdict.fromkeys(list_in).keys()) def sort_5(list_in): return list(dict.fromkeys(list_in).keys()) if __name__ == '__main__': # time usage: t5\u0026lt; t4 \u0026lt; t3 \u0026lt; t2 \u0026lt; t1 result = {} for i in range(1, 6): result['sort_{}'.format(i)] = repeat('sort_{}(example)'.format(i), 'from __main__ import sort_{}, example'.format(i), number=1000000, repeat=5) for k, v in result.items(): avg_v = round(sum(v) / len(v), 3) print(k, avg_v)  在我的苏菲婆上的结果仅供参考：\n   排序 平均时间     sort_1 1.477   sort_2 1.305   sort_3 0.957   sort_4 0.734   sort_5 0.698    可见，python3.6 之后 dict 是最好的原序去重办法，3.6 之前用 defaultdict 吧。\n","date":1504260537,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1504260537,"objectID":"2b07ecde73ceab87a018956f5781a7b9","permalink":"https://szthanatos.github.io/post/python/unique_list_ordered/","publishdate":"2017-09-01T18:08:57+08:00","relpermalink":"/post/python/unique_list_ordered/","section":"post","summary":"对列表的去重很简单，set() 一下再 list() 回来就可以了，但是如果","tags":["list","benchmark"],"title":"列表原序去重性能测试","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://szthanatos.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]